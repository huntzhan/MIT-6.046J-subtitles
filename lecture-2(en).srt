1
00:00:07,570 --> 00:00:11,230
My name is Erik Demaine. You should call me Erik.

2
00:00:11,960 --> 00:00:14,530
Welcome back to 6.046. This is Lecture 2.

3
00:00:15,230 --> 00:00:20,030
And today we are going to essentially fill in

4
00:00:20,120 --> 00:00:24,360
some of the more mathematical underpinnings of Lecture 1.

5
00:00:24,540 --> 00:00:27,060
So, Lecture 1, we just sort of barely got our feet

6
00:00:27,060 --> 00:00:29,040
wet with some analysis of algorithms,

7
00:00:29,040 --> 00:00:30,430
insertion sort and mergesort.

8
00:00:30,720 --> 00:00:33,070
And we needed a couple of tools.

9
00:00:33,200 --> 00:00:34,740
We had this big idea of asymptotics

10
00:00:34,820 --> 00:00:36,350
and forgetting about constants,

11
00:00:36,410 --> 00:00:37,480
just looking at the lead term.

12
00:00:38,010 --> 00:00:41,300
And so, today, we're going to develop asymptotic notation

13
00:00:41,300 --> 00:00:43,300
so that we know that mathematically.

14
00:00:43,710 --> 00:00:47,130
And we also ended up with a recurrence with mergesort,

15
00:00:47,130 --> 00:00:48,180
the running time of mergesort,

16
00:00:48,240 --> 00:00:50,180
so we need to see how to solve recurrences.

17
00:00:50,380 --> 00:00:52,550
And we will do those two things today.

18
00:00:52,600 --> 00:00:53,330
Question?

19
00:00:54,730 --> 00:00:56,590
Yes, I will speak louder. Thanks.

20
00:00:57,520 --> 00:01:01,290
Good. Even though I have a microphone, I am not amplified.

21
00:01:01,960 --> 00:01:05,000
OK, so let's start with asymptotic notation.

22
00:01:14,830 --> 00:01:17,350
We have seen some basic asymptotic notation.

23
00:01:17,490 --> 00:01:19,260
I am sure you have seen it in other classes before,

24
00:01:19,570 --> 00:01:21,030
things like big O-notation.

25
00:01:22,110 --> 00:01:27,130
And today we are going to really define this rigorously

26
00:01:27,130 --> 00:01:29,650
so we know what is true and what is not,

27
00:01:29,850 --> 00:01:31,980
what is valid and what is not.

28
00:01:38,620 --> 00:01:40,860
We are going to define,

29
00:01:41,870 --> 00:01:45,360
and unfortunately today is going to be really mathematical

30
00:01:45,700 --> 00:01:47,200
and really no algorithms today,

31
00:01:47,210 --> 00:01:49,550
which is sort of an anticlimax.

32
00:01:49,610 --> 00:01:52,770
But next lecture we will talk about real algorithms

33
00:01:52,850 --> 00:01:54,340
and will apply all the things we learned today

34
00:01:54,340 --> 00:01:55,970
to real algorithms.

35
00:01:57,940 --> 00:02:01,610
This is big O-notation,capital O-notation.

36
00:02:01,810 --> 00:02:04,780
We have f(n)=O(g(n)).

37
00:02:04,940 --> 00:02:13,680
This means that there are some suitable constants,

38
00:02:15,760 --> 00:02:19,700
c and n naught,

39
00:02:24,600 --> 00:02:29,830
such that f(n) is bounded by c·g(n)

40
00:02:30,910 --> 00:02:33,810
for all sufficiently large n.

41
00:02:36,710 --> 00:02:39,180
So, this is pretty intuitive notion.

42
00:02:39,220 --> 00:02:40,180
We have seen it before.

43
00:02:40,200 --> 00:02:43,700
We are going to assume that f(n) is non-negative here.

44
00:02:44,110 --> 00:02:47,390
And I just want f(n) to be bounded above by g(n).

45
00:02:47,770 --> 00:02:50,740
We have seen a bunch of examples,

46
00:02:50,770 --> 00:02:58,780
but something like 2n^2=O(n^3) defined.

47
00:02:59,360 --> 00:03:04,730
And roughly this means if you drop leading constants

48
00:03:04,780 --> 00:03:07,750
and low order terms then this is less than or equal to that.

49
00:03:07,880 --> 00:03:10,370
So, big O corresponds roughly to less than or equal to.

50
00:03:11,130 --> 00:03:13,030
But this is the formalization.

51
00:03:13,450 --> 00:03:16,000
Another way to think of it formally,

52
00:03:16,870 --> 00:03:19,320
a funny thing about this notation is it is asymmetric.

53
00:03:19,400 --> 00:03:21,900
Normally, you think of equality being symmetric.

54
00:03:21,960 --> 00:03:23,740
If A=B then B=A.

55
00:03:23,740 --> 00:03:24,840
But it's not true here.

56
00:03:25,130 --> 00:03:28,330
We do not have n^3 being big O of n^2.

57
00:03:28,590 --> 00:03:31,620
We don't even have big O of n^3 equaling n^2.

58
00:03:31,700 --> 00:03:34,830
So, we will see exactly what that means in a second.

59
00:03:36,150 --> 00:03:37,950
But before we get there,

60
00:03:40,720 --> 00:03:44,190
this is a bit bizarre notation

61
00:03:44,370 --> 00:03:46,490
and you should always think about what it really means.

62
00:03:48,000 --> 00:03:50,470
Another way to think about what it really means is

63
00:03:50,470 --> 00:03:55,000
that f(n) is in some set of functions that are like g.

64
00:03:55,350 --> 00:04:01,280
You could define big O(g(n)) to be a set of functions,

65
00:04:01,370 --> 00:04:04,360
let's call it f(n),

66
00:04:06,610 --> 00:04:09,280
such that there exist constants.

67
00:04:11,200 --> 00:04:12,880
They are the same definition,

68
00:04:13,330 --> 00:04:17,730
I think, fancy here, c and no,

69
00:04:19,540 --> 00:04:25,840
such that we have the bound f(n) is between zero and c·g(n).

70
00:04:32,140 --> 00:04:33,570
It is a bit of a long definition,

71
00:04:33,570 --> 00:04:35,360
and that is why we use the notation,

72
00:04:35,370 --> 00:04:37,120
to avoid having to write this over and over.

73
00:04:37,790 --> 00:04:40,610
You can think of instead of n^2

74
00:04:40,610 --> 00:04:42,600
being equal to big O of n^3,

75
00:04:42,600 --> 00:04:47,680
what we really mean is that 2n^2 is in the set big O(n^3).

76
00:04:48,200 --> 00:04:50,300
When we write equal sign,

77
00:04:50,370 --> 00:04:55,060
we in some sense mean this in the set,

78
00:04:55,520 --> 00:04:57,000
but we are going to use equal sign.

79
00:04:57,000 --> 00:04:57,900
You could write this.

80
00:04:58,080 --> 00:04:59,990
And occasionally you see papers that write this,

81
00:04:59,990 --> 00:05:03,990
but this is the notation that we are going to use.

82
00:05:04,110 --> 00:05:06,590
That has the consequence the equal sign is asymmetric,

83
00:05:06,730 --> 00:05:09,960
just like this operator.

84
00:05:11,270 --> 00:05:14,950
We have some nifty ways

85
00:05:15,000 --> 00:05:16,980
that we actually use big O-notation.

86
00:05:26,880 --> 00:05:28,440
And it is using it as a macro.

87
00:05:31,030 --> 00:05:33,100
By the way, we have a lot to cover today,

88
00:05:33,260 --> 00:05:34,630
so I am going to go relatively fast.

89
00:05:34,780 --> 00:05:35,470
If anything is unclear,

90
00:05:35,650 --> 00:05:38,470
just stop, ask questions,then I will slow down.

91
00:05:38,520 --> 00:05:40,690
Otherwise, I will take this as all completely obvious

92
00:05:40,720 --> 00:05:42,870
and I can keep going at full speed.

93
00:05:44,780 --> 00:05:51,970
The convention, this is intuitive,

94
00:05:51,970 --> 00:05:55,290
I guess, if you do some macro programming or something,

95
00:05:57,450 --> 00:05:59,650
but it's a bit more mathematical.

96
00:06:07,710 --> 00:06:09,790
We have defined big O-notation

97
00:06:10,110 --> 00:06:12,600
and it equals big O of something.

98
00:06:15,890 --> 00:06:17,680
And so we have only defined big O

99
00:06:17,920 --> 00:06:21,210
when on the equal sign we have big O of some function.

100
00:06:21,450 --> 00:06:23,700
But it is useful to have some general expression

101
00:06:23,700 --> 00:06:25,720
on the right-hand side that involves big O.

102
00:06:25,840 --> 00:06:35,110
For example, let's say we have f(n) = n^3 +O(n^2).

103
00:06:37,400 --> 00:06:40,000
This is attempting to get an error bound.

104
00:06:40,020 --> 00:06:42,450
This is saying f(n) is basically n^3

105
00:06:42,500 --> 00:06:45,260
but there are these lower order terms that are O(n^2).

106
00:06:45,500 --> 00:06:51,190
And so this means that there is a function,

107
00:06:56,450 --> 00:07:02,400
shorthand for a function, h(n) which is in O(n^2)

108
00:07:03,010 --> 00:07:14,810
or equals O(n^2) such that f(n)=n^3 + h(n).

109
00:07:16,510 --> 00:07:19,090
It is saying that there are some lower order terms

110
00:07:19,150 --> 00:07:21,740
that are bounded above by some constant times n^2

111
00:07:21,750 --> 00:07:23,060
for sufficiently large n,

112
00:07:23,560 --> 00:07:24,770
and that is what is here.

113
00:07:25,290 --> 00:07:28,080
And then f(n) equals, now this is a true equality,

114
00:07:28,180 --> 00:07:30,020
n^3 plus that error term.

115
00:07:30,310 --> 00:07:32,360
This is very useful here.

116
00:07:32,480 --> 00:07:35,040
Essentially, I am expressing what the lead constant is

117
00:07:35,170 --> 00:07:36,020
and then saying well,

118
00:07:36,020 --> 00:07:38,370
there is other stuff and it's all at most n^2.

119
00:07:38,710 --> 00:07:41,730
Saying that f(n) therefore is also order n^3,

120
00:07:41,750 --> 00:07:43,900
but that is a bit weaker of a statement.

121
00:07:44,280 --> 00:07:45,740
This is a bit more refined.

122
00:07:45,950 --> 00:07:48,410
We won't need to use this too often, but it is useful.

123
00:07:48,460 --> 00:07:49,420
Sometimes we will see,

124
00:07:49,450 --> 00:07:52,100
like in last class we even had a big O inside a summation.

125
00:07:52,320 --> 00:07:53,570
So, you can use them all over the place.

126
00:07:53,610 --> 00:07:57,170
The point is they represent some function in that set.

127
00:07:59,190 --> 00:08:02,970
A bit less intuitive, and this is more subtle,

128
00:08:06,040 --> 00:08:08,540
is what it means to have big O on the left-hand side.

129
00:08:09,050 --> 00:08:10,320
It means the same thing,

130
00:08:10,320 --> 00:08:16,160
but there is some convention what equality means.

131
00:08:16,250 --> 00:08:19,310
And this is why equal sign is asymmetric.

132
00:08:20,510 --> 00:08:24,110
You should read equals like "Is".

133
00:08:25,340 --> 00:08:30,080
Is means that everything over here is something over here.

134
00:08:30,250 --> 00:08:32,760
So, there is an implicit for all on the left-hand side

135
00:08:32,800 --> 00:08:34,380
and there exists on the right-hand side.

136
00:08:34,440 --> 00:08:35,580
This is a true statement.

137
00:08:35,610 --> 00:08:40,180
Anything that is n^2 + O(n) is also O(n^2),

138
00:08:40,510 --> 00:08:41,910
but not the other way around.

139
00:08:42,170 --> 00:08:44,320
So, this is a bit asymmetric.

140
00:08:47,750 --> 00:08:50,230
If you think about it, this is pretty intuitive

141
00:08:50,940 --> 00:08:56,370
but it is subtle so you should be careful.

142
00:09:13,280 --> 00:09:16,580
This says for any expansion of the macro on the left-hand side,

143
00:09:17,810 --> 00:09:19,800
which should be f(n),

144
00:09:21,080 --> 00:09:22,850
there is an expansion of the macro

145
00:09:22,870 --> 00:09:25,220
on the right-hand side such that we get equality.

146
00:09:27,970 --> 00:09:29,670
And what this allows you to do is

147
00:09:29,700 --> 00:09:32,110
if you have a chain of equal signs relations,

148
00:09:32,190 --> 00:09:33,040
a chain of "Is"S,

149
00:09:33,130 --> 00:09:35,570
then the very first one is equal to

150
00:09:35,640 --> 00:09:37,270
or bounded by the very last one.

151
00:09:37,330 --> 00:09:39,530
So, you can chain equal signs the way you normally would.

152
00:09:39,530 --> 00:09:43,220
You just cannot flip them around. Good.

153
00:09:43,680 --> 00:09:48,410
So, that's big O-notation. Any questions about that?

154
00:09:55,870 --> 00:09:58,380
So, big O is great for expressing upper bounds.

155
00:09:58,760 --> 00:10:01,520
But we also want to talk about lower bounds.

156
00:10:02,440 --> 00:10:04,800
For algorithms, we usually care

157
00:10:04,800 --> 00:10:06,360
about upper bounds on their running time.

158
00:10:06,430 --> 00:10:09,830
Running times at most n^2 is at most n log n up to big O,

159
00:10:10,680 --> 00:10:12,600
but sometimes we need to express functions

160
00:10:12,600 --> 00:10:14,270
that are at least some quantity.

161
00:10:15,190 --> 00:10:17,110
For example, we will show that sorting requires

162
00:10:17,110 --> 00:10:19,720
at least n log n time in some model.

163
00:10:19,870 --> 00:10:21,980
So, we need some other notation for that.

164
00:10:23,960 --> 00:10:28,150
And the notation is big Omega-notation.

165
00:10:30,960 --> 00:10:33,950
And it is pretty symmetric.

166
00:10:34,390 --> 00:10:37,550
I will just write out the set definition here.

167
00:10:38,720 --> 00:10:42,200
And we are going to write f(n)=big Omega g(n) to mean

168
00:10:42,200 --> 00:10:46,280
f(n) is at least some constant times g(n) --

169
00:10:53,230 --> 00:10:54,880
for sufficiently large n

170
00:11:06,710 --> 00:11:11,490
So, I am basically just reversing the inequality relation

171
00:11:11,500 --> 00:11:14,370
between f and g, nothing surprising,

172
00:11:15,410 --> 00:11:16,800
just to have it there.

173
00:11:19,340 --> 00:11:20,650
A random example,

174
00:11:20,680 --> 00:11:22,550
and now we will get a little bit more sophisticated,

175
00:11:22,780 --> 00:11:25,790
root n= big Omega log(n).

176
00:11:25,790 --> 00:11:28,840
And you should read this that up to constant factors root n

177
00:11:28,880 --> 00:11:31,780
is at least log n for sufficiently large n.

178
00:11:32,910 --> 00:11:37,480
So, omega sort of corresponds to greater than or equal to.

179
00:11:37,600 --> 00:11:40,010
Let me give you some analogies.

180
00:11:43,500 --> 00:11:46,600
We have big O, we have big omega,

181
00:11:46,970 --> 00:11:49,220
this is less than or equal to,

182
00:11:49,450 --> 00:11:50,840
this is greater than or equal to.

183
00:11:50,880 --> 00:11:53,660
And I am going to fill in some more here in a moment.

184
00:12:08,770 --> 00:12:11,650
It's nice to have all the usual operators we have.

185
00:12:11,710 --> 00:12:12,980
Normally we have strict less than,

186
00:12:12,980 --> 00:12:14,940
strict greater than and equal sign.

187
00:12:15,100 --> 00:12:18,850
And we want those sort of analogs in the asymptotic world

188
00:12:18,890 --> 00:12:20,450
where we ignore constant factors

189
00:12:20,560 --> 00:12:22,660
and ignore lower order terms.

190
00:12:22,880 --> 00:12:26,330
We have, for example, big Theta.

191
00:12:26,440 --> 00:12:27,930
This is a capital theta

192
00:12:28,230 --> 00:12:31,050
which means you write the horizontal bar in the middle

193
00:12:31,050 --> 00:12:32,390
as opposed to all the way through.

194
00:12:32,580 --> 00:12:35,900
I didn't invent Greek, so that is the way it is.

195
00:12:36,930 --> 00:12:39,310
Theta means that you are less than or equal to

196
00:12:39,320 --> 00:12:40,930
and you are greater than or equal to

197
00:12:41,720 --> 00:12:43,150
up to constant factors,

198
00:12:44,010 --> 00:12:46,160
so it is the inner section of these two sets,

199
00:12:46,180 --> 00:12:47,740
big O and big Omega.

200
00:12:53,290 --> 00:12:54,700
That is sort of like equal sign

201
00:12:54,790 --> 00:12:56,250
but, of course,this is very different.

202
00:12:56,450 --> 00:13:00,070
You have things like n^2 is big Theta of 2

203
00:13:00,230 --> 00:13:02,270
because you ignore constant factors,

204
00:13:02,330 --> 00:13:04,760
but all of these other relations,

205
00:13:04,770 --> 00:13:08,280
OK, n^2 + O = Theta,

206
00:13:08,970 --> 00:13:10,540
but this does not hold with theta

207
00:13:10,590 --> 00:13:12,650
because square root of n is really

208
00:13:12,700 --> 00:13:14,320
asymptotically bigger than log n.

209
00:13:14,650 --> 00:13:16,320
And some of the other examples

210
00:13:16,390 --> 00:13:21,180
we saw like n^2 versus n^3, those don't hold with T.

211
00:13:23,380 --> 00:13:28,650
And we have some strict notation

212
00:13:32,200 --> 00:13:38,850
which are the little o-notation and little omega-notation.

213
00:13:38,930 --> 00:13:41,530
There is no little theta because there is not notion

214
00:13:41,530 --> 00:13:44,730
of strict equality versus unstrict equality.

215
00:13:44,990 --> 00:13:47,790
Little o is going to correspond roughly to less than

216
00:13:48,020 --> 00:13:51,330
and little omega is going to correspond to greater than.

217
00:13:51,490 --> 00:13:54,170
This is a notation you will just have to get used to.

218
00:13:54,920 --> 00:13:58,560
And I am not going to define it precisely here

219
00:13:58,770 --> 00:14:00,730
because it is almost exactly the same.

220
00:14:00,930 --> 00:14:02,270
The difference is that instead of saying

221
00:14:02,270 --> 00:14:04,760
there exists constant c and n_o,

222
00:14:04,850 --> 00:14:07,140
you have to say for every constant c

223
00:14:07,310 --> 00:14:09,590
there exists a constant n_o.

224
00:14:12,410 --> 00:14:14,340
The relationship between f and g,

225
00:14:14,380 --> 00:14:24,740
this inequality must hold for all c instead of just for 1.

226
00:14:29,100 --> 00:14:31,930
And so n_o can now depend on c.

227
00:14:33,150 --> 00:14:36,900
You can assume that really n is sufficiently large,

228
00:14:36,940 --> 00:14:39,040
but this gives you a strict inequality.

229
00:14:39,070 --> 00:14:41,910
No matter what constant you put here, in front of g,

230
00:14:42,200 --> 00:14:44,080
let's say we are doing little o,

231
00:14:44,230 --> 00:14:45,990
No matter what constant you put here, in front of g,

232
00:14:46,140 --> 00:14:47,920
f will be still less than

233
00:14:48,020 --> 00:14:50,270
c times g for sufficiently large n.

234
00:14:51,420 --> 00:14:54,920
We have some random examples.

235
00:15:03,280 --> 00:15:05,030
We are again ignoring constants.

236
00:15:05,030 --> 00:15:08,870
n^2 is always less than n^3 for sufficiently large n.

237
00:15:09,040 --> 00:15:10,410
And it is a bit subtle here.

238
00:15:10,450 --> 00:15:13,490
I mean in order to prove something like this,

239
00:15:13,650 --> 00:15:17,210
it will become intuitive after you manipulate it a little bit.

240
00:15:17,300 --> 00:15:21,270
You have to figure out what n_o is in terms of c.

241
00:15:21,730 --> 00:15:25,520
I think it something like 2/c.

242
00:15:29,780 --> 00:15:32,740
If we have less than or equal to, that should be right.

243
00:15:32,740 --> 00:15:35,870
As long n is at least this big,

244
00:15:36,120 --> 00:15:38,360
no matter how small of a c,

245
00:15:38,440 --> 00:15:40,800
you should think of c here as being epsilon now,

246
00:15:40,860 --> 00:15:42,620
in the usual epsilon and deltas.

247
00:15:43,160 --> 00:15:45,610
No matter how small c gets,

248
00:15:45,680 --> 00:15:50,170
still I can bound n^2 in terms of n^3, upper bound,

249
00:15:50,620 --> 00:15:53,140
but whenever you have theta

250
00:15:53,170 --> 00:15:54,820
you do not have either of these relations.

251
00:15:55,000 --> 00:16:04,970
For example, n^2 = Theta(n^2) and it is not little o

252
00:16:05,280 --> 00:16:08,080
and it not little omega because it is exactly n^2.

253
00:16:08,230 --> 00:16:11,410
You will get some sense in order relation out of this,

254
00:16:11,470 --> 00:16:15,690
although there are some messy behaviors

255
00:16:16,450 --> 00:16:17,840
as you will see in your problem set.

256
00:16:18,760 --> 00:16:20,920
Any questions about asymptotic notation?

257
00:16:21,060 --> 00:16:22,470
That is the quick rundown.

258
00:16:22,690 --> 00:16:25,550
Now we are going to use it to solve some recurrences.

259
00:16:26,740 --> 00:16:29,610
Although we won't use it that much today,

260
00:16:29,660 --> 00:16:31,820
we will use it a lot more on Wednesday.

261
00:16:32,850 --> 00:16:33,690
OK.

262
00:16:51,600 --> 00:16:54,600
We will move onto the second topic of today,

263
00:16:54,620 --> 00:16:56,420
which is solving recurrences.

264
00:16:58,130 --> 00:16:59,960
You have probably solved some recurrences

265
00:16:59,960 --> 00:17:05,710
before in 6.042 or whatever discrete math class you have taken.

266
00:17:05,910 --> 00:17:08,680
We are going to do more and have some techniques here

267
00:17:08,720 --> 00:17:11,870
that are particularly useful for analyzing recursive algorithms,

268
00:17:12,410 --> 00:17:14,690
and we will see that mostly on Wednesday.

269
00:17:15,600 --> 00:17:18,370
There are three main methods

270
00:17:18,380 --> 00:17:22,340
that we are going to use here for solving recurrences.

271
00:17:23,260 --> 00:17:25,390
The first one is the substitution method.

272
00:17:27,720 --> 00:17:31,270
There is no general procedure for solving a recurrence.

273
00:17:31,340 --> 00:17:34,440
There is no good algorithm for solving recurrences,unfortunately.

274
00:17:34,440 --> 00:17:36,490
We just have a bunch of techniques.

275
00:17:36,500 --> 00:17:37,990
Some of them work some of the time,

276
00:17:38,200 --> 00:17:41,370
and if you are lucky yours will work for your recurrence,

277
00:17:41,540 --> 00:17:43,720
but it is sort of like solving an integral.

278
00:17:43,780 --> 00:17:45,280
You have to just know some of them,

279
00:17:45,300 --> 00:17:47,500
you have to know various methods for solving them.

280
00:17:47,540 --> 00:17:51,110
It is usually easy to check if you have the right answer.

281
00:17:51,110 --> 00:17:52,260
Just like with integrals,

282
00:17:52,290 --> 00:17:54,610
you just differentiate and say oh, I got the right answer.

283
00:17:54,890 --> 00:17:58,620
And that is essentially the idea of substitution method.

284
00:17:59,090 --> 00:18:01,140
Substitution method will always work,

285
00:18:02,510 --> 00:18:05,960
but unfortunately Step 1 is guess the answer.

286
00:18:06,240 --> 00:18:08,730
And you have to guess it correctly.

287
00:18:09,630 --> 00:18:11,310
That makes it a big difficult.

288
00:18:12,380 --> 00:18:14,780
You don't have to guess it completely.

289
00:18:15,000 --> 00:18:18,620
You can usually get away with not knowing the constant factors,

290
00:18:18,620 --> 00:18:19,730
which is a good thing because we don't

291
00:18:19,730 --> 00:18:21,420
really care about the constant factors.

292
00:18:21,670 --> 00:18:25,420
You guess the form.You say oh, it is going to be roughly n^2,

293
00:18:25,670 --> 00:18:28,540
and so it's some constant times n^2 presumably.

294
00:18:29,100 --> 00:18:29,830
So, you guess that.

295
00:18:29,840 --> 00:18:31,450
We are going to figure out the constants.

296
00:18:31,550 --> 00:18:35,000
You try to verify whether the recurrence

297
00:18:35,000 --> 00:18:39,370
satisfies this bound by induction,

298
00:18:39,410 --> 00:18:40,070
and that is the key.

299
00:18:40,070 --> 00:18:41,830
Substitution uses induction.

300
00:18:42,280 --> 00:18:45,500
And from that you usually get the constants for free.

301
00:18:45,680 --> 00:18:47,380
You figure out what the constants

302
00:18:47,460 --> 00:18:50,640
have to be in order to make this work.

303
00:18:51,300 --> 00:18:52,570
So, that is the general idea.

304
00:18:52,730 --> 00:18:54,650
You will see a few examples of this.

305
00:18:54,680 --> 00:18:56,810
Actually, the same example several times.

306
00:18:58,560 --> 00:19:04,140
Unfortunately,this is what you might call, I don't know.

307
00:19:06,080 --> 00:19:07,150
This is an algorithm,

308
00:19:07,180 --> 00:19:09,780
but it uses an oracle which is knowing the right answer.

309
00:19:09,820 --> 00:19:11,970
But sometimes it is not too hard to guess the answer.

310
00:19:13,100 --> 00:19:14,250
It depends.

311
00:19:14,360 --> 00:19:19,380
If you look at this recurrence, T = 4T(n/2) + n,

312
00:19:19,580 --> 00:19:22,440
we should implicitly always have some base case

313
00:19:22,830 --> 00:19:26,920
of T of some constant, usually 1 is a constant,

314
00:19:26,990 --> 00:19:28,870
so we don't really care about the base case.

315
00:19:29,000 --> 00:19:31,000
For algorithms that is always the case.

316
00:19:32,460 --> 00:19:33,780
And we want to solve this thing.

317
00:19:34,550 --> 00:19:37,210
Does anyone have a guess to what the solution is?

318
00:19:37,390 --> 00:19:38,870
Ideally someone who doesn't already know

319
00:19:38,870 --> 00:19:40,420
how to solve this recurrence.

320
00:19:41,280 --> 00:19:43,490
OK. How many people know how to solve this recurrence?

321
00:19:43,800 --> 00:19:46,440
A few, OK.

322
00:19:46,620 --> 00:19:49,400
And, of the rest, any guesses?

323
00:19:50,170 --> 00:19:52,240
If you look at what is going on here,

324
00:19:52,400 --> 00:19:55,970
here you have T(n/2) and let's ignore this term more or less.

325
00:19:57,180 --> 00:20:00,940
We have n/2 here. If we double n and get T(n)

326
00:20:01,050 --> 00:20:03,470
then we multiply the value by 4.

327
00:20:03,530 --> 00:20:04,430
And then there is this additive end,

328
00:20:04,430 --> 00:20:06,190
but that doesn't matter so much.

329
00:20:06,280 --> 00:20:08,750
What function do you know that when you double the argument

330
00:20:08,840 --> 00:20:10,920
the output goes up by a factor of 4?

331
00:20:12,530 --> 00:20:14,950
Sorry? n^2,yeah.

332
00:20:15,040 --> 00:20:19,760
You should think n^2 and you would be right.

333
00:20:19,890 --> 00:20:21,780
But we won't prove n^2 yet.

334
00:20:21,780 --> 00:20:23,940
Let's prove something simpler,

335
00:20:24,050 --> 00:20:25,230
because it turns out proving that

336
00:20:25,230 --> 00:20:27,210
it is at most n^2 is a bit of a pain.

337
00:20:27,800 --> 00:20:29,750
We will see that in just a few minutes.

338
00:20:30,030 --> 00:20:33,760
But let's guess that T = O(n³) first

339
00:20:33,800 --> 00:20:37,200
because that will be easier to prove by induction.

340
00:20:37,200 --> 00:20:39,180
You sort of see how it is done in the easy case,

341
00:20:39,420 --> 00:20:42,850
and then we will actually get the right answer, n^2, later.

342
00:20:43,210 --> 00:20:46,250
I need to prove. What I am going to do is guess that

343
00:20:46,250 --> 00:20:50,920
T is some constant times n^3 at most,

344
00:20:51,010 --> 00:20:53,150
so I will be a little more precise.

345
00:20:53,160 --> 00:20:56,850
I cannot use the big O-notation in the substitution method

346
00:20:56,880 --> 00:21:02,790
so I have to expand it out to use constants.

347
00:21:04,030 --> 00:21:07,480
I will show you why in a little bit,

348
00:21:09,880 --> 00:21:12,980
but let me just tell you at a high level what is important

349
00:21:13,080 --> 00:21:14,990
in not using big O-notation.

350
00:21:15,100 --> 00:21:16,510
Big O-notation is great

351
00:21:16,640 --> 00:21:20,410
if you have a finite chain of big O relations, you know,

352
00:21:20,490 --> 00:21:25,650
n^2 is big O(n³) is big O(n^4) is big O(n^4) is big O(n^4).

353
00:21:25,670 --> 00:21:29,210
That is all true. And so you get that n^2 is big O.

354
00:21:29,530 --> 00:21:32,470
But if you have an infinite chain of those relations

355
00:21:32,650 --> 00:21:35,490
then the first thing is not big O of the last thing.

356
00:21:35,620 --> 00:21:37,310
You have to be very careful.

357
00:21:37,530 --> 00:21:41,590
For example, this is a total aside on the lecture notes.

358
00:21:41,740 --> 00:21:45,400
Suppose you want to prove that n = O(1).

359
00:21:45,700 --> 00:21:46,620
This is a great relation.

360
00:21:46,620 --> 00:21:49,640
If it were true, every algorithm would have constant running time

361
00:21:49,850 --> 00:21:51,000
This is not true.

362
00:21:52,910 --> 00:21:56,710
Not in Wayne's World notation.

363
00:21:57,770 --> 00:22:01,130
You could "Prove this by induction"

364
00:22:01,130 --> 00:22:04,650
By saying well, base case is 1 = O(1).

365
00:22:04,700 --> 00:22:06,780
OK, that is true.

366
00:22:06,890 --> 00:22:08,530
And then the induction step as well,

367
00:22:08,600 --> 00:22:14,290
if I know that n-1, so let's suppose that n-1 =O(1),

368
00:22:15,130 --> 00:22:20,930
well, that implies that n, which is +1,

369
00:22:21,220 --> 00:22:27,610
if this is O(1) and 1 = O(1), the whole thing is O.

370
00:22:27,820 --> 00:22:29,110
And that is true.

371
00:22:29,170 --> 00:22:33,890
If you knew that = O and 1 = O then their sum is also O,

372
00:22:34,110 --> 00:22:35,820
but this is a false proof.

373
00:22:35,820 --> 00:22:37,860
You cannot induct over big Os.

374
00:22:38,040 --> 00:22:39,740
What is going on here is that the constants

375
00:22:39,740 --> 00:22:41,480
that are implicit in here are changing.

376
00:22:41,570 --> 00:22:42,530
Here you have some big O of 1,

377
00:22:42,530 --> 00:22:44,110
here you have some big O of 1.

378
00:22:44,240 --> 00:22:47,000
You are probably doubling the constant in there

379
00:22:47,040 --> 00:22:48,720
every time you do this relation.

380
00:22:48,720 --> 00:22:50,680
If you have a finite number of doubling of constants,

381
00:22:50,720 --> 00:22:52,040
no big deal, it is just a constant,

382
00:22:52,070 --> 00:22:53,880
two the power number of doublings.

383
00:22:54,090 --> 00:22:56,880
But here you are doing n doublings and that is no good.

384
00:22:57,380 --> 00:23:00,710
The constant is now depending on n.

385
00:23:00,780 --> 00:23:02,930
So, we are avoiding this kind of problem

386
00:23:03,110 --> 00:23:04,610
by writing out the constant.

387
00:23:04,650 --> 00:23:06,830
We have to make sure that constant doesn't change.

388
00:23:08,170 --> 00:23:08,990
Good.

389
00:23:10,860 --> 00:23:12,240
Now I have written out the constant.

390
00:23:12,240 --> 00:23:12,890
I should be safe.

391
00:23:12,920 --> 00:23:16,810
I am assuming it for all k less than n,

392
00:23:16,910 --> 00:23:19,290
now I have to prove it for k equal to n.

393
00:23:19,670 --> 00:23:25,400
I am going to take T and just expand it.

394
00:23:25,500 --> 00:23:26,660
I am going to do the obvious thing.

395
00:23:26,660 --> 00:23:28,870
I have this recurrence how to expand T.

396
00:23:28,930 --> 00:23:30,010
Then it involves T.

397
00:23:30,010 --> 00:23:32,710
And I know some fact about T

398
00:23:32,730 --> 00:23:35,040
because n/2 is less than n.

399
00:23:35,650 --> 00:23:42,080
So, let's expand. T = 4T + n.

400
00:23:42,700 --> 00:23:44,890
And now I have an upper bound on this thing

401
00:23:45,020 --> 00:23:47,430
from the induction hypothesis.

402
00:23:48,290 --> 00:23:58,530
This is at most 4 times c times the argument cubed plus n.

403
00:24:05,990 --> 00:24:08,960
I have a feeling that by the end of the lecture

404
00:24:09,510 --> 00:24:12,570
These blackboards will be totally stucked

405
00:24:16,470 --> 00:24:18,380
Oh, it's not going up. Ok.

406
00:24:22,630 --> 00:24:24,360
It's ok. I will use half of the board.

407
00:24:31,800 --> 00:24:33,850
I'd like to say it's from my super human strenth.

408
00:24:33,850 --> 00:24:36,460
But I believe it's from the quality of the blackboards,

409
00:24:37,490 --> 00:24:38,780
or their hinges.

410
00:24:40,520 --> 00:24:43,390
Continuing on here. Let's expand this a little bit.

411
00:24:44,320 --> 00:24:51,870
We have n cubed over 2 cubed.

412
00:24:52,000 --> 00:24:55,640
Two cubed is 8,so 4 over 8 is a half.

413
00:24:56,070 --> 00:25:03,420
So, we have a half times C times n cube + n

414
00:25:05,100 --> 00:25:08,270
And what I would like this to be is,

415
00:25:08,390 --> 00:25:10,160
so at the bottom where I would like to go

416
00:25:10,200 --> 00:25:13,990
is that this is at most cn3.

417
00:25:15,180 --> 00:25:17,630
That is what I would like to prove to reestablish

418
00:25:17,630 --> 00:25:19,480
the induction hypothesis for n.

419
00:25:19,840 --> 00:25:22,200
What I will do,in order to see when that is case,

420
00:25:22,290 --> 00:25:25,420
is just write this as what I want,

421
00:25:25,800 --> 00:25:31,250
so this is sort of the desired value,cn3,

422
00:25:31,300 --> 00:25:32,810
minus whatever I don't want.

423
00:25:32,810 --> 00:25:36,630
This is called the residual.

424
00:25:41,110 --> 00:25:42,770
Now I have to actually figure this out.

425
00:25:42,870 --> 00:25:45,680
Let's see. We have cn^3, but only a half n^3 here,

426
00:25:45,680 --> 00:25:51,240
so I need to subtract off 1/2n^3 to get that lead term correct.

427
00:25:51,240 --> 00:25:52,890
And then I have plus n and there is a minus here,

428
00:25:52,890 --> 00:25:54,910
so it is minus n.

429
00:25:55,750 --> 00:25:57,480
And that is the residual.

430
00:25:57,580 --> 00:25:59,490
In order for this to be at most this,

431
00:25:59,720 --> 00:26:02,530
I need that the residual s non-negative.

432
00:26:02,770 --> 00:26:10,660
This is if the residual part is greater than or equal to zero,

433
00:26:11,750 --> 00:26:15,470
which is pretty easy to do because here I have control over c.

434
00:26:15,650 --> 00:26:17,830
I get to pick c to be whatever I want.

435
00:26:18,050 --> 00:26:22,560
And, as long as c is at least, oh, I don't know, 2,

436
00:26:22,660 --> 00:26:25,700
then this is a 1 at least.

437
00:26:25,700 --> 00:26:28,590
Then I have n^3 should be greater than or equal to n.

438
00:26:28,610 --> 00:26:30,130
And that is always the case.

439
00:26:30,670 --> 00:26:38,250
So this is, for example, this is true if c is at least 1,

440
00:26:38,250 --> 00:26:41,250
and I don't think it matters what n is

441
00:26:41,320 --> 00:26:45,990
but let's say n is at least 1 just for kicks.

442
00:26:47,600 --> 00:26:50,590
So, what we have done is proved

443
00:26:50,590 --> 00:26:54,210
that T is at most some constant times n^3.

444
00:26:54,210 --> 00:26:56,680
And the constant is like 1.

445
00:26:58,700 --> 00:27:01,090
So, that is an upper bound. It is not a tight upper bound.

446
00:27:01,160 --> 00:27:03,920
We actually believed that it is n^2, and it is,

447
00:27:04,160 --> 00:27:06,380
but you have to be a little careful.

448
00:27:06,400 --> 00:27:07,900
This does not mean that the answer is n^3.

449
00:27:07,900 --> 00:27:10,890
It just means that at most is O(n^3).

450
00:27:11,180 --> 00:27:13,000
And this is a proof by induction.

451
00:27:13,000 --> 00:27:15,790
Now, technically I should have put a base case in this induction,

452
00:27:16,050 --> 00:27:17,390
so there is a little bit missing.

453
00:27:17,440 --> 00:27:21,360
The base case is pretty easy because T(1) is some constant,

454
00:27:22,310 --> 00:27:24,560
but it will sort of influence things.

455
00:27:24,650 --> 00:27:31,450
If the base case T is some constant.

456
00:27:31,610 --> 00:27:34,950
And what we need is that it is at most c times one cubed,

457
00:27:34,950 --> 00:27:36,200
which is c.

458
00:27:37,190 --> 00:27:38,530
And that will be true as long as

459
00:27:38,530 --> 00:27:40,950
you choose c to be sufficiently large.

460
00:27:41,170 --> 00:27:48,640
So, this is true if c is chosen sufficiently large.

461
00:27:48,700 --> 00:27:50,380
Now, we don't care about constants,

462
00:27:50,580 --> 00:27:53,220
but the point is just to be a little bit careful.

463
00:27:53,330 --> 00:27:58,710
It is not true that T is at most 1 times n^2,

464
00:27:58,860 --> 00:28:01,000
even though here all we need is that c is at least 1.

465
00:28:01,020 --> 00:28:01,880
For the base case to work,

466
00:28:01,880 --> 00:28:05,770
c actually might have to be a hundred or whatever T is.

467
00:28:06,290 --> 00:28:08,110
So, be a little bit careful there.

468
00:28:09,590 --> 00:28:11,700
It doesn't really affect the answer, usually it won't

469
00:28:11,830 --> 00:28:14,460
because we have very simple base cases here.

470
00:28:14,970 --> 00:28:24,500
OK, so let's try to prove the tight bound of O(n^2).

471
00:28:27,370 --> 00:28:28,630
I am not going to prove an omega bound,

472
00:28:28,630 --> 00:28:30,360
but you can prove an omega n squared bound

473
00:28:30,360 --> 00:28:32,340
as well using substitution method.

474
00:28:34,060 --> 00:28:35,770
I will just be satisfied for now

475
00:28:35,870 --> 00:28:39,900
proving an upper bound of n squared.

476
00:28:40,750 --> 00:28:48,780
Let's try to prove that T,this is the same recurrence,

477
00:28:48,820 --> 00:28:50,810
I want to prove that it is O.

478
00:28:52,780 --> 00:28:56,020
I am going to do the same thing.

479
00:28:56,100 --> 00:28:58,900
And I will write a bit faster because this is basically copying.

480
00:29:04,550 --> 00:29:06,850
Except now, instead of three, I have two.

481
00:29:07,450 --> 00:29:16,920
Then I have T = 4T + n. I expand this T(n/2).

482
00:29:17,030 --> 00:29:23,780
This is at most 4c(n/2)^2 + n.

483
00:29:23,780 --> 00:29:25,960
And now, instead of have 2 cubed,

484
00:29:25,960 --> 00:29:28,140
I have 2 squared, which is only 4.

485
00:29:28,450 --> 00:29:32,910
The fours cancel. I get cn^2 + n.

486
00:29:33,480 --> 00:29:36,480
And if you prefer to write it as desired minus residual,

487
00:29:36,580 --> 00:29:39,570
then I have cn^2 - n.

488
00:29:39,670 --> 00:29:43,910
And I want this to be non-negative.

489
00:29:45,960 --> 00:29:48,850
And it is damn hard for minus n to be non-negative.

490
00:29:48,850 --> 00:29:50,650
If n is zero we are happy,

491
00:29:50,800 --> 00:29:52,520
but unfortunately this is an induction on n.

492
00:29:52,520 --> 00:29:55,720
It's got to hold for all n greater than or equal to 1.

493
00:29:57,230 --> 00:30:03,240
This is not less than or equal to cn^2.

494
00:30:03,330 --> 00:30:08,030
Notice the temptation is to write that this equals O,

495
00:30:09,420 --> 00:30:10,940
which is true for this one step.

496
00:30:11,750 --> 00:30:15,270
cn^2 -(-n) , well, these are both order n,

497
00:30:15,470 --> 00:30:17,480
or this is order n, this is order n squared.

498
00:30:17,540 --> 00:30:19,840
Certainly this thing is O(n^2), that is true,

499
00:30:20,100 --> 00:30:22,050
but it is not completing the induction.

500
00:30:22,140 --> 00:30:23,660
To complete the induction, you have to prove

501
00:30:23,740 --> 00:30:26,790
the induction hypothesis for n with this constant c.

502
00:30:27,020 --> 00:30:29,460
Here you are getting a constant c of like c + 1,

503
00:30:30,640 --> 00:30:31,970
which is not good.

504
00:30:31,970 --> 00:30:35,720
This is true but useless.

505
00:30:36,700 --> 00:30:40,070
It does not finish the induction,

506
00:30:40,200 --> 00:30:41,610
so you can sort of ignore that.

507
00:30:42,540 --> 00:30:43,830
This proof doesn't work,

508
00:30:43,900 --> 00:30:45,420
which is kind of annoying because we feel,

509
00:30:45,420 --> 00:30:47,800
in our heart of hearts, that T = n^2.

510
00:30:48,780 --> 00:30:52,750
It turns out to fix this you need to express T

511
00:30:52,750 --> 00:30:54,390
in a slightly different form.

512
00:30:54,440 --> 00:30:56,850
This is, again, divine inspiration.

513
00:30:57,030 --> 00:30:59,110
And, if you have a good connection to some divinity,

514
00:30:59,220 --> 00:31:00,220
you are all set.

515
00:31:00,480 --> 00:31:06,260
But it is a little bit harder for the rest of us mere mortals.

516
00:31:07,720 --> 00:31:11,130
It turns out,and maybe you could guess this,

517
00:31:13,030 --> 00:31:17,610
that the idea is we want to strengthen the induction hypothesis.

518
00:31:17,680 --> 00:31:19,950
We assumed this relatively weak thing,

519
00:31:20,000 --> 00:31:22,740
T is less than or equal to some constant times k^2.

520
00:31:22,780 --> 00:31:24,660
We didn't know what the constant was, that is fine,

521
00:31:24,710 --> 00:31:26,790
but we assumed that there were no lower order terms.

522
00:31:26,830 --> 00:31:28,500
I want to look at lower order terms.

523
00:31:28,810 --> 00:31:29,920
Maybe they play a role.

524
00:31:30,180 --> 00:31:33,230
And if you look at this progression you say,

525
00:31:33,320 --> 00:31:35,310
oh, well, I am getting something like n^2

526
00:31:35,390 --> 00:31:37,200
and the constants are pretty damn tight.

527
00:31:37,200 --> 00:31:40,370
I mean the fours are canceling and the c just is preserved.

528
00:31:40,410 --> 00:31:42,990
How am I going to get rid of this lower order term plus n?

529
00:31:43,290 --> 00:31:46,700
Well, maybe I could subtract off a linear term in here and,

530
00:31:46,790 --> 00:31:48,610
if I am lucky,it will cancel with this one.

531
00:31:48,850 --> 00:31:51,330
That is all the intuition we have at this point.

532
00:31:51,570 --> 00:31:52,660
It turns out it works.

533
00:31:53,920 --> 00:32:00,590
We look at T and this is 4T + n as usual.

534
00:32:00,870 --> 00:32:05,770
Now we expand a slightly messier form.

535
00:32:05,880 --> 00:32:15,730
We have 4 + n.

536
00:32:16,430 --> 00:32:20,620
This part is the same because the fours cancel again.

537
00:32:20,720 --> 00:32:23,150
So, we get c_1*n^2, which is good.

538
00:32:23,150 --> 00:32:25,280
I mean that is sort of the form we want.

539
00:32:25,500 --> 00:32:28,270
Then we have something times n, so let's figure it out.

540
00:32:28,340 --> 00:32:29,880
We have a plus 1 times n,

541
00:32:29,880 --> 00:32:37,870
so let's write it 1 minus c_2 over 2 times n.

542
00:32:38,040 --> 00:32:39,220
Oops, got that wrong.

543
00:32:39,220 --> 00:32:44,620
There is four times a two so, in fact, the two is upstairs.

544
00:32:48,250 --> 00:32:50,080
Let me double check. Right.

545
00:32:51,150 --> 00:32:54,700
OK. Now we can write this as desired minus residual.

546
00:32:55,070 --> 00:32:56,650
And we have to be a little careful here

547
00:32:56,650 --> 00:32:59,300
because now we have a stronger induction hypothesis to prove.

548
00:32:59,330 --> 00:33:01,610
We don't just need it is at most c_1*n^2,

549
00:33:01,610 --> 00:33:02,580
which would be fine here

550
00:33:02,630 --> 00:33:04,510
because we could choose c_2 to be large,

551
00:33:04,790 --> 00:33:10,870
but what we really need is c_1*n^2 - c_2*n,

552
00:33:11,730 --> 00:33:13,740
and then minus some other stuff.

553
00:33:13,740 --> 00:33:16,440
This is, again,desired minus residual.

554
00:33:16,680 --> 00:33:18,360
And minus residual,let's see,

555
00:33:18,400 --> 00:33:25,260
we have a minus 1 and we have a minus c_2.

556
00:33:27,840 --> 00:33:30,440
That doesn't look so happy.

557
00:33:38,220 --> 00:33:40,710
Plus c_2, thank you,

558
00:33:41,860 --> 00:33:43,460
because that again looked awfully negative.

559
00:33:43,540 --> 00:33:45,370
It is plus c_2. I am getting my signs,

560
00:33:45,640 --> 00:33:49,490
there is a minus here and there is one minus here,so there we go.

561
00:33:51,350 --> 00:33:56,200
Again, I want my residual to be greater than or equal to zero.

562
00:33:58,860 --> 00:34:00,360
And if I have that

563
00:34:03,100 --> 00:34:06,980
I will be all set in making this inductive argument.

564
00:34:12,160 --> 00:34:13,990
Office hours start this week,

565
00:34:15,140 --> 00:34:16,810
in case you are eager to go.

566
00:34:17,930 --> 00:34:21,610
They are all held in some room in Building 24,

567
00:34:21,640 --> 00:34:23,960
which is roughly the midpoint between here and Stata,

568
00:34:24,200 --> 00:34:26,410
I think, for no particular reason.

569
00:34:29,570 --> 00:34:32,270
And you can look at the Web page for details on the office hours.

570
00:34:32,640 --> 00:34:33,680
Continuing along,

571
00:34:33,850 --> 00:34:39,300
when is c_2 - 1 going to be greater than or equal to zero?

572
00:34:39,650 --> 00:34:43,740
Well, that is true if c_2 is at least 1,

573
00:34:44,220 --> 00:34:45,030
which is no big deal.

574
00:34:45,030 --> 00:34:47,550
Again, we get to choose the constants however we want.

575
00:34:47,620 --> 00:34:49,480
It only has to hold for some choice of constants.

576
00:34:49,630 --> 00:34:51,740
So, we can set c_2 greater than or equal to 1.

577
00:34:52,070 --> 00:34:53,720
And then we are happy.

578
00:34:53,770 --> 00:34:57,320
That means this whole thing is

579
00:34:57,390 --> 00:35:01,160
less than or equal to c_1*n^2 - c_2*n

580
00:35:01,260 --> 00:35:04,900
if c_2 is greater than or equal to 1.

581
00:35:05,120 --> 00:35:06,030
It is kind of funny here.

582
00:35:06,190 --> 00:35:11,890
This finishes the induction, at least the induction step.

583
00:35:12,480 --> 00:35:14,120
We proved now that for any value of c_1,

584
00:35:14,370 --> 00:35:16,290
and provided c_2 is at least one.

585
00:35:16,780 --> 00:35:19,700
We have to be a little more careful that c_1

586
00:35:19,870 --> 00:35:22,170
does actually have to be sufficiently large.

587
00:35:22,230 --> 00:35:23,810
Any particular reason why?

588
00:35:30,100 --> 00:35:31,840
c_1 better not be negative, indeed.

589
00:35:31,920 --> 00:35:34,010
c_1 has to be positive for this to work,

590
00:35:34,440 --> 00:35:39,320
but it even has to be larger than positive depending.

591
00:35:39,750 --> 00:35:40,870
Sorry.I have been going so fast,

592
00:35:40,960 --> 00:35:41,990
I haven't asked you questions.

593
00:35:42,000 --> 00:35:43,390
Now you are caught off guard. Yeah?

594
00:35:43,930 --> 00:35:45,380
Because of the base case, exactly.

595
00:35:45,450 --> 00:35:55,070
So, the base case will have T is c_1 time 1 squared minus c_2,

596
00:35:56,170 --> 00:36:00,660
we want to prove that it is at most this,

597
00:36:00,790 --> 00:36:04,550
and T is some constant we have assumed.

598
00:36:04,820 --> 00:36:06,470
We need to choose c_1 to be

599
00:36:06,530 --> 00:36:08,690
sufficiently larger than c_2, in fact,

600
00:36:08,790 --> 00:36:10,160
so c_2 has to be at least 1.

601
00:36:10,360 --> 00:36:13,470
c_1 may have to be at least a hundred more than one

602
00:36:13,750 --> 00:36:15,390
if this is one hundred.

603
00:36:15,960 --> 00:36:22,940
so this will be true, if c_1 is sufficiently large.

604
00:36:23,980 --> 00:36:28,660
And sufficiently large now means with respect to c_2.

605
00:36:29,550 --> 00:36:31,110
You have to be a little bit careful,

606
00:36:31,190 --> 00:36:33,320
but in this case it doesn't matter.

607
00:36:35,320 --> 00:36:38,130
Any questions about the substitution method?

608
00:36:38,200 --> 00:36:39,880
That was the same example three times.

609
00:36:40,170 --> 00:36:42,680
In the end, it turned out we got the right answer.

610
00:36:43,080 --> 00:36:45,700
But we sort of had to know the answer in order to find it,

611
00:36:45,710 --> 00:36:46,880
which is a bit of a pain.

612
00:36:47,100 --> 00:36:48,700
It would certainly be nicer to just

613
00:36:48,800 --> 00:36:51,000
figure out the answer by some procedure,

614
00:36:51,000 --> 00:36:53,810
and that will be the next two techniques we talk about.

615
00:36:56,300 --> 00:36:59,080
Sorry? How would you prove a lower bound?

616
00:36:59,260 --> 00:37:01,400
I haven't tried it for this recurrence,

617
00:37:01,400 --> 00:37:03,920
but you should be able to do exactly the same form.

618
00:37:04,700 --> 00:37:12,560
Argue that T is greater than or equal to c_1*n^2 - c_2*n.

619
00:37:12,640 --> 00:37:14,950
I didn't check whether that particular form will work,

620
00:37:15,000 --> 00:37:15,860
but I think it does.

621
00:37:18,630 --> 00:37:19,730
Try it.

622
00:37:21,250 --> 00:37:22,830
These other methods will give you,

623
00:37:22,850 --> 00:37:24,690
in some sense, upper and lower bounds

624
00:37:24,850 --> 00:37:26,430
if you are a little bit careful.

625
00:37:26,620 --> 00:37:27,960
But, to really check things,

626
00:37:27,960 --> 00:37:30,050
you pretty much have to do the substitution method.

627
00:37:30,120 --> 00:37:32,430
And you will get some practice with that.

628
00:37:32,540 --> 00:37:34,440
Usually we only care about upper bounds.

629
00:37:34,580 --> 00:37:37,560
Proving upper bounds like this is what we will focus on,

630
00:37:37,610 --> 00:37:39,060
but occasionally we need lower bounds.

631
00:37:40,010 --> 00:37:41,580
It is always nice to know that you have the right answer

632
00:37:41,580 --> 00:37:43,760
by proving a matching lower bound.

633
00:37:49,390 --> 00:37:51,930
The next method we will talk about

634
00:37:53,560 --> 00:37:54,960
is the recursion-tree method.

635
00:37:55,170 --> 00:37:58,820
And it is a particular way of adding up a recurrence,

636
00:37:59,540 --> 00:38:01,880
and it is my favorite way.

637
00:38:02,080 --> 00:38:07,090
It usually just works. That's the great thing about it.

638
00:38:07,250 --> 00:38:08,880
It provides you intuition for free.

639
00:38:09,000 --> 00:38:10,880
It tells you what the answer is pretty much.

640
00:38:11,000 --> 00:38:13,250
It is slightly nonrigorous,

641
00:38:13,320 --> 00:38:14,520
this is a bit of a pain,

642
00:38:14,570 --> 00:38:16,330
so you have to be really careful when you apply it.

643
00:38:16,370 --> 00:38:18,140
Otherwise, you might get the wrong answer.

644
00:38:18,340 --> 00:38:20,510
Because it involves dot, dot, dots,

645
00:38:20,670 --> 00:38:23,670
our favorite three characters,

646
00:38:23,850 --> 00:38:26,770
but dot, dot, dots are always a little bit nonrigorous

647
00:38:26,930 --> 00:38:28,030
so be careful.

648
00:38:28,750 --> 00:38:30,780
Technically, what you should do is find out

649
00:38:30,780 --> 00:38:32,590
what the answer is with recursion-tree method.

650
00:38:32,740 --> 00:38:34,960
Then prove that it is actually right with the substitution method.

651
00:38:35,960 --> 00:38:37,660
Usually that is not necessary,

652
00:38:37,840 --> 00:38:39,350
but you should at least have in your mind

653
00:38:39,400 --> 00:38:41,620
that that is required rigorously.

654
00:38:41,760 --> 00:38:43,580
And probably the first few recurrences you solve,

655
00:38:43,580 --> 00:38:44,780
you should do it that way.

656
00:38:44,880 --> 00:38:46,700
When you really understand the recursion-tree method,

657
00:38:46,700 --> 00:38:49,740
you can be a little bit more sloppy

658
00:38:49,920 --> 00:38:51,420
if you are really sure you have the right answer.

659
00:38:51,480 --> 00:38:53,750
Let's do an example.

660
00:38:53,810 --> 00:39:00,100
We saw recursion trees very briefly last time with mergesort

661
00:39:00,420 --> 00:39:02,480
as the intuition why it was n log n.

662
00:39:03,880 --> 00:39:07,300
And, if you took an example like the one we just did

663
00:39:07,310 --> 00:39:09,380
with the recursion-tree method, it is dead simple.

664
00:39:09,840 --> 00:39:11,780
Just to make our life harder,

665
00:39:11,930 --> 00:39:13,930
let's do a more complicated recursion.

666
00:39:14,020 --> 00:39:15,970
Here we imagine we have some algorithm.

667
00:39:15,970 --> 00:39:17,430
It starts with a problem size n,

668
00:39:17,550 --> 00:39:19,940
it recursively solves a problem of size n/4,

669
00:39:20,180 --> 00:39:22,640
it then recursively solves a problem of size n/2,

670
00:39:22,830 --> 00:39:28,140
and it does n^2 work on the side with nonrecursive work.

671
00:39:28,680 --> 00:39:32,110
What is that? I mean that is a big less obvious, I would say.

672
00:39:34,250 --> 00:39:37,550
What we are going to do is draw a picture,

673
00:39:40,550 --> 00:39:44,830
and we are just going to expand out that recursion in tree form

674
00:39:54,110 --> 00:39:55,650
and then just add everything up.

675
00:39:57,560 --> 00:40:00,620
We want the general picture,

676
00:40:02,390 --> 00:40:05,820
and the general principle in the recursion-tree method

677
00:40:05,820 --> 00:40:07,420
is we just draw this as a picture.

678
00:40:07,440 --> 00:40:18,800
We say well, T_n equals the sum of n^2+T(n/4)+T(n/2).

679
00:40:19,920 --> 00:40:22,480
This is a weird way of writing a sum

680
00:40:22,550 --> 00:40:23,770
but why not write it that way.

681
00:40:24,030 --> 00:40:25,750
This is going to be a tree.

682
00:40:26,910 --> 00:40:28,370
And it is going to be a tree

683
00:40:28,400 --> 00:40:31,820
by recursively expanding each of these two leaves.

684
00:40:31,970 --> 00:40:33,920
I start by expanding T_n to this,

685
00:40:34,120 --> 00:40:36,680
then I keep expanding,expanding, expanding everything.

686
00:40:36,890 --> 00:40:38,630
Let's go one more step.

687
00:40:39,470 --> 00:40:46,270
We have this n^2, T(n/4), T(n/2)

688
00:40:46,270 --> 00:40:47,830
If we expand one more time,

689
00:40:48,140 --> 00:40:52,440
this is going to be n^2 plus two things.

690
00:40:52,800 --> 00:40:56,470
The first thing is going to be (n/4)^2,

691
00:40:56,470 --> 00:40:59,350
the second thing is going to be (n/2)^2.

692
00:40:59,380 --> 00:41:01,920
Plus their recursive branches.

693
00:41:01,960 --> 00:41:08,200
We have T(n/16) and T(n/8).

694
00:41:08,400 --> 00:41:10,590
Here my arithmetic shows thin.

695
00:41:11,070 --> 00:41:13,220
This better be the same, T(n/8),

696
00:41:13,220 --> 00:41:16,220
and this should be T(n/4), I believe.

697
00:41:16,590 --> 00:41:18,540
You just keep going forever, I mean,

698
00:41:18,610 --> 00:41:22,270
until you get down to the base case where T is a constant.

699
00:41:23,170 --> 00:41:26,210
So, I am now going to skip some steps and say dot, dot, dot.

700
00:41:26,430 --> 00:41:28,540
This is where you have to be careful.

701
00:41:30,440 --> 00:41:37,970
We have n^2, (n/4)^2, (n/2)^2.

702
00:41:38,060 --> 00:41:40,730
Now this is easy because I have already done them all.

703
00:41:40,920 --> 00:41:46,480
(n/16)^2, (n/8)^2, (n/8)^2 again,

704
00:41:48,280 --> 00:41:54,010
(n/4)^2 and et cetera, dot, dot, dot,

705
00:41:54,220 --> 00:41:55,950
of various levels of recursion here.

706
00:41:56,050 --> 00:41:59,000
At the bottom, we are going to get a bunch of constants.

707
00:41:59,000 --> 00:41:59,990
These are the leaves.

708
00:42:03,210 --> 00:42:05,740
I would like to know how many leaves there are.

709
00:42:07,350 --> 00:42:10,330
One challenge is how many leaves in this tree could there be?

710
00:42:10,410 --> 00:42:11,530
This is a bit subtle,

711
00:42:11,740 --> 00:42:14,550
unlike mergesort or unlike the previous recurrence we solved,

712
00:42:14,780 --> 00:42:16,430
the number of leaves here is a bit funny

713
00:42:16,510 --> 00:42:18,650
because we are recursing at different speeds.

714
00:42:18,780 --> 00:42:21,350
This tree is going to be much smaller than this tree.

715
00:42:21,560 --> 00:42:22,940
It is going to have smaller depth

716
00:42:23,000 --> 00:42:25,870
because it has already done down to n/16.

717
00:42:25,870 --> 00:42:28,040
Here it has only gone down to n/4.

718
00:42:28,860 --> 00:42:31,040
But how many leaves are there in this recursion tree?

719
00:42:33,980 --> 00:42:36,570
All I need is an upper bound,

720
00:42:37,410 --> 00:42:39,140
some reasonable upper bound.

721
00:42:39,260 --> 00:42:41,110
I can tell you it is at most n^10,

722
00:42:41,110 --> 00:42:42,990
but that is a bit unreasonable.

723
00:42:48,860 --> 00:42:50,410
It should be less than n, good.

724
00:42:50,500 --> 00:42:51,800
Why is it less than n?

725
00:42:55,440 --> 00:42:58,590
Exactly. I start with a problem of size n.

726
00:42:58,790 --> 00:43:02,500
And I recurse into a problem that n/4 and a problem that says n/2

727
00:43:02,540 --> 00:43:04,100
When I get down to one I stop.

728
00:43:04,470 --> 00:43:09,500
So, n/4 + n/2 = 3n/4, which is strictly less than n.

729
00:43:09,670 --> 00:43:12,040
So, definitely the total number

730
00:43:12,040 --> 00:43:13,370
of leaves has to be at most n.

731
00:43:13,670 --> 00:43:16,300
If I start out with n sort of stuff

732
00:43:16,450 --> 00:43:19,710
and get rid of a quarter of it and then recurse,

733
00:43:19,800 --> 00:43:22,730
it is definitely going to be less than n stuff at the bottom.

734
00:43:24,470 --> 00:43:26,430
So, strictly less than n leaves.

735
00:43:28,220 --> 00:43:30,650
At this point, I have done nothing interesting.

736
00:43:31,080 --> 00:43:35,300
And then the second cool idea in recursion trees

737
00:43:35,350 --> 00:43:37,950
is you don't just expand this tree and see what it looks like

738
00:43:38,020 --> 00:43:40,390
and then say, well, God, how the hell am I going to sum that?

739
00:43:40,620 --> 00:43:42,760
You sum it level by level.

740
00:43:42,970 --> 00:43:44,310
That is the only other idea.

741
00:43:44,520 --> 00:43:46,330
It usually works really, really well.

742
00:43:46,430 --> 00:43:48,190
Here it is a bit complicated

743
00:43:48,820 --> 00:43:52,260
and I have to think a bit to figure out n^2 is n^2.

744
00:43:52,410 --> 00:43:54,200
That is the first level. Easy.

745
00:43:54,430 --> 00:43:57,420
The second level, I have to think a lot harder.

746
00:43:57,440 --> 00:43:59,710
There are three kinds of mathematicians,

747
00:43:59,710 --> 00:44:01,470
those who can add and those who cannot,

748
00:44:02,290 --> 00:44:05,720
and I am the latter kind so I need your help.

749
00:44:07,250 --> 00:44:09,080
Can you add these things together?

750
00:44:09,190 --> 00:44:10,650
It's n^2 over something.

751
00:44:13,380 --> 00:44:20,750
Please? 5/16. Good, thanks.

752
00:44:20,750 --> 00:44:22,470
Now I really need your help.

753
00:44:22,520 --> 00:44:23,470
I think that one I could have done,

754
00:44:23,500 --> 00:44:25,290
but this one is a little bit harder.

755
00:44:25,290 --> 00:44:27,340
I will go look at my notes while you compute that.

756
00:44:33,390 --> 00:44:39,440
Any answers? 73/256.

757
00:44:39,570 --> 00:44:40,930
Anyone else confirm that?

758
00:44:41,990 --> 00:44:44,510
It seems a bit high to me.

759
00:44:45,610 --> 00:44:48,880
73 does not sound right to me. I can cheat.

760
00:44:49,600 --> 00:44:52,020
64? Closer.

761
00:44:54,330 --> 00:44:56,780
It is actually important that we get this right.

762
00:44:56,930 --> 00:44:58,590
The 256 is correct.

763
00:44:58,680 --> 00:45:03,230
I can tell. Everyone should know that 16^2= 256.

764
00:45:03,230 --> 00:45:04,300
We are computer scientists.

765
00:45:05,990 --> 00:45:08,970
25, good. We have two people saying 25,

766
00:45:09,030 --> 00:45:10,820
therefore it is correct by democracy.

767
00:45:11,810 --> 00:45:14,950
25 is also what my notes say, and I computed it at home.

768
00:45:15,230 --> 00:45:16,380
25 is the right answer.

769
00:45:16,380 --> 00:45:20,230
Now, did anyone notice something magical about this progression?

770
00:45:24,360 --> 00:45:26,080
It squares each time, good.

771
00:45:26,630 --> 00:45:29,640
And, if we were going to add these up, you might call it?

772
00:45:32,610 --> 00:45:34,460
A geometric series, very good.

773
00:45:34,520 --> 00:45:36,790
So, it turns out this is geometric.

774
00:45:37,260 --> 00:45:39,240
And we know how to sum geometric series,

775
00:45:39,240 --> 00:45:40,380
at least you should.

776
00:45:57,190 --> 00:45:58,420
We started n^2.

777
00:45:58,480 --> 00:45:59,820
We know that at the bottom,

778
00:46:00,030 --> 00:46:03,070
well, this is not quite a level, we get something like n,

779
00:46:03,320 --> 00:46:05,330
but we are decreasing geometrically.

780
00:46:06,300 --> 00:46:12,260
So, the total, I mean the solution to the recurrence

781
00:46:12,260 --> 00:46:14,180
is the sum of all the numbers in this tree.

782
00:46:14,230 --> 00:46:16,700
If we added it up level by level and then add up all the levels

783
00:46:16,720 --> 00:46:18,220
that is going to give us the answer.

784
00:46:18,610 --> 00:46:21,720
This is the total computed level by level.

785
00:46:21,780 --> 00:46:23,710
It is just a cute way to compute it.

786
00:46:23,940 --> 00:46:27,370
It usually gives you nice answers like geometric answers.

787
00:46:27,620 --> 00:46:32,280
We have n^2(1+5/16+...)

788
00:46:32,420 --> 00:46:38,260
And, if we believe in fate and we see this three number recurrence

789
00:46:38,440 --> 00:46:40,280
we know that we have the right answer.

790
00:46:40,330 --> 00:46:44,720
In general, it is going to be (5^k)/(16^k),

791
00:46:44,720 --> 00:46:46,680
at least we hope, and so on.

792
00:46:46,880 --> 00:46:48,150
And it keeps going.

793
00:46:48,290 --> 00:46:49,990
It doesn't go on infinitely,

794
00:46:50,170 --> 00:46:52,020
but let's just assume it goes on infinitely.

795
00:46:52,020 --> 00:46:55,780
That will be an upper bound that goes on forever.

796
00:46:56,650 --> 00:46:58,560
This is all times n^2.

797
00:46:59,590 --> 00:47:03,760
Now,if you are going to know one thing about geometric series,

798
00:47:03,790 --> 00:47:08,840
you should know that 1 + 1/2+ 1/4. If you sum all the powers of 2

799
00:47:09,970 --> 00:47:15,000
you get 2.

800
00:47:15,290 --> 00:47:16,310
We are computer scientists.

801
00:47:16,310 --> 00:47:18,360
We have got to know at least the binary case.

802
00:47:18,390 --> 00:47:22,850
This is like writing 0.1111111 in binary,

803
00:47:23,000 --> 00:47:24,700
actually  1.1111111

804
00:47:24,800 --> 00:47:28,780
0.1111 forever is same as 1, so this is 2.

805
00:47:29,960 --> 00:47:31,300
This is even smaller.

806
00:47:31,320 --> 00:47:33,230
We have 5/16, that is less than a half and

807
00:47:33,230 --> 00:47:34,320
then we are squaring each time,

808
00:47:34,400 --> 00:47:36,480
so this is even less than 2.

809
00:47:39,090 --> 00:47:40,960
If you want, there is a nifty formula

810
00:47:40,960 --> 00:47:43,670
for solving the general geometric series,

811
00:47:43,670 --> 00:47:45,230
but all we need is that it is a constant.

812
00:47:45,390 --> 00:47:51,420
This is O(n^2). It is also Ω(n^2).

813
00:47:51,840 --> 00:47:53,240
It is pretty obvious that it is Ω(n^2)

814
00:47:53,300 --> 00:47:55,080
because the top thing is n^2.

815
00:47:55,470 --> 00:47:57,880
So, there is our lower bound of n^2.

816
00:47:57,920 --> 00:48:01,320
And we have it within a factor of 2, which is pretty good.

817
00:48:01,320 --> 00:48:02,950
You actually get a better factor here.

818
00:48:03,090 --> 00:48:04,500
So, that is recursion-tree method.

819
00:48:04,590 --> 00:48:05,800
It is a little shaky here

820
00:48:05,890 --> 00:48:07,230
because we have these dot, dot, dots,

821
00:48:07,230 --> 00:48:09,840
and we just believe that it is geometric.

822
00:48:09,850 --> 00:48:11,440
It turns out most of the time it is geometric.

823
00:48:11,520 --> 00:48:12,340
No problem here.

824
00:48:12,390 --> 00:48:15,340
I would definitely check it with the substitution method

825
00:48:15,380 --> 00:48:16,620
because this is not obvious to me

826
00:48:16,740 --> 00:48:18,390
that it is going to be geometric.

827
00:48:18,820 --> 00:48:20,790
In the cases we will look at in a moment,

828
00:48:20,970 --> 00:48:22,240
it will be much clearer,

829
00:48:27,040 --> 00:48:29,170
so clear that we can state a theorem

830
00:48:29,270 --> 00:48:31,090
that everything is working fine.

831
00:48:31,940 --> 00:48:34,480
And still time, good.

832
00:48:37,810 --> 00:48:39,410
So, that was recursion-trees.

833
00:48:41,770 --> 00:48:43,900
There is one more method we are going to talk about,

834
00:48:44,640 --> 00:48:46,350
and you could essentially think of it

835
00:48:46,400 --> 00:48:48,720
as an application of the recursion-tree method

836
00:48:48,910 --> 00:48:51,380
but it is made more precise.

837
00:48:58,390 --> 00:49:02,140
And it is an actual theorem, whereas recursion trees,

838
00:49:02,240 --> 00:49:04,720
if the dot, dot, dots aren't obvious,you better check them.

839
00:49:07,100 --> 00:49:10,980
The sad part about the master method is it is pretty restrictive.

840
00:49:10,990 --> 00:49:15,780
It only applies to a particular family of recurrences.

841
00:49:25,560 --> 00:49:34,750
It should be T(n) = aT(n/b) + f(n).

842
00:49:35,150 --> 00:49:38,800
Am I going to call it f? Yes, I will call it f.

843
00:49:39,080 --> 00:49:41,830
In particular, it will not cover the recurrence I just solved

844
00:49:41,930 --> 00:49:44,440
because I was recursing on two different problems

845
00:49:44,500 --> 00:49:45,680
of different sizes.

846
00:49:45,830 --> 00:49:47,310
Here, every problem you recurse on

847
00:49:47,330 --> 00:49:48,870
should be of the same size.

848
00:49:48,920 --> 00:49:49,990
There are a subproblems.

849
00:49:50,120 --> 00:49:51,830
A way to think of this is a recursive algorithm.

850
00:49:51,890 --> 00:49:52,820
You have a subproblems.

851
00:49:52,900 --> 00:49:55,420
Each of them is of size n/b,

852
00:49:55,500 --> 00:49:57,020
so the total costs will be this.

853
00:49:57,160 --> 00:49:59,330
Then you are doing f(n) nonrecursive work.

854
00:50:00,180 --> 00:50:03,770
A few constraints. a should be at least 1,

855
00:50:04,360 --> 00:50:06,020
should have at least 1 recursion.

856
00:50:06,170 --> 00:50:08,200
b should be strictly greater than 1.

857
00:50:08,270 --> 00:50:09,640
You better make the problem smaller

858
00:50:09,700 --> 00:50:11,710
or else it is going to be infinity.

859
00:50:13,820 --> 00:50:17,580
And f(n) should have some nice property.

860
00:50:19,650 --> 00:50:25,640
f(n) should be asymptotically positive.

861
00:50:30,170 --> 00:50:32,960
How many people know what asymptotically positive means?

862
00:50:34,460 --> 00:50:38,000
No one. OK, you haven't read the textbook. That's OK.

863
00:50:38,060 --> 00:50:40,190
I haven't read it either, although don't tell Charles.

864
00:50:40,420 --> 00:50:42,710
And he'd notice.

865
00:50:42,820 --> 00:50:47,820
And what might you think asymptotically positive means?

866
00:50:47,910 --> 00:50:49,280
That we can do a little bit better.

867
00:50:52,360 --> 00:50:53,270
Sorry?

868
00:50:56,370 --> 00:50:59,650
Yes, it means for large enough n, f(n) is positive.

869
00:51:00,350 --> 00:51:08,210
This means f(n) is greater than zero for n, at least some n_o,

870
00:51:08,280 --> 00:51:10,060
so for some constant n_o.

871
00:51:10,120 --> 00:51:11,410
Eventually it should be positive.

872
00:51:11,480 --> 00:51:12,590
I mean, we don't care about

873
00:51:12,660 --> 00:51:15,640
whether it's negative 1 for n=1, not a big deal.

874
00:51:16,260 --> 00:51:17,430
It won't affect the answer

875
00:51:17,480 --> 00:51:19,750
because we only care about the asympotics within.

876
00:51:26,060 --> 00:51:29,350
The master method, you gave it a recurrence of this form,

877
00:51:29,460 --> 00:51:30,830
it tells you the answer.

878
00:51:31,070 --> 00:51:32,850
That is the great thing about the master method.

879
00:51:32,970 --> 00:51:34,690
The annoying thing about the master method

880
00:51:34,690 --> 00:51:35,800
is that it has three cases.

881
00:51:35,850 --> 00:51:36,870
It is a big long.

882
00:51:38,440 --> 00:51:40,870
It takes a little bit longer to memorize than all the others

883
00:51:40,870 --> 00:51:41,970
because the others are just ideas.

884
00:51:42,090 --> 00:51:44,760
Here we need to actually remember a few things.

885
00:51:46,570 --> 00:51:48,500
Let me state the theorem.

886
00:51:49,530 --> 00:51:50,560
Well, not quite yet.

887
00:51:50,810 --> 00:51:52,560
There is one very simple idea,

888
00:51:52,740 --> 00:51:56,090
which is we are going to compare this nonrecursive work f(n)

889
00:51:56,120 --> 00:52:01,380
with a very particular function n^logb(a).

890
00:52:02,950 --> 00:52:07,010
Why n^logb(a)? You will see later.

891
00:52:08,380 --> 00:52:11,670
It turns out it is the number of leaves in the recursion tree,

892
00:52:11,860 --> 00:52:13,960
but that is foreshadowing.

893
00:52:14,920 --> 00:52:18,120
So, it is either less, equal or bigger.

894
00:52:18,470 --> 00:52:20,240
And here we care about asymptotics.

895
00:52:20,340 --> 00:52:22,470
And we have to be a little bit more precise

896
00:52:22,470 --> 00:52:24,090
about less, equal or bigger.

897
00:52:24,140 --> 00:52:27,950
You might think well, it means little o, big Theta, or little omega.

898
00:52:28,100 --> 00:52:30,870
It would be nice if the theorem held for all of those cases,

899
00:52:30,950 --> 00:52:33,200
but it leaves some gaps.

900
00:52:34,430 --> 00:52:36,590
Let's start with Case 1.

901
00:52:36,970 --> 00:52:38,880
Case 1 is when f(n) is smaller.

902
00:52:39,780 --> 00:52:41,680
And not just that it is little o,

903
00:52:42,730 --> 00:52:45,430
but it is actually quite a bit smaller.

904
00:52:45,480 --> 00:52:49,820
It has got to be polynomially smaller than n^logb(a).

905
00:52:58,950 --> 00:53:03,250
For some positive epsilon, the running time should be this n

906
00:53:03,320 --> 00:53:06,620
to this constant log base b of a minus that epsilon,

907
00:53:06,660 --> 00:53:10,140
so it is really polynomially smaller than n^logb(a).

908
00:53:11,040 --> 00:53:13,070
We cannot handle the little o case,

909
00:53:13,120 --> 00:53:14,120
that's a little bit too strong.

910
00:53:14,170 --> 00:53:16,270
This is saying it is really quite a bit smaller.

911
00:53:19,220 --> 00:53:26,150
But the answer then is really simple, T(n) = Θ( n^logb(a) ).

912
00:53:27,850 --> 00:53:30,250
Great. That is Case 1.

913
00:53:32,110 --> 00:53:40,070
Case 2 is when f(n) is pretty much equal to n^logb(a).

914
00:53:42,190 --> 00:53:43,620
And by pretty much equal I mean

915
00:53:43,620 --> 00:53:46,320
up to poly log factors.

916
00:53:48,470 --> 00:53:52,800
This is log base 2 of n to the power k.

917
00:53:52,960 --> 00:53:55,340
You should know this notation.

918
00:53:56,360 --> 00:53:58,500
For example,k could be zero.

919
00:53:58,900 --> 00:54:01,440
And then they are equal up to constant factors,

920
00:54:01,530 --> 00:54:04,410
for some k greater than or equal to zero.

921
00:54:07,250 --> 00:54:08,490
Less than will not work,

922
00:54:08,550 --> 00:54:10,480
so it is really important that k is non-negative.

923
00:54:10,630 --> 00:54:12,140
It should probably be an integer.

924
00:54:12,640 --> 00:54:14,780
It doesn't actually matter whether there is an integer,

925
00:54:16,050 --> 00:54:19,100
but there it is. It could n^logb(a) times lg n

926
00:54:19,100 --> 00:54:21,450
or just times nothing, whatever.

927
00:54:22,200 --> 00:54:24,820
Again, the solution is easy here,

928
00:54:24,820 --> 00:54:33,850
T = Θ( n^logb(a)…).

929
00:54:33,850 --> 00:54:36,480
Presumably it has to be at least times lg^k.

930
00:54:36,520 --> 00:54:41,230
It turns out it is lg to the k plus 1 of n.

931
00:54:46,550 --> 00:54:47,610
That is Case 2.

932
00:54:48,730 --> 00:54:52,770
We have one more case which is slightly more complicated.

933
00:54:55,040 --> 00:54:57,660
We need to assume slightly more for Case 3.

934
00:54:58,010 --> 00:54:59,840
But Case 3 is roughly

935
00:54:59,840 --> 00:55:04,430
when f(n) grows bigger than n^logb(a).

936
00:55:04,480 --> 00:55:06,820
So, it should be capital Omega,

937
00:55:07,040 --> 00:55:09,110
here is one place where we get to use omega,

938
00:55:09,900 --> 00:55:17,210
n^logb(a) for some positive epsilon.

939
00:55:20,000 --> 00:55:22,730
It should grow not just bigger but polynomially bigger.

940
00:55:22,910 --> 00:55:25,780
Here it was growing just a log factor bigger, poly log,

941
00:55:25,960 --> 00:55:28,280
and here it is a polynomial factor.

942
00:55:29,390 --> 00:55:32,540
In this case,we need another assumption about f(n)

943
00:55:33,250 --> 00:55:36,360
because we worry a little bit about how quickly f(n) grows.

944
00:55:37,460 --> 00:55:39,340
We want to make sure

945
00:55:39,340 --> 00:55:42,530
that as you go down the recursion f gets smaller.

946
00:55:42,620 --> 00:55:44,940
It would be kind of nice if f gets smaller as you go down,

947
00:55:46,080 --> 00:55:47,280
otherwise you are, again,

948
00:55:47,280 --> 00:55:49,340
trying to sum to infinity or whatever.

949
00:55:54,620 --> 00:56:03,880
I see why this is for some epsilon prime greater than zero.

950
00:56:04,070 --> 00:56:07,950
What I would like is that if I just sort of take the recurrence,

951
00:56:08,010 --> 00:56:12,080
this T(n) and just throw in fs instead,

952
00:56:12,080 --> 00:56:17,880
f(n) should be somehow related to af(n/b).

953
00:56:18,050 --> 00:56:18,900
What I would like is that

954
00:56:18,900 --> 00:56:21,470
f(n), which is at the top of the recursion tree,

955
00:56:21,730 --> 00:56:25,920
should be bigger than the thing at the next level down.

956
00:56:26,060 --> 00:56:28,600
The sum of all the values at the next level down

957
00:56:28,660 --> 00:56:31,600
should be bigger by some constant factor.

958
00:56:31,690 --> 00:56:36,280
Here I have the next level down is at most some 1 - ε,

959
00:56:36,310 --> 00:56:38,030
something strictly less than 1,

960
00:56:38,460 --> 00:56:40,530
some constant strictly less than 1

961
00:56:40,580 --> 00:56:42,640
times the thing at the top level.

962
00:56:43,010 --> 00:56:46,060
I need that to make sure things are getting smaller as I go down.

963
00:56:46,720 --> 00:56:52,300
Then T(n) = Θ(f(n)).

964
00:56:54,130 --> 00:56:55,330
And that is the theorem.

965
00:56:55,420 --> 00:56:58,090
This is the master theorem or whatever you want to call it.

966
00:56:58,120 --> 00:56:59,920
It is not named after some guy name Master.

967
00:56:59,980 --> 00:57:02,490
It is just the master of all methods

968
00:57:02,550 --> 00:57:04,510
because it is very easy to apply.

969
00:57:09,480 --> 00:57:11,340
Let's apply it a few times.

970
00:57:11,540 --> 00:57:14,660
It is a bit much to take in all at once.

971
00:57:15,460 --> 00:57:18,170
And then I will give you a sketch of the proof

972
00:57:18,980 --> 00:57:21,630
to see that it is really not that surprising this is true

973
00:57:21,830 --> 00:57:23,530
if you look at the recursion-tree.

974
00:57:24,060 --> 00:57:25,930
But first let's just try using it.

975
00:57:28,530 --> 00:57:35,370
For example, we could take T(n) = 4T(n/2) +n.

976
00:57:36,440 --> 00:57:42,330
This is a, this is b,this is f(n).

977
00:57:45,450 --> 00:57:49,460
The first thing we should compute is n^logb(a).

978
00:57:50,040 --> 00:57:51,720
This I think even I can do.

979
00:57:52,360 --> 00:57:55,420
Log base 2 of 4. Yeah, log base 2 I can do.

980
00:57:55,490 --> 00:57:57,760
This is n^2.

981
00:57:59,700 --> 00:58:02,640
OK, so is f(n) smaller or bigger than n^2?

982
00:58:02,820 --> 00:58:03,890
Well, f(n) = n.

983
00:58:03,980 --> 00:58:06,920
n^2 is clearly bigger by a polynomial factor.

984
00:58:07,010 --> 00:58:08,270
So, we are in Case 1.

985
00:58:14,080 --> 00:58:15,190
What is the answer?

986
00:58:22,140 --> 00:58:23,620
n^2, yeah.

987
00:58:28,000 --> 00:58:31,420
It is theta n^log_ba, which here it is just n^2.

988
00:58:33,950 --> 00:58:39,720
Let's do some slight variation.

989
00:58:39,720 --> 00:58:44,190
I am going to keep a and b the same and just change f.

990
00:58:46,540 --> 00:58:53,010
Let's say T(n)=4T(n/2)+n^2.

991
00:58:53,490 --> 00:58:55,360
This is like drill spelling.

992
00:58:55,480 --> 00:59:01,330
n^2 is asymptotically the same as n^2 even up to constants.

993
00:59:01,430 --> 00:59:04,440
What is the answer? This is Case 2.

994
00:59:10,940 --> 00:59:11,820
It is slightly harder.

995
00:59:20,090 --> 00:59:24,850
What is k in this example? Zero.

996
00:59:28,190 --> 00:59:31,890
The answer is? Survey says?

997
00:59:32,660 --> 00:59:33,710
N^2 log n.

998
00:59:42,350 --> 00:59:45,120
Good. And a couple more.

999
00:59:46,790 --> 00:59:52,360
T(n)=4T(n/2) + n^3. What is the answer?

1000
00:59:54,460 --> 00:59:56,560
n^3.

1001
00:59:59,320 --> 01:00:00,430
This is Case 3.

1002
01:00:02,590 --> 01:00:04,020
I know this is pretty boring.

1003
01:00:04,040 --> 01:00:06,600
At this point we are just applying this stupid theorem.

1004
01:00:09,720 --> 01:00:13,060
How about n^2/lg n?

1005
01:00:14,510 --> 01:00:16,320
What is the answer?

1006
01:00:21,110 --> 01:00:24,230
Good. In this case no one should answer.

1007
01:00:24,930 --> 01:00:27,400
It is a big tricky. I forget exactly the answer.

1008
01:00:27,700 --> 01:00:33,580
I think it is like n^2 log log n over log n,no?

1009
01:00:34,070 --> 01:00:37,060
Oh, no. n^2 log log n, that's right.Yeah.

1010
01:00:37,910 --> 01:00:39,050
But you shouldn't know that,

1011
01:00:39,080 --> 01:00:40,930
and this doesn't follow from the master method.

1012
01:00:41,050 --> 01:00:42,740
This is something you would have to solve,

1013
01:00:42,790 --> 01:00:43,900
probably with the recursion-tree

1014
01:00:43,900 --> 01:00:45,300
would be a good way to do this one,

1015
01:00:45,620 --> 01:00:47,840
and you need to know some properties of logs

1016
01:00:48,140 --> 01:00:50,180
to know how that goes.

1017
01:00:50,240 --> 01:00:52,410
But here the master method does not apply.

1018
01:01:03,160 --> 01:01:04,960
And so you have to use a different method.

1019
01:01:09,470 --> 01:01:10,950
OK. The last thing I want to do is

1020
01:01:10,950 --> 01:01:12,470
tell you why the master method is true,

1021
01:01:13,020 --> 01:01:14,650
and that makes it much more intuitive,

1022
01:01:14,650 --> 01:01:16,680
especially using recursion-trees,

1023
01:01:17,740 --> 01:01:19,330
why everything works.

1024
01:01:33,420 --> 01:01:37,210
This is a sketch of a proof, not the full thing.

1025
01:01:37,750 --> 01:01:40,060
You should read the proof in the textbook.

1026
01:01:40,550 --> 01:01:42,510
It is not that much harder than what I will show,

1027
01:01:42,510 --> 01:01:44,910
but it is good for you to know the formal details.

1028
01:01:44,910 --> 01:01:47,910
I don't have time here to do all of the details.

1029
01:01:48,120 --> 01:01:50,360
I will just tell you the salient parts.

1030
01:01:50,370 --> 01:01:54,300
This is the proof sketch or the intuition

1031
01:01:56,400 --> 01:01:58,610
behind the master method.

1032
01:02:03,210 --> 01:02:06,270
What we are going to do is just take the recursion-tree

1033
01:02:06,350 --> 01:02:07,730
for this recurrence

1034
01:02:08,280 --> 01:02:11,840
and add up each level and then add up all the levels

1035
01:02:12,040 --> 01:02:13,130
and see what we get.

1036
01:02:16,340 --> 01:02:20,000
We start with f at the top after we have expanded one level.

1037
01:02:20,210 --> 01:02:27,080
Then we get a different problems, each of size n/b.

1038
01:02:27,340 --> 01:02:33,400
And after we expand them it will f for each one.

1039
01:02:33,790 --> 01:02:35,250
They are all the same size.

1040
01:02:35,520 --> 01:02:37,340
Then we expand all of those and so on,

1041
01:02:37,540 --> 01:02:41,590
and we get another a subproblems from there.

1042
01:02:41,780 --> 01:02:46,960
We are going to get like f.

1043
01:02:49,170 --> 01:02:52,360
That is sort of decreasing geometrically the size,

1044
01:02:52,570 --> 01:02:54,500
and so on and so on and so on,

1045
01:02:54,650 --> 01:02:58,080
until at the bottom we get constant size problems.

1046
01:02:58,150 --> 01:03:00,650
This is a bit special because this is the base case,

1047
01:03:00,840 --> 01:03:02,820
but we have some other constant at the bottom.

1048
01:03:03,390 --> 01:03:05,410
We would like to know how many leaves there are,

1049
01:03:06,210 --> 01:03:08,220
but that is a little bit tricky at the moment.

1050
01:03:08,240 --> 01:03:11,600
Let's first compute the height of this tree.

1051
01:03:14,130 --> 01:03:16,230
Let me draw it over here.

1052
01:03:17,190 --> 01:03:18,500
What is the height of this tree?

1053
01:03:18,570 --> 01:03:20,160
I start with a problem of size n.

1054
01:03:20,330 --> 01:03:22,600
I want to get down to a problem of size 1.

1055
01:03:24,010 --> 01:03:25,380
How long does that take?

1056
01:03:28,670 --> 01:03:29,610
How many levels?

1057
01:03:36,480 --> 01:03:38,530
This is probably too easy for some

1058
01:03:38,550 --> 01:03:42,250
and not at your fingertips for others.

1059
01:03:48,490 --> 01:03:50,050
Log base b of n, good.

1060
01:03:50,630 --> 01:03:53,590
The height of this tree is n^log_b,

1061
01:03:53,600 --> 01:03:54,900
because it is just how many times

1062
01:03:54,910 --> 01:03:56,770
I divide by b until I get down to 1.

1063
01:03:57,540 --> 01:03:58,690
That is great.

1064
01:03:58,940 --> 01:04:00,720
Now I should be able to compute the number of leaves

1065
01:04:00,800 --> 01:04:02,820
because I have branching factor a,

1066
01:04:03,020 --> 01:04:04,540
I have height h.

1067
01:04:04,710 --> 01:04:11,320
The number of leaves is a^h, a^log_bn.

1068
01:04:13,960 --> 01:04:16,100
Let me expand that a little bit.

1069
01:04:16,330 --> 01:04:20,100
a^log_bn, properties of logs,

1070
01:04:20,130 --> 01:04:23,940
we can take the n downstairs and put the a upstairs,

1071
01:04:24,150 --> 01:04:28,770
and we get n^log_ba. Our good friend n^log_ba.

1072
01:04:28,770 --> 01:04:30,910
So, that is why our good friend n^log_ba is

1073
01:04:30,970 --> 01:04:32,310
so important in the master method.

1074
01:04:32,410 --> 01:04:34,630
What we are doing is comparing f,

1075
01:04:34,650 --> 01:04:35,540
which is the top level,

1076
01:04:35,730 --> 01:04:39,580
to n^log_ba, which up to theta is the bottom level.

1077
01:04:39,810 --> 01:04:41,630
Now the leaves are all at the same level

1078
01:04:41,710 --> 01:04:44,430
because we are decreasing at the same rate in every branch.

1079
01:04:44,770 --> 01:04:48,200
If I add up the cost at the bottom level,

1080
01:04:48,280 --> 01:04:51,450
it is Theta n^log_ba.

1081
01:04:53,260 --> 01:04:54,890
I add up the things at the top level

1082
01:04:54,970 --> 01:04:58,720
it is f(n), not terribly exciting.

1083
01:04:58,840 --> 01:05:00,230
But the next level,

1084
01:05:00,260 --> 01:05:03,820
this is a little bit more interesting, is af(n/b),

1085
01:05:04,270 --> 01:05:05,630
which should look familiar

1086
01:05:05,630 --> 01:05:09,320
if you had the master method already memorized, it is that.

1087
01:05:09,900 --> 01:05:15,670
So, we know that af(n/b) has decreased by some constant factor,

1088
01:05:15,890 --> 01:05:17,430
1-epsilon prime.

1089
01:05:18,180 --> 01:05:19,240
We have gone down.

1090
01:05:19,410 --> 01:05:22,000
This is a constant factor smaller than this.

1091
01:05:22,500 --> 01:05:24,340
And then you sum up the next level.

1092
01:05:24,390 --> 01:05:28,840
It is going to be like a^2f(n/b^2).

1093
01:05:31,770 --> 01:05:34,330
I see that I actually wrote this wrong, the parentheses.

1094
01:05:34,330 --> 01:05:35,700
Sorry about that.

1095
01:05:35,960 --> 01:05:39,160
It is not (n/b)^2. It is n/b^2.

1096
01:05:41,910 --> 01:05:47,200
So, this sequence, in Case 3 at least,

1097
01:05:47,240 --> 01:05:48,990
is decreasing geometrically.

1098
01:05:49,640 --> 01:05:52,570
If it is decreasing geometrically up to constant factors,

1099
01:05:52,570 --> 01:05:57,310
it is dominated by the biggest term, which is f(n).

1100
01:05:57,360 --> 01:05:59,800
Therefore, in Case 3, we get Theta(f(n)).

1101
01:06:00,680 --> 01:06:03,500
Let's look at the other cases,

1102
01:06:03,570 --> 01:06:06,540
and let me adapt those cases to how much time we have left.

1103
01:06:06,560 --> 01:06:07,310
Wow, lot's of time.

1104
01:06:09,010 --> 01:06:10,690
Five minutes. Tons of time.

1105
01:06:11,270 --> 01:06:15,550
What to do? Let me write that down.

1106
01:06:15,800 --> 01:06:21,420
Case 3, the costs decrease.

1107
01:06:21,450 --> 01:06:22,750
Now, this is a place I would argue

1108
01:06:22,750 --> 01:06:24,740
where the dot, dot, dot is pretty obvious.

1109
01:06:25,200 --> 01:06:29,700
Here, this is damn simple, it is a^kf.

1110
01:06:29,900 --> 01:06:37,510
And, in Case 3, we assume that the costs decrease geometrically

1111
01:06:44,000 --> 01:06:46,560
as we go down the tree.

1112
01:06:47,990 --> 01:06:50,570
That was sort of backwards to start with Case 3.

1113
01:06:50,630 --> 01:06:52,590
Let's do Case 1,

1114
01:06:53,000 --> 01:06:56,350
which is sort of the other intuitively easy case.

1115
01:06:56,620 --> 01:07:04,780
In Case 1, we know that f is polynomially smaller than this thing.

1116
01:07:06,160 --> 01:07:07,890
And we are sort of changing

1117
01:07:07,890 --> 01:07:10,490
by this very simple procedure in the middle.

1118
01:07:10,580 --> 01:07:12,050
I am going to wave my hands if this is

1119
01:07:12,050 --> 01:07:13,490
where you need a more formal argument.

1120
01:07:13,730 --> 01:07:16,700
I claim that this will increase geometrically.

1121
01:07:17,170 --> 01:07:19,770
It has to increase geometrically because this f

1122
01:07:19,800 --> 01:07:23,310
is polynomially smaller than this one,

1123
01:07:23,440 --> 01:07:25,580
you are going to get various polynomials in the middle

1124
01:07:25,790 --> 01:07:29,110
which interpret geometrically from the small one to the big one.

1125
01:07:29,150 --> 01:07:31,300
Therefore, the big one dominates because it is, again,

1126
01:07:31,380 --> 01:07:32,710
geometric series.

1127
01:07:33,110 --> 01:07:39,100
As I said, this is intuition, not a formal argument.

1128
01:07:39,150 --> 01:07:41,180
This one was pretty formal because we assumed it,

1129
01:07:41,430 --> 01:07:43,940
but here you need a bit more argument.

1130
01:07:44,080 --> 01:07:45,830
They may not increase geometrically

1131
01:07:45,880 --> 01:07:47,470
but they could increase faster,

1132
01:07:47,650 --> 01:07:50,420
and that is also fine.

1133
01:07:51,090 --> 01:07:53,840
So, in Case 3, you are dominated,

1134
01:07:56,330 --> 01:07:57,300
I mean you are always dominated

1135
01:07:57,340 --> 01:08:00,220
by the biggest term in a geometric series.

1136
01:08:00,450 --> 01:08:02,530
Here it happens to be f

1137
01:08:05,170 --> 01:08:10,870
and here you are dominated by n^log_ba

1138
01:08:10,900 --> 01:08:13,230
with a bottom term, oh, Theta.

1139
01:08:15,650 --> 01:08:16,940
Case 2,

1140
01:08:19,900 --> 01:08:22,400
here it is pretty easy

1141
01:08:22,420 --> 01:08:24,270
but you need to know some properties of logs.

1142
01:08:24,480 --> 01:08:25,260
In Case 2,

1143
01:08:25,300 --> 01:08:27,600
we assume that all of these are basically the same.

1144
01:08:27,720 --> 01:08:30,710
I mean, we assume that the top is equal to the bottom.

1145
01:08:30,940 --> 01:08:33,830
And this is changing in this very procedural way.

1146
01:08:33,900 --> 01:08:35,760
Therefore, all of the ones in the middle

1147
01:08:35,800 --> 01:08:37,140
have to be pretty much the same.

1148
01:08:38,410 --> 01:08:41,440
Not quite because here we don't have the log factor.

1149
01:08:41,710 --> 01:08:43,320
Here we have a log to the k.

1150
01:08:43,320 --> 01:08:47,030
We have n^log_ba times log to the kn.

1151
01:08:47,220 --> 01:08:48,800
Here we don't have the log to the k.

1152
01:08:48,900 --> 01:08:50,560
So, the logs do disappear here.

1153
01:08:50,650 --> 01:08:53,100
It turns out the way they disappear is pretty slowly.

1154
01:08:53,270 --> 01:08:59,110
If you look at the top half of these terms,

1155
01:08:59,300 --> 01:09:00,970
they will all have log to the k.

1156
01:09:01,350 --> 01:09:03,270
The bottom half they will start to disappear.

1157
01:09:03,470 --> 01:09:07,280
I am giving you some oracle information.

1158
01:09:07,360 --> 01:09:12,220
If you take logs and you don't change the argument by too much,

1159
01:09:12,330 --> 01:09:13,800
the logs remain.

1160
01:09:14,750 --> 01:09:16,610
Maybe halfway is too far.

1161
01:09:17,500 --> 01:09:20,560
The claim is that each level is roughly the same,

1162
01:09:20,740 --> 01:09:25,220
especially the upper most levels are all asymptotically equal.

1163
01:09:28,090 --> 01:09:30,560
Roughly the same.

1164
01:09:32,340 --> 01:09:35,940
And, therefore, the cost is one level,

1165
01:09:35,950 --> 01:09:45,650
here like f times the number of levels, h.

1166
01:09:46,000 --> 01:09:47,830
And h is log base b of n.

1167
01:09:47,930 --> 01:09:49,590
B is a constant so we don't care.

1168
01:09:49,740 --> 01:09:52,140
This is Theta(lgn).

1169
01:09:55,430 --> 01:10:05,570
And, therefore,we get T = n^log_ba lg^kn times another log n.

1170
01:10:06,130 --> 01:10:08,220
So, we get f(n) times log n.

1171
01:10:08,970 --> 01:10:10,780
That is the very quick sketch.

1172
01:10:10,790 --> 01:10:13,010
Sorry, I am being pretty fuzzy on Cases 1 and 2.

1173
01:10:13,080 --> 01:10:15,300
Read the proof because you will have to,

1174
01:10:15,350 --> 01:10:17,740
at some point, manipulate logs in that way.

1175
01:10:18,010 --> 01:10:20,070
And that is all. Any questions?

1176
01:10:20,160 --> 01:10:22,280
Or, you are all eager to go. OK.

1177
01:10:22,460 --> 01:10:24,630
Thanks. See you Wednesday.

