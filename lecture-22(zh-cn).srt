1
00:00:07,470 --> 00:00:08,870
燃起来了！！

2
00:00:10,210 --> 00:00:11,910
本周结局篇的内容

3
00:00:11,970 --> 00:00:15,550
依然是高级课题——高速缓存参数无关算法

4
00:00:15,620 --> 00:00:20,240
这个算法相当有前途啊 我都快嫁给它了

5
00:00:20,310 --> 00:00:22,940
因为我在这个领域已经做了大量的研究

6
00:00:23,050 --> 00:00:28,690
我们的很萌的查教授参与了这个领域的创立

7
00:00:28,800 --> 00:00:32,480
我与查哥第一次邂逅的缘由

8
00:00:32,550 --> 00:00:37,430
正是他的一个缓参无关算法的讲座

9
00:00:37,480 --> 00:00:41,000
还记得 那是99年的温哥华WADS会议

10
00:00:41,010 --> 00:00:43,610
我没记错吧？ 嗯 大概是有一年多的事情吧

11
00:00:43,640 --> 00:00:46,560
正是那时 我了解了缓参无关算法

12
00:00:46,630 --> 00:00:47,970
开启了我的研究之旅

13
00:00:48,070 --> 00:00:51,430
做研究真的好开心啊

14
00:00:51,500 --> 00:00:53,630
而且这个课题 在某种意义上

15
00:00:53,700 --> 00:00:56,140
是在这门课上发扬光大的

16
00:00:56,210 --> 00:00:58,980
曾经有一个学期

17
00:00:59,050 --> 00:01:02,770
大概是98年到99年 那时课后的习题

18
00:01:02,840 --> 00:01:04,920
都是缓参无关算法相关的

19
00:01:04,990 --> 00:01:06,350
正是那一年的学生们

20
00:01:06,360 --> 00:01:08,500
寓研于学 同时发展起了这个问题的研究思想

21
00:01:08,570 --> 00:01:12,140
史称《那些年我们研究过的算法》

22
00:01:12,210 --> 00:01:15,090
这学期 我们本来也想这么搞

23
00:01:15,130 --> 00:01:17,450
但现在都浮云了

24
00:01:17,510 --> 00:01:19,580
我们现在已经对这个算法相当了解了

25
00:01:19,690 --> 00:01:21,640
喜闻乐见的事儿了

26
00:01:23,320 --> 00:01:26,600
好吧 这就是一些故事的设定

27
00:01:26,700 --> 00:01:29,180
它是由一群MIT大牛学生开发的

28
00:01:29,250 --> 00:01:31,920
特别是一个工程硕士 H神

29
00:01:31,980 --> 00:01:33,620
这是他的硕士论文

30
00:01:33,720 --> 00:01:37,410
我就说这么多了

31
00:01:37,480 --> 00:01:39,730
虽然我还没发布 但其实

32
00:01:39,830 --> 00:01:42,040
有一些相关的资料在我的主页上

33
00:01:42,110 --> 00:01:44,150
我之后会把它们整理到课程主页上去

34
00:01:44,220 --> 00:01:46,780
把我说的所有相关材料都整理起来

35
00:01:46,860 --> 00:01:49,320
那都是5年来的研究成果

36
00:01:49,390 --> 00:01:51,340
始于1999年

37
00:01:51,410 --> 00:01:54,240
第一篇论文就是那时候发的

38
00:01:54,310 --> 00:01:59,390
详细的援引我就不在课上说了

39
00:02:01,810 --> 00:02:09,970
另外 这个课题跟我们上周的课题息息相关

40
00:02:10,040 --> 00:02:14,860
多线程算法 虽然是更高层次上的联系

41
00:02:14,930 --> 00:02:19,590
这个算法针对的是当今计算机的并行化

42
00:02:19,690 --> 00:02:23,460
而在我们上周的两次课里

43
00:02:23,530 --> 00:02:26,090
我们用的是一个非常简单的计算机模型

44
00:02:26,160 --> 00:02:27,470
它是随机读写的

45
00:02:27,540 --> 00:02:29,540
读写内存的花费是O(1)

46
00:02:29,610 --> 00:02:33,520
你可以从内存中读或写一个字段

47
00:02:33,590 --> 00:02:36,080
而一个字段有多大 它有一些详细的定义

48
00:02:36,150 --> 00:02:39,850
但它是一个基础 简单 单一的模型

49
00:02:39,920 --> 00:02:43,600
而所谓的多线程 也就是说

50
00:02:43,670 --> 00:02:46,470
你同时有多个线程的运算在工作

51
00:02:46,570 --> 00:02:48,310
但你同时只有单一的内存

52
00:02:48,380 --> 00:02:51,580
每个线程读写内存的花费都是常数阶的

53
00:02:51,690 --> 00:02:53,910
不过这次我们要换一个模型

54
00:02:53,920 --> 00:03:00,410
我们要认识到 现实中的机器

55
00:03:00,480 --> 00:03:04,070
它的存储模块是分层的

56
00:03:04,150 --> 00:03:07,640
首先你有处理器 然后是缓存

57
00:03:07,710 --> 00:03:11,100
一级缓存可能就在同一个芯片上

58
00:03:11,170 --> 00:03:12,960
然后到二级缓存

59
00:03:13,070 --> 00:03:15,890
如果你的机子还没淘汰 那你应该有三级缓存

60
00:03:15,960 --> 00:03:19,060
然后才到内存

61
00:03:21,660 --> 00:03:26,500
然后 才轮到大硬盘

62
00:03:26,610 --> 00:03:29,740
硬盘里可能也有一些缓存

63
00:03:29,810 --> 00:03:31,850
但我这里不作考虑

64
00:03:31,920 --> 00:03:33,240
重点就是

65
00:03:33,310 --> 00:03:36,150
你有很多层的存储

66
00:03:36,220 --> 00:03:37,530
它们的不同点是

67
00:03:37,630 --> 00:03:39,190
越靠近处理器的存储

68
00:03:39,260 --> 00:03:41,390
速度就越快 一般来说 一级缓存的话

69
00:03:41,460 --> 00:03:44,460
只需要差不多一个处理器周期

70
00:03:44,530 --> 00:03:46,640
后面的存储就越来越慢

71
00:03:46,710 --> 00:03:50,510
内存大概要70纳秒左右

72
00:03:50,590 --> 00:03:54,390
才能获取一定的信息 这个时间已经很长了

73
00:03:54,460 --> 00:03:57,570
70纳秒对于处理器来说 相当漫长

74
00:03:57,990 --> 00:04:02,460
我们越往这边走 信息的读写就越慢

75
00:04:02,530 --> 00:04:05,810
但存储空间就越大

76
00:04:05,880 --> 00:04:08,630
如果所有存储都在一级缓存这儿

77
00:04:08,710 --> 00:04:10,110
问题就解决了

78
00:04:10,180 --> 00:04:12,140
你只知道这有块单一的存储

79
00:04:12,220 --> 00:04:13,260
如果要读取里面的信息

80
00:04:13,330 --> 00:04:15,350
我们假设它的时间都是一样的

81
00:04:15,420 --> 00:04:20,160
但通常 我们做不到 也不可能做到

82
00:04:20,240 --> 00:04:22,010
把所有东西塞在一级缓存里 我想说

83
00:04:22,120 --> 00:04:25,970
存储的分层结构是有原因的

84
00:04:26,030 --> 00:04:29,910
有没有人能给个理由

85
00:04:29,980 --> 00:04:36,550
人生总有些极限无法逆袭 请说

86
00:04:36,620 --> 00:04:39,330
因为快速存取存储器很贵

87
00:04:39,400 --> 00:04:41,350
这确实很现实的一个限制

88
00:04:41,420 --> 00:04:43,910
你可以试着给电脑加上一堆一级缓存

89
00:04:43,980 --> 00:04:48,250
可能你可以试试看

90
00:04:48,350 --> 00:04:51,600
价钱确实是个好理由 很实际

91
00:04:51,670 --> 00:04:55,400
这是它们这么袖珍的一个原因

92
00:04:55,470 --> 00:04:56,820
但假如快速存取存储器很便宜

93
00:04:56,930 --> 00:04:59,310
而大家又都是高帅富

94
00:04:59,390 --> 00:05:04,020
是不是还有一个无法超越的物理极限

95
00:05:04,090 --> 00:05:05,370
光速

96
00:05:05,440 --> 00:05:06,970
爱因斯坦笑了 这问题不好整

97
00:05:07,040 --> 00:05:10,220
假设无论是多是少

98
00:05:10,290 --> 00:05:13,570
一个原子里只能装一定的位信息

99
00:05:13,670 --> 00:05:17,040
在这个空间里 你只能写这么多位了

100
00:05:17,110 --> 00:05:20,480
如果你要更多位 你就要更多的空间

101
00:05:20,550 --> 00:05:21,680
而如果空间越大

102
00:05:21,750 --> 00:05:23,960
光的往返时间就越长

103
00:05:24,030 --> 00:05:27,940
假设你的处理器就是空间中的一个点

104
00:05:28,010 --> 00:05:31,530
这个点很小 然后它要从别处获取数据

105
00:05:31,600 --> 00:05:36,150
数据越大 离它的平均距离就越远

106
00:05:36,220 --> 00:05:39,680
不过你可以把处理器周围的东西——

107
00:05:39,780 --> 00:05:41,810
其实我们也不怎么三维

108
00:05:41,880 --> 00:05:44,390
因为这些芯片一般是二维的 不过没关系

109
00:05:44,460 --> 00:05:48,170
你可以把它做成一个球形 包围着处理器

110
00:05:48,240 --> 00:05:49,740
这样获取数据就能很快了

111
00:05:49,780 --> 00:05:52,030
越往外时间花费就越多

112
00:05:52,100 --> 00:05:54,740
这就是这个模型要表达的东西

113
00:05:54,810 --> 00:05:57,270
虽然这只是个大致的理论

114
00:05:57,340 --> 00:06:00,450
是从它固有的物理和几何的角度上推导出的

115
00:06:00,500 --> 00:06:05,160
但大概就是这样 延迟和往返时间

116
00:06:05,230 --> 00:06:08,090
越大的存储就会越慢

117
00:06:08,160 --> 00:06:15,290
一般来说 读写内存的花费

118
00:06:16,090 --> 00:06:20,890
就是由延迟和往返时间 这两样组成

119
00:06:20,960 --> 00:06:24,320
这都受到了光速的限制

120
00:06:24,390 --> 00:06:30,570
除了往返时间

121
00:06:30,670 --> 00:06:32,610
你还要算数据的读取时间

122
00:06:32,670 --> 00:06:34,600
这也要看你的数据有多大

123
00:06:34,670 --> 00:06:38,780
数据越大 时间越长 所以说

124
00:06:38,850 --> 00:06:42,830
这就是 要准确地描述 我们说

125
00:06:42,940 --> 00:06:49,690
数据量 除以 带宽

126
00:06:50,070 --> 00:06:53,360
带宽就是你读取数据的频率

127
00:06:53,460 --> 00:06:55,440
你会留意到这些不同层次的存储

128
00:06:55,520 --> 00:06:59,900
它们的带宽几乎都是一样的

129
00:06:59,970 --> 00:07:01,700
如果你的电脑没什么问题

130
00:07:01,770 --> 00:07:03,690
它们的带宽就都应该是一致的

131
00:07:03,830 --> 00:07:07,830
你从硬盘里读数据是很快的

132
00:07:07,900 --> 00:07:09,950
一般就是你总线的速度

133
00:07:10,020 --> 00:07:11,820
而总线传入处理器的速度

134
00:07:11,890 --> 00:07:13,450
所有部件是都是一样快的

135
00:07:13,520 --> 00:07:14,950
所以 虽然它们比较慢

136
00:07:15,020 --> 00:07:17,550
但它们的慢都是因为延迟的关系

137
00:07:17,620 --> 00:07:22,160
所以 虽然这一半公式是合理的

138
00:07:22,230 --> 00:07:24,610
但因为大家的带宽都相同

139
00:07:24,680 --> 00:07:27,420
所以 时间增大的就是延迟了

140
00:07:27,490 --> 00:07:30,290
那么 如果延迟在不断增大

141
00:07:30,310 --> 00:07:32,820
而每层的除数带宽又相同的话

142
00:07:32,890 --> 00:07:35,760
我们要怎么做才能够

143
00:07:35,830 --> 00:07:39,400
让每一层的时间都大致相等呢？

144
00:07:41,790 --> 00:07:47,430
这个是固定的 不不不 这个是递增的

145
00:07:47,500 --> 00:07:50,570
但这个分母却不变

146
00:07:50,610 --> 00:07:54,230
那我们要怎么做才能使公式平衡？

147
00:07:59,000 --> 00:08:01,000
改变数据的读取量

148
00:08:01,070 --> 00:08:04,410
随着延迟的增大 如果我们增大数据读取量

149
00:08:04,480 --> 00:08:10,220
那么读取每个元素的平摊花费就减少了

150
00:08:10,330 --> 00:08:16,550
好的 这个平摊分析很明显了

151
00:08:17,250 --> 00:08:21,840
上面是读取一个数据块的是花费

152
00:08:21,940 --> 00:08:25,300
这个读取量就是数据块的大小

153
00:08:26,250 --> 00:08:31,190
那么 读取一个元素的平摊花费

154
00:08:34,480 --> 00:08:40,990
就会是 延迟除以数据块大小

155
00:08:41,060 --> 00:08:45,920
再加上带宽的倒数

156
00:08:49,030 --> 00:08:50,610
好了 这条式子你们都应该

157
00:08:50,670 --> 00:08:52,610
在脑海中好好思考一下

158
00:08:52,680 --> 00:08:54,940
我在这里除掉数据量是因为

159
00:08:55,060 --> 00:08:57,470
数据量就是你在一次读取中

160
00:08:57,540 --> 00:09:00,000
所获取的元素的数量

161
00:09:00,070 --> 00:09:03,170
好的 我们有了一条平摊花费的公式

162
00:09:03,240 --> 00:09:04,750
而后面这一项 带宽的倒数

163
00:09:04,820 --> 00:09:07,260
与存储的层次结构无关

164
00:09:07,340 --> 00:09:09,500
这一项没有什么本质的限制

165
00:09:09,570 --> 00:09:11,570
除了它可能也很大

166
00:09:11,670 --> 00:09:14,800
延迟这一项 则被读取量平摊开来

167
00:09:14,860 --> 00:09:16,350
所以 无论延迟有多大

168
00:09:16,360 --> 00:09:17,990
它要是越大

169
00:09:18,060 --> 00:09:20,160
我们只要读取得越多

170
00:09:20,230 --> 00:09:22,950
我们就能使得这两项 (之和) 相等

171
00:09:23,020 --> 00:09:26,060
这样就能很好地保持平衡

172
00:09:26,130 --> 00:09:29,850
特别是硬盘 它的延迟一般都很高

173
00:09:29,920 --> 00:09:33,280
不仅是因为光速的原因

174
00:09:33,350 --> 00:09:35,050
实际上 主要的问题是磁头速度

175
00:09:35,120 --> 00:09:36,970
磁头在硬盘磁道上移动

176
00:09:37,070 --> 00:09:39,130
要花费很多时间 因为这是普通物质运动

177
00:09:39,200 --> 00:09:42,510
而在其他存储层 那都不是普通物质运动

178
00:09:42,590 --> 00:09:44,230
那是电子的运动

179
00:09:44,330 --> 00:09:46,670
所以 硬盘真的很慢很延迟

180
00:09:46,730 --> 00:09:48,470
如果你要从硬盘里读取信息

181
00:09:48,540 --> 00:09:51,950
你最好一次就读很多很多

182
00:09:52,020 --> 00:09:55,420
过去一次读取 1MB 的方式弱爆了

183
00:09:55,490 --> 00:09:57,770
你可能要一次读几个MB才行

184
00:09:57,870 --> 00:10:03,000
这样你才能让这两项相均衡

185
00:10:03,480 --> 00:10:06,990
好吧 但这种做法会有个问题

186
00:10:07,830 --> 00:10:09,800
谁能谈谈这会有什么问题？

187
00:10:09,860 --> 00:10:11,350
好好掂量下这个算法

188
00:10:11,430 --> 00:10:14,300
每当它要从硬盘里读取一个元素

189
00:10:14,370 --> 00:10:16,040
它就要把目标元素附近几MB数据

190
00:10:16,110 --> 00:10:19,380
全部都给读出来

191
00:10:21,580 --> 00:10:28,050
这样一来 平摊的花费才比较合适

192
00:10:28,120 --> 00:10:32,280
但实际上 这也有个前提

193
00:10:32,280 --> 00:10:34,980
[学生]:...

194
00:10:35,090 --> 00:10:36,680
[教授]:没错 这个前提就是

195
00:10:36,790 --> 00:10:39,480
读出来的所有数据我都用得上

196
00:10:39,550 --> 00:10:43,190
比如 假设我们每次读取10MB数据

197
00:10:43,260 --> 00:10:47,370
虽然实际上 A[i]才是我们真正请求的

198
00:10:47,440 --> 00:10:52,600
但我们还是得到了一千万个A[i]周边元素

199
00:10:52,710 --> 00:10:54,760
不过要是真的能用得上所有数据

200
00:10:54,760 --> 00:10:58,250
那就真的无敌了

201
00:10:59,220 --> 00:11:05,880
但这好像也是可行的 因为数据分布有空间局部性

202
00:11:06,790 --> 00:11:10,420
好了 我们故事的主线目标是

203
00:11:10,520 --> 00:11:12,790
在这个缓参无关和高效缓存算法的世界中

204
00:11:12,860 --> 00:11:17,830
让你的算法能够这种情况下

205
00:11:17,900 --> 00:11:22,050
有着出色的表现

206
00:11:23,170 --> 00:11:27,590
这就是数据“块化”的思想

207
00:11:27,660 --> 00:11:32,690
我们希望在数据块中所有的元素

208
00:11:32,700 --> 00:11:37,980
或者至少大部分的元素 都能派上用场

209
00:11:39,490 --> 00:11:42,090
这是个连续的数据存储块

210
00:11:42,150 --> 00:11:45,910
所以 这样就是空间局部性了

211
00:11:52,960 --> 00:11:56,030
理想情况下 我们能用上所有元素 但我说

212
00:11:56,100 --> 00:11:58,470
这也得看你的算法如何 因为这也是有技巧的

213
00:11:58,540 --> 00:11:59,780
但那又是另一回事儿了

214
00:11:59,850 --> 00:12:02,220
好吧 如果你要读取数据

215
00:12:02,300 --> 00:12:05,280
譬如说读取10MB的数据到内存里

216
00:12:05,350 --> 00:12:07,540
而你的内存又至少有...

217
00:12:07,610 --> 00:12:10,170
现在你没个4G内存都不好意思说那是电脑了

218
00:12:10,240 --> 00:12:11,470
所以 你能可以往内存里

219
00:12:11,510 --> 00:12:14,650
塞入好多好多的数据块

220
00:12:14,720 --> 00:12:16,530
而你的目标则是 这些数据块在内存的保质期

221
00:12:16,600 --> 00:12:19,970
是越长越好 虽然你不一定会用得上

222
00:12:20,040 --> 00:12:21,570
如果你的算法是时间是线性的 那你就有可能

223
00:12:21,640 --> 00:12:23,910
只对每个元素访问常数次

224
00:12:23,980 --> 00:12:25,050
但这就够了

225
00:12:25,160 --> 00:12:27,730
但如果你的算法时间是高于线性的

226
00:12:27,800 --> 00:12:30,300
那你对数据的访问就不止一次了

227
00:12:30,410 --> 00:12:32,330
这样一来 高效的算法

228
00:12:32,430 --> 00:12:34,290
就不仅是能用上所有元素那么简单

229
00:12:34,400 --> 00:12:36,010
而且使用次数还要越多越好

230
00:12:36,080 --> 00:12:38,160
把数据彻底压榨干了 再让它回硬盘里

231
00:12:38,230 --> 00:12:41,270
而这就是时间局部性

232
00:12:42,870 --> 00:12:51,060
理想情况下 你能不断地重复使用数据块

233
00:12:51,130 --> 00:12:54,070
所以说 既然我们有了缓存——

234
00:12:54,140 --> 00:12:56,410
啊噢 我忘了把它写下来了

235
00:12:56,520 --> 00:12:59,010
人家才不是因为不会拼单词才没写的

236
00:12:59,080 --> 00:13:01,660
人家可是拼词小王子呀

237
00:13:03,490 --> 00:13:05,870
——我们就应该把缓存派上用场

238
00:13:05,940 --> 00:13:08,330
事实上 缓存能储存不止一个数据块的内容

239
00:13:08,390 --> 00:13:12,080
每个缓存都能存好几个块 具体是多少

240
00:13:12,150 --> 00:13:16,480
过会儿 答案自然就会揭晓

241
00:13:16,980 --> 00:13:19,860
好的 这就是我们的主线目标

242
00:13:19,930 --> 00:13:22,710
但到目前为止 这个模型还是有点坑爹

243
00:13:22,750 --> 00:13:24,200
如果你要设计一个算法

244
00:13:24,280 --> 00:13:27,770
让它在这种机子上直接运行

245
00:13:27,850 --> 00:13:29,860
不是不行 只是很有难度

246
00:13:29,930 --> 00:13:33,520
说白了 就是实际不可行

247
00:13:33,590 --> 00:13:36,720
即使这就是计算机真实的样子

248
00:13:37,400 --> 00:13:41,080
在一些理论中和在大部分实践上

249
00:13:41,150 --> 00:13:45,980
我们主要考虑的是 两层存储结构

250
00:13:49,520 --> 00:13:51,400
这样就能把问题简化

251
00:13:51,470 --> 00:13:55,770
从而集中讨论算法

252
00:13:55,850 --> 00:13:58,140
这是对这一个模型的简化

253
00:13:58,240 --> 00:14:01,090
在这个模型里 每一层存储

254
00:14:01,160 --> 00:14:04,530
都有不同的数据块大小 不同的存储大小

255
00:14:04,610 --> 00:14:07,820
这简直比七国还乱 还何谈算法设计

256
00:14:07,890 --> 00:14:11,490
但如果你只考虑两层结构 那就容易多了

257
00:14:11,600 --> 00:14:15,650
所以 假设我们的处理器

258
00:14:15,790 --> 00:14:20,780
它只有一定数量的寄存器

259
00:14:20,850 --> 00:14:23,790
也就是说 只要它存了几个数据

260
00:14:23,860 --> 00:14:26,530
你就能做相加等运算

261
00:14:27,120 --> 00:14:29,830
然后 我们有条非常快的传输线

262
00:14:29,910 --> 00:14:34,820
所以我画得很宽 把它连到缓存里

263
00:14:39,370 --> 00:14:45,880
然后这就是缓存 它的传输线就比较窄了

264
00:14:45,960 --> 00:14:52,350
它连向一个灰常大的存储

265
00:14:56,150 --> 00:14:58,910
我把它称为内存

266
00:15:04,970 --> 00:15:06,850
好的 这就是我们的概要图

267
00:15:06,920 --> 00:15:10,170
它可以代表这个模型中的任意两层

268
00:15:10,240 --> 00:15:13,080
它可以代表三级缓存和内存

269
00:15:13,150 --> 00:15:16,160
这一对的名字可能是最吻合的了

270
00:15:16,240 --> 00:15:18,920
又或者 图里的缓存代表内存

271
00:15:18,990 --> 00:15:21,240
也就是通常说的随机存储器

272
00:15:21,340 --> 00:15:24,740
而图里的内存则对应的是硬盘

273
00:15:24,810 --> 00:15:26,250
因你考虑的情况而异

274
00:15:26,280 --> 00:15:28,890
而通常 当我们有一个程序时

275
00:15:28,930 --> 00:15:32,470
我们通常会假设 程序整个都在内存里

276
00:15:32,540 --> 00:15:34,290
那么 我们就只关心缓存的表现

277
00:15:34,360 --> 00:15:36,260
所以 你的着眼点应该在这两层存储之间

278
00:15:36,300 --> 00:15:38,380
因为那可能就是对程序影响最大的部分

279
00:15:38,490 --> 00:15:41,780
因为这两层之间的读取花费很大

280
00:15:44,020 --> 00:15:46,710
如果你的数据不是都在内存里

281
00:15:46,780 --> 00:15:47,840
你还要读取硬盘数据的话

282
00:15:47,910 --> 00:15:49,890
那你就要更关注这一层了

283
00:15:49,960 --> 00:15:51,760
因为这里的读取花费是航母级的

284
00:15:51,830 --> 00:15:55,270
大概是量标的6次方这么多

285
00:15:55,300 --> 00:15:59,680
但在实践中 你只需要考虑

286
00:15:59,780 --> 00:16:02,840
最为相关的那两层模型就好

287
00:16:02,920 --> 00:16:05,140
好的 现在我要定义一些参数

288
00:16:05,210 --> 00:16:06,920
我把它们称为缓存和内存

289
00:16:06,990 --> 00:16:09,640
这样说会更清楚明了一些 因为我觉得

290
00:16:09,680 --> 00:16:12,380
这里的内存 就是一般内存的感觉

291
00:16:12,450 --> 00:16:13,700
而我们现在要考虑的就是

292
00:16:13,770 --> 00:16:18,410
这一块额外的叫缓存的东西 它的大小是有限的

293
00:16:18,480 --> 00:16:23,980
我们定义 数据块的大小为B

294
00:16:28,270 --> 00:16:33,460
数据块的数量为M/B

295
00:16:36,650 --> 00:16:41,370
所以 缓存的大小就为M

296
00:16:49,110 --> 00:16:54,080
好 内存也分成一个个大小为B的数据块

297
00:16:54,300 --> 00:16:56,700
然后我们假设它是无穷大的

298
00:16:56,770 --> 00:16:59,220
我们并不关心它的大小

299
00:16:59,290 --> 00:17:02,520
假设它是足够大 足以装得下

300
00:17:02,560 --> 00:17:05,370
你的算法程序 数据结构 等等

301
00:17:05,440 --> 00:17:09,010
好的 这就是一般的模型

302
00:17:11,760 --> 00:17:13,640
然后因为某些奇怪的历史原因

303
00:17:13,750 --> 00:17:14,800
黑历史不堪回首啊

304
00:17:14,880 --> 00:17:17,470
这些代号就用大写M和大写B来表示了

305
00:17:17,540 --> 00:17:19,110
虽然M听起来更像内存

306
00:17:19,180 --> 00:17:22,840
但这确实是指缓存 别问我为什么

307
00:17:22,990 --> 00:17:28,150
都是月亮惹的祸

308
00:17:29,600 --> 00:17:31,750
好的 现在这个模型要怎么搞？

309
00:17:31,780 --> 00:17:34,590
它看似挺高端的 但我们要怎么理解它？

310
00:17:34,660 --> 00:17:38,210
首先 我们要假设缓存的速度非常快

311
00:17:38,280 --> 00:17:42,010
所以 处理器访问缓存是一瞬间的事

312
00:17:42,040 --> 00:17:46,720
虽然处理器还是要花时间来做运算

313
00:17:46,790 --> 00:17:49,040
但我假设缓存离处理器很近 不必多管

314
00:17:49,110 --> 00:17:51,610
而内存因为太大了 所以它的距离很远

315
00:17:51,680 --> 00:17:56,920
因此 这个传输线就是一个问题

316
00:17:56,990 --> 00:17:59,030
实际上 这条传输线也是很宽的

317
00:17:59,100 --> 00:18:02,330
不过因为它很长 所以延迟会很高

318
00:18:02,400 --> 00:18:06,940
即使带宽也很高

319
00:18:07,050 --> 00:18:10,040
好的 这里所有的传输都是以块计算的

320
00:18:10,110 --> 00:18:12,480
当你需要某个数据时

321
00:18:12,580 --> 00:18:15,160
处理器就会请求A[i]

322
00:18:15,200 --> 00:18:16,350
请求在存储里的东西

323
00:18:16,420 --> 00:18:20,270
如果它恰好在缓存里 就搞定了 轻松加愉快

324
00:18:20,330 --> 00:18:23,250
否则 你就要从内存里面

325
00:18:23,330 --> 00:18:25,290
读取包含请求元素的一整块数据

326
00:18:25,360 --> 00:18:27,820
把它读到缓存里 如果缓存已满的话

327
00:18:27,820 --> 00:18:29,220
还要先清理旧的数据块

328
00:18:29,230 --> 00:18:31,620
然后处理器才能使用这个数据 继续执行

329
00:18:31,730 --> 00:18:34,340
直到它又访问到不在缓存的数据为止

330
00:18:34,410 --> 00:18:35,950
那就又得请求内存了

331
00:18:36,020 --> 00:18:37,020
当你清理旧数据时

332
00:18:37,090 --> 00:18:41,490
你其实是把它写回到内存里 这就是我们的模型

333
00:18:42,710 --> 00:18:50,960
我们假设访问缓存是不花费时间的

334
00:18:51,930 --> 00:18:57,730
但我们依然要考虑算法的运行时间

335
00:18:57,770 --> 00:19:02,750
我没有对运行时间的定义作任何改动

336
00:19:04,990 --> 00:19:06,410
它还是指运算时间

337
00:19:06,480 --> 00:19:11,870
或者按多线程里的术语来说 它也叫工作

338
00:19:11,880 --> 00:19:15,470
这里写运算时间好了

339
00:19:16,040 --> 00:19:18,380
我们还是要考虑运行时间

340
00:19:18,490 --> 00:19:20,580
然后T(N)还是原来的意思

341
00:19:20,700 --> 00:19:24,510
运行时间只是为了让我们更好地理解

342
00:19:24,590 --> 00:19:27,520
这个模型是怎么运作的 更主要是为了衡量

343
00:19:27,590 --> 00:19:29,760
这个存储系统所能取得的并行度

344
00:19:29,830 --> 00:19:33,100
因为当你访问某个元素时 实际是访问了B个元素

345
00:19:34,100 --> 00:19:37,460
这些都是学过的知识了

346
00:19:37,570 --> 00:19:42,160
而现在我要做的 是计算存储的传输量

347
00:19:47,620 --> 00:19:50,880
因为这是用数据块来传输的 所以应该是

348
00:19:50,950 --> 00:19:55,420
两层存储间的数据块传输量

349
00:19:55,500 --> 00:19:58,690
缓存和内存之间的传输量

350
00:20:08,390 --> 00:20:12,530
那么 存储的传输无非就是读跟写

351
00:20:12,680 --> 00:20:19,870
无非就是这样 这可以写成是

352
00:20:20,440 --> 00:20:29,620
向内存读取和写入的块数量

353
00:20:29,840 --> 00:20:32,160
好的 接下来我要引入一些符号

354
00:20:32,230 --> 00:20:36,740
这些都是新的符号 我们来看看都是些什么

355
00:20:36,810 --> 00:20:41,510
我用MT(N)来表示存储的传输量

356
00:20:41,580 --> 00:20:45,410
用来代替大小为N的数据的传输时间

357
00:20:45,490 --> 00:20:49,600
这真的是一个函数 而且它还不单取决于N

358
00:20:49,670 --> 00:20:53,360
它还取决我们模型中的参数B和M

359
00:20:53,430 --> 00:20:58,390
所以 MT_B,M(N)才是它的完全体

360
00:20:58,460 --> 00:21:00,610
但这就要写一大坨了

361
00:21:00,670 --> 00:21:03,600
所以我还是简写成MT(N)算了

362
00:21:03,670 --> 00:21:06,260
但我所关注的主要还是

363
00:21:06,340 --> 00:21:07,890
函数关于N的增长 额...

364
00:21:07,970 --> 00:21:09,600
其实所有参数的增长我都关注

365
00:21:09,670 --> 00:21:11,900
但我这里能改变的只有N

366
00:21:11,980 --> 00:21:14,210
所以 我就主要关注它了

367
00:21:14,280 --> 00:21:17,330
就像做递归一样 只有N是变化的

368
00:21:17,390 --> 00:21:19,950
我不能递归改变块的大小

369
00:21:20,030 --> 00:21:21,520
我也不能递归改变缓存大小

370
00:21:21,590 --> 00:21:23,530
这些都是给定的 不能改动

371
00:21:23,600 --> 00:21:26,050
所以 我们主要还是改动N

372
00:21:26,130 --> 00:21:29,100
但B和M都会有影响 它们不是常数

373
00:21:29,170 --> 00:21:32,410
它们都是这个模型的参数

374
00:21:32,480 --> 00:21:36,540
简单明了

375
00:21:36,700 --> 00:21:40,420
这也被称为硬盘存取模型

376
00:21:40,490 --> 00:21:46,050
你也可以叫它DAM模型 外部存储模型

377
00:21:46,130 --> 00:21:47,900
或者缓存敏感模型

378
00:21:47,970 --> 00:21:53,020
可能我应该写出来 这是缓存敏感的

379
00:21:53,610 --> 00:21:55,400
一般来说 如果你的算法

380
00:21:55,470 --> 00:21:58,560
是在这种模型上运行的话

381
00:21:58,630 --> 00:22:02,530
那它就是缓存敏感算法

382
00:22:04,370 --> 00:22:06,840
但我们对缓存敏感算法不是很感兴趣

383
00:22:06,950 --> 00:22:10,430
我们学过的B树就是一种

384
00:22:10,510 --> 00:22:12,630
B树是缓存敏感的数据结构

385
00:22:12,670 --> 00:22:15,270
你假设 存储底层有些大小为B的数据块

386
00:22:15,350 --> 00:22:17,200
虽然你可能不清楚整个模型是如何

387
00:22:17,240 --> 00:22:20,350
但重点是 缓存的大小并不重要

388
00:22:20,380 --> 00:22:22,020
因为你只是想知道 当我向缓存读入B个元素

389
00:22:22,100 --> 00:22:24,360
我就会尽可能多地用上其中的元素

390
00:22:24,430 --> 00:22:26,310
并且找到访问元素在这B个元素中的位置

391
00:22:26,380 --> 00:22:31,020
这样存储传输次数就是以B为底的log N

392
00:22:31,070 --> 00:22:33,790
而不是log N（以2为底） 这种结构快多了

393
00:22:33,880 --> 00:22:37,570
抛弃你们心爱的平衡二叉树吧 骚年

394
00:22:37,650 --> 00:22:40,720
以B为底肯定完爆以2为底

395
00:22:40,800 --> 00:22:45,080
B树是一种缓存敏感算法

396
00:22:46,570 --> 00:22:51,030
但我们今天和下堂课要做的

397
00:22:51,100 --> 00:22:54,310
却是缓参无关算法

398
00:23:01,590 --> 00:23:03,190
而实际上 我们只有一个不同点

399
00:23:03,270 --> 00:23:05,750
来区分 缓存敏感算法 和 缓参无关算法

400
00:23:05,820 --> 00:23:07,520
在缓参无关算法中

401
00:23:07,580 --> 00:23:12,850
算法并不知道B和M是多少

402
00:23:22,560 --> 00:23:27,020
这看似很微妙 但却是非常酷炫

403
00:23:27,110 --> 00:23:29,860
你假设这就是计算机的模型

404
00:23:29,930 --> 00:23:31,920
而你关注的又是存储的传输量

405
00:23:31,990 --> 00:23:34,260
大小为B的数据块 从大小为M的缓存

406
00:23:34,370 --> 00:23:37,010
传输到数据块同样为B的内存里

407
00:23:37,080 --> 00:23:39,920
不过 你实际上并不清楚这个模型的具体细节

408
00:23:39,990 --> 00:23:41,610
你不知道这个模型的参数

409
00:23:41,720 --> 00:23:44,140
你知道它大概如此 但你不知道它到底有多宽

410
00:23:44,210 --> 00:23:48,890
它到底有多高 为什么不呢？

411
00:23:48,960 --> 00:23:51,710
在分析里 B和M是已知的

412
00:23:51,790 --> 00:23:53,690
我们接下来要写的算法

413
00:23:53,760 --> 00:23:56,090
都是我们在课堂上曾经学过的

414
00:23:56,130 --> 00:23:57,090
无聊无趣的老算法

415
00:23:57,160 --> 00:23:58,700
但这也是这个模型的优点之一

416
00:23:58,770 --> 00:24:02,220
那就是 我们以前见过的算法都是缓参无关的

417
00:24:02,260 --> 00:24:03,370
没错 因为在此之前

418
00:24:03,450 --> 00:24:06,020
我们并不知道缓存的存在

419
00:24:06,100 --> 00:24:09,780
所以 我们现在能选择的算法很多

420
00:24:09,820 --> 00:24:12,070
值得注意的是 有些算法在这个模型中表现不俗

421
00:24:12,140 --> 00:24:13,680
但某些就不行了 所以我们要

422
00:24:13,740 --> 00:24:16,750
设计出和老算法类似的算法

423
00:24:16,810 --> 00:24:20,110
但又能在这种模型下有良好的表现

424
00:24:20,180 --> 00:24:22,480
而且与B和M无关

425
00:24:22,550 --> 00:24:24,430
换句话说 我们设计的算法

426
00:24:24,570 --> 00:24:28,000
在各种各样的B和M之下都能高效运行

427
00:24:28,040 --> 00:24:30,820
这样才算是好的缓参无关算法

428
00:24:30,890 --> 00:24:34,880
好的 这种假设会推出几个推论

429
00:24:34,990 --> 00:24:38,610
在缓存敏感算法里 你可以确切地说

430
00:24:38,690 --> 00:24:41,880
我把存储分成大小为B的数据块

431
00:24:41,960 --> 00:24:45,610
就像这样 我把B个元素存在一起

432
00:24:45,690 --> 00:24:46,900
因为你知道B的大小 你才能这样做

433
00:24:46,980 --> 00:24:48,460
你还可以说 好吧 我现在想

434
00:24:48,530 --> 00:24:50,460
把B个元素读入到缓存里来

435
00:24:50,540 --> 00:24:52,870
然后覆盖这一部分的内容

436
00:24:52,940 --> 00:24:54,720
你可以明确地管理你的缓存

437
00:24:54,790 --> 00:24:55,960
但在缓参无关算法里

438
00:24:56,040 --> 00:24:58,220
你就不能这样做了 因为你不知道

439
00:24:58,260 --> 00:25:00,370
所有东西都是隐式的

440
00:25:00,400 --> 00:25:02,560
实际上 缓存就是这样运作的

441
00:25:02,630 --> 00:25:04,810
硬盘除外

442
00:25:04,940 --> 00:25:10,890
所以 这是一个非常合理的模型 特别是

443
00:25:10,940 --> 00:25:15,610
当你要访问一个不在缓存内的元素

444
00:25:15,670 --> 00:25:21,120
你就要自动请求包含这个元素的数据块

445
00:25:31,730 --> 00:25:34,270
然后你就要经历一轮的存储传输

446
00:25:34,340 --> 00:25:36,230
因为它不在缓存里

447
00:25:36,300 --> 00:25:41,100
还有一点值得注意的是

448
00:25:41,140 --> 00:25:42,590
你的缓存要是满了怎么办

449
00:25:42,630 --> 00:25:45,760
那你就必须把一个数据块写回

450
00:25:46,020 --> 00:25:48,710
这样一来 我们就要有一个模型来管理

451
00:25:48,780 --> 00:25:50,520
哪一块要被写回 因为我们控制不了

452
00:25:50,590 --> 00:25:54,270
在这种算法里 我们不清楚数据块的细节

453
00:25:55,440 --> 00:26:01,010
所以 我们假设这是一个理想的模型

454
00:26:01,090 --> 00:26:04,050
当你要获取新的数据块时 如果缓存已满

455
00:26:04,120 --> 00:26:12,740
你就把"最长"不会用到的数据块写回

456
00:26:15,660 --> 00:26:19,140
不好意思 是"最久"

457
00:26:19,280 --> 00:26:22,180
最长是距离 最久是时间

458
00:26:22,250 --> 00:26:26,780
未来最久不会用到的数据

459
00:26:26,970 --> 00:26:29,750
好的 这是最完美的方案了

460
00:26:29,820 --> 00:26:31,270
不过在现实中很难做到

461
00:26:31,340 --> 00:26:33,620
因为你不能预知未来

462
00:26:33,660 --> 00:26:34,770
除非你是玛雅人

463
00:26:34,900 --> 00:26:39,170
所以说 这是一个理想的模型

464
00:26:39,210 --> 00:26:43,510
但它也有它的合理性

465
00:26:43,580 --> 00:26:47,680
如果你读过我发的资料20的话就能理解

466
00:26:47,770 --> 00:26:50,020
那是S神和T大的论文

467
00:26:50,090 --> 00:26:52,550
他们引入了竞争性算法的理念

468
00:26:52,620 --> 00:26:55,060
那么 我们只涉及过那篇论文的一小部分

469
00:26:55,130 --> 00:26:59,090
就是列表存储的移前启发式

470
00:26:59,160 --> 00:27:03,020
不过 它也证明了存在一些方法——

471
00:27:03,090 --> 00:27:04,980
你或许已经在习题课上听过了

472
00:27:05,090 --> 00:27:06,930
当然 有些人听过了 有些人没听过

473
00:27:06,970 --> 00:27:10,310
——那就是分页策略

474
00:27:10,350 --> 00:27:13,270
你想要维持一部份数据块或分页在缓存里

475
00:27:13,340 --> 00:27:16,100
而你一旦要访问不在缓存中的数据

476
00:27:16,170 --> 00:27:19,200
你就会有一定的花费

477
00:27:19,300 --> 00:27:21,340
那最好的解决方法 就是把在未来里

478
00:27:21,420 --> 00:27:23,220
最久不会用到的数据写回

479
00:27:23,290 --> 00:27:25,640
因为剩下的数据块你都会用到

480
00:27:25,700 --> 00:27:29,350
这种方法其实是一种离线最优策略

481
00:27:29,420 --> 00:27:30,930
因为前提是预知未来

482
00:27:31,000 --> 00:27:33,300
不过 确实有一些算法

483
00:27:33,370 --> 00:27:36,790
跟这种策略能形成常数竞争关系

484
00:27:36,800 --> 00:27:37,830
但我不想详细说明了

485
00:27:37,900 --> 00:27:40,250
因为它们并不是确切的常数竞争关系

486
00:27:40,290 --> 00:27:43,170
但也足以构成常数竞争关系了

487
00:27:43,210 --> 00:27:45,570
我们可以根据这堂课的主旨来作这种假设

488
00:27:45,640 --> 00:27:48,250
但你们不用想太多 在大多数情况下

489
00:27:48,320 --> 00:27:50,300
我们都不会用到这种假设

490
00:27:50,370 --> 00:27:53,910
但在这里就会用到 这就是缓参无关算法

491
00:27:53,990 --> 00:27:56,250
这样一来思路会更清晰一点

492
00:27:56,290 --> 00:27:59,630
如果我们认为应该发生的事情就会发生的话

493
00:27:59,700 --> 00:28:02,620
你可以用最近最少使用算法来大致模拟

494
00:28:02,690 --> 00:28:07,990
或者你也可以用其他的启发式

495
00:28:08,050 --> 00:28:10,680
更好地逼近最优策略

496
00:28:12,470 --> 00:28:15,570
好吧 缓存无关算法的内容有好多好多

497
00:28:15,630 --> 00:28:17,770
一旦你有了这个两层模型

498
00:28:17,850 --> 00:28:19,580
你就得假设 你不知道B和M

499
00:28:19,660 --> 00:28:24,100
无论是读取还是写入 你都要这样假设

500
00:28:24,680 --> 00:28:27,730
我想 我还要再说一点

501
00:28:28,810 --> 00:28:30,210
虽然现在已经很直观

502
00:28:30,290 --> 00:28:33,190
但我把图都画成表格的形状了

503
00:28:33,260 --> 00:28:35,870
所以 你可能看不出来这是线性顺序

504
00:28:35,940 --> 00:28:39,980
线性顺序其实就是读取顺序

505
00:28:41,520 --> 00:28:46,640
所以 虽然我们不会一直显式地说明

506
00:28:46,710 --> 00:28:51,210
存储的一般模型是线性数组

507
00:28:51,280 --> 00:28:53,760
你的程序的一切数据

508
00:28:53,830 --> 00:28:55,590
都是存在这种线性数组里的

509
00:28:55,660 --> 00:28:58,220
要是你写过汇编什么的 你就明白了

510
00:28:58,290 --> 00:29:00,320
存储模型就是这样 你有一个地址空间

511
00:29:00,470 --> 00:29:01,840
这两头之间的地址都用数字来标记

512
00:29:01,910 --> 00:29:04,270
然后你就可以...这些都是物理存储

513
00:29:04,310 --> 00:29:06,480
都是写入数据的地方

514
00:29:06,550 --> 00:29:08,510
它从0开始 一直延伸到

515
00:29:08,540 --> 00:29:11,000
我们把这里设为无限吧

516
00:29:11,070 --> 00:29:13,090
如果你分配了一个数组

517
00:29:13,180 --> 00:29:16,520
它可能就会在这中间占用了一些空间 谁知道呢？

518
00:29:16,590 --> 00:29:18,900
好吧 我们通常不会管这么多

519
00:29:18,970 --> 00:29:21,130
我现在关注的是存储本身

520
00:29:21,200 --> 00:29:24,930
它是分成一块一块的

521
00:29:25,000 --> 00:29:29,320
无论你怎么存储你的数据

522
00:29:30,290 --> 00:29:34,170
它都是分成一块块大小为B的数据簇

523
00:29:34,240 --> 00:29:38,200
所以 如果这是...还是写成1吧

524
00:29:38,270 --> 00:29:40,900
写1方便多了 那这就是B了

525
00:29:40,940 --> 00:29:42,790
那这里就是B+1

526
00:29:42,890 --> 00:29:47,590
这里就是2B 然后2B+1 如此类推

527
00:29:48,090 --> 00:29:50,200
这就是存储数组的标号

528
00:29:50,270 --> 00:29:51,840
存储就是这么分成数据块的

529
00:29:51,940 --> 00:29:57,450
如果你要访问这里 你就要读取以这个U为中心

530
00:29:57,520 --> 00:30:00,200
往左走 最靠近它的B倍数地址

531
00:30:00,270 --> 00:30:03,550
一直到下一个B倍数地址

532
00:30:03,590 --> 00:30:05,120
你要把这一整块都读出来

533
00:30:05,190 --> 00:30:08,330
那么 如果有一组数组

534
00:30:08,400 --> 00:30:11,690
它被分配到了这里

535
00:30:11,760 --> 00:30:12,590
那你心里就要想着

536
00:30:12,660 --> 00:30:15,250
这个数组跟数据块不是完美对齐的

537
00:30:15,320 --> 00:30:17,780
但因为它基本都会变成这样 所以不用太操心

538
00:30:17,850 --> 00:30:22,310
虽然这里确实有一些细节的事情

539
00:30:22,970 --> 00:30:27,010
好的 关于模型就说这么多了

540
00:30:27,080 --> 00:30:30,300
那么 除了B树以外 每一个我们见过的算法

541
00:30:30,370 --> 00:30:34,470
其实都是缓参无关算法 我们的问题是

542
00:30:34,510 --> 00:30:37,300
我们可以通过运行时间来了解算法的性能

543
00:30:37,370 --> 00:30:40,630
而现在 我们想计算存储传输量

544
00:30:40,710 --> 00:30:43,080
也就是MT(N)

545
00:30:43,150 --> 00:30:46,940
我想提出一个新的事实或定理

546
00:30:47,010 --> 00:30:50,660
我把它写到方括号里

547
00:30:52,410 --> 00:30:55,210
因为我不会写得很严谨

548
00:30:56,460 --> 00:31:01,880
如果一个算法在两层模型中是高效的

549
00:31:01,950 --> 00:31:04,570
换句话说 就是我们要研究的东西

550
00:31:04,570 --> 00:31:06,650
如果它在两层模型中是高效的

551
00:31:06,720 --> 00:31:11,160
而这个算法又是缓参无关算法

552
00:31:12,510 --> 00:31:15,470
那么 它在任意多层的模型中

553
00:31:15,540 --> 00:31:24,720
它总会是高效的 譬如说L层模型

554
00:31:24,800 --> 00:31:26,740
我这里就不详细定义什么是高效了

555
00:31:26,780 --> 00:31:30,470
但直观来说 如果你的机子是这种结构

556
00:31:30,540 --> 00:31:32,300
而你又有一个缓参无关算法

557
00:31:32,380 --> 00:31:36,130
那对于任意的B和M 你都能应用缓参无关分析

558
00:31:36,210 --> 00:31:38,230
那么 你就能分析这个存储传输量

559
00:31:38,300 --> 00:31:41,480
还有这个和这个...

560
00:31:41,530 --> 00:31:44,890
如果你缓存无关算法还不错

561
00:31:44,960 --> 00:31:48,660
那么它在每一层就都会取得很好的性能

562
00:31:48,730 --> 00:31:50,620
因此 总的性能也会很好

563
00:31:50,690 --> 00:31:52,420
很好 == 渐近最优

564
00:31:52,480 --> 00:31:54,510
也就是具有常数阶的竞争性

565
00:31:54,580 --> 00:31:56,510
我这里就不证明了

566
00:31:56,580 --> 00:31:59,350
你可以读一下我的缓参无关论文

567
00:31:59,420 --> 00:32:01,740
里面提到了关于缓参无关算法的有趣的事实

568
00:32:01,780 --> 00:32:03,630
如果你有一个缓存敏感算法

569
00:32:03,700 --> 00:32:07,970
它被设定了具体的B和M的值

570
00:32:08,040 --> 00:32:10,330
那你就失去了这些特性了

571
00:32:10,370 --> 00:32:13,680
所以 这些都是缓参无关的一些美妙的特性

572
00:32:13,750 --> 00:32:17,730
还有一个很爽的事就是 当你敲代码的时候

573
00:32:17,800 --> 00:32:19,740
你不需要定义B和M

574
00:32:19,810 --> 00:32:23,600
拯救程序员于水深火热之中

575
00:32:24,200 --> 00:32:29,530
好的 我们来实际谈谈算法吧

576
00:32:29,610 --> 00:32:32,080
模型已经说完了

577
00:32:34,480 --> 00:32:36,700
那么 我们先从一些简单的东西开始

578
00:32:36,770 --> 00:32:41,220
做实际分析前先热热身

579
00:32:41,290 --> 00:32:42,600
在缓参无关的世界里

580
00:32:42,640 --> 00:32:46,660
你能做到的最基本又有用的事情就是扫描了

581
00:32:48,970 --> 00:32:56,110
扫描的意思就是把数组的元素按顺序访问一遍

582
00:33:00,800 --> 00:33:03,900
从A_1按顺序访问到A_N

583
00:33:03,970 --> 00:33:05,730
而对于访问元素来说 大致上

584
00:33:05,800 --> 00:33:08,250
花费的时间是常数阶的 比如说

585
00:33:08,320 --> 00:33:10,500
假设你要计算数组元素的总和

586
00:33:10,570 --> 00:33:12,660
你要把每一个数组元素加起来

587
00:33:12,710 --> 00:33:15,310
那你就用一个额外的变量来存结果

588
00:33:15,380 --> 00:33:17,600
它可以存放在寄存器里面

589
00:33:17,670 --> 00:33:24,180
这就是一个简单的例子 数组求和

590
00:33:26,140 --> 00:33:31,870
好的 我画一幅图 这就是我们的内存

591
00:33:34,040 --> 00:33:38,550
每一个单元都表示一个元素

592
00:33:38,620 --> 00:33:40,590
log N个位 或者一个字 等等

593
00:33:40,660 --> 00:33:46,820
我们的数组在这里 也可能是那里

594
00:33:46,850 --> 00:33:51,000
我们要访问这里 这里 和这里

595
00:33:51,080 --> 00:33:54,430
如此类推  那花费是多少

596
00:33:54,480 --> 00:33:55,680
存储传输量是多少

597
00:33:55,750 --> 00:33:57,440
我们知道这是一个线性时间算法

598
00:33:57,510 --> 00:33:59,710
它花费N阶的时间

599
00:33:59,810 --> 00:34:03,380
那它花费多少存储传输量呢

600
00:34:06,670 --> 00:34:09,910
N/B 就是这么多

601
00:34:14,540 --> 00:34:17,850
准确来说 是N/B阶的

602
00:34:17,920 --> 00:34:25,390
再加上2或者1 大O记号 有点不对喔

603
00:34:25,450 --> 00:34:27,030
因为N可能比B还要小

604
00:34:27,100 --> 00:34:29,560
我们需要考虑到所有的情况

605
00:34:29,560 --> 00:34:31,840
特别是因为 你通常也不是用N来计算

606
00:34:31,910 --> 00:34:34,030
你一般用的是k

607
00:34:34,100 --> 00:34:36,420
而k则是一个我们不确定的数

608
00:34:36,490 --> 00:34:38,940
但一般而言 它就是O(N/B+1)

609
00:34:39,010 --> 00:34:41,810
因为我们至少要传输一个数据块

610
00:34:41,920 --> 00:34:45,090
才能够做访问操作 除非N是0

611
00:34:45,160 --> 00:34:47,160
值得注意的是

612
00:34:47,230 --> 00:34:50,440
如果常数也要考虑 那这就是+2了

613
00:34:50,540 --> 00:34:53,220
如果我不把它写进大O记号里 那它就是+2

614
00:34:53,290 --> 00:34:57,120
因为第一块基本就浪费掉了

615
00:34:57,180 --> 00:34:59,620
而后面的数据块就会是对齐的

616
00:34:59,700 --> 00:35:01,310
但如果你很不走运的话

617
00:35:01,380 --> 00:35:03,110
那最后一个数据块也会浪费掉

618
00:35:03,180 --> 00:35:04,470
一个数据块只有一个可用元素

619
00:35:04,540 --> 00:35:06,350
剩余的空间就浪费了

620
00:35:06,420 --> 00:35:07,990
但数组中间的部分

621
00:35:08,090 --> 00:35:11,300
中间的这些数据块就都是对齐的

622
00:35:11,400 --> 00:35:13,010
这些元素你都会用上

623
00:35:13,120 --> 00:35:16,080
所以 对于N个元素的数组 你只有N/B个数据块

624
00:35:16,130 --> 00:35:17,840
因为一块里面有B个元素

625
00:35:17,910 --> 00:35:20,450
这都是些琐碎事情

626
00:35:20,500 --> 00:35:26,340
我们来看看一些有趣点的事吧

627
00:35:29,830 --> 00:35:33,370
那就是一次做两个扫描

628
00:35:36,420 --> 00:35:40,180
好的 在此我们对M不做任何要求

629
00:35:40,220 --> 00:35:42,990
我们不对缓存大小做任何要求

630
00:35:43,560 --> 00:35:45,250
只要能装下一个数据块就好

631
00:35:45,320 --> 00:35:50,120
我们最后访问到的数据块必须在缓存里

632
00:35:50,140 --> 00:35:54,580
好的 其实你可以做任意常数的并行扫描

633
00:35:54,620 --> 00:35:56,630
在多线程思想看来

634
00:35:56,700 --> 00:36:01,740
这并不是严格的并行化 而是模拟并行化

635
00:36:01,780 --> 00:36:02,820
如果做常数次扫描

636
00:36:02,900 --> 00:36:04,500
那就做第一次 跳去做另一次

637
00:36:04,580 --> 00:36:05,890
回来做第一次 再跳去做另一次

638
00:36:05,960 --> 00:36:08,420
来回同时地做几次扫描

639
00:36:08,490 --> 00:36:14,170
比如说 这有段挺好玩的代码

640
00:36:14,280 --> 00:36:17,810
如果你要翻转一个数组

641
00:36:18,780 --> 00:36:24,980
好的 我们来试下手 这是个好问题

642
00:36:31,210 --> 00:36:34,950
你用两次扫描就能把它做出来

643
00:36:35,020 --> 00:36:39,630
只要不断交换第一个和最后一个元素就好

644
00:36:39,700 --> 00:36:47,240
那我就交换A_i和A_N-i+1

645
00:36:47,270 --> 00:36:55,180
然后从一开始循环 那么 这就是目标数组

646
00:36:55,290 --> 00:36:57,030
假设这真的是我们的数组

647
00:36:57,100 --> 00:37:00,510
我交换这两个元素 我再交换两个元素 如此类推

648
00:37:00,580 --> 00:37:03,460
然后就得到翻转的数组了

649
00:37:03,540 --> 00:37:05,870
如果元素个数是奇数 那到了中间

650
00:37:05,940 --> 00:37:09,590
它就不做任何事

651
00:37:09,670 --> 00:37:13,340
你可以把这看成是两次扫描

652
00:37:13,430 --> 00:37:14,810
一次是从这边扫

653
00:37:14,860 --> 00:37:17,030
一次是反过来扫

654
00:37:17,170 --> 00:37:19,070
好像挺复杂 从这边扫过去

655
00:37:19,140 --> 00:37:21,400
当然 反着扫的性能分析是一样的

656
00:37:21,470 --> 00:37:24,800
只要你的缓存足够大

657
00:37:24,860 --> 00:37:26,860
装得下两个数据块就行

658
00:37:26,930 --> 00:37:30,430
这个假设不过分吧？

659
00:37:35,000 --> 00:37:36,800
那我们就写下来

660
00:37:36,970 --> 00:37:40,840
假设缓存中的数据块数量

661
00:37:40,910 --> 00:37:45,650
也就是M/B 在这个算法中 至少是两个

662
00:37:45,720 --> 00:37:49,830
那存储的传输量就依然

663
00:37:49,890 --> 00:37:53,770
还是O(N/B+1)阶

664
00:37:55,430 --> 00:37:57,370
好吧 常数项可能会增大

665
00:37:57,470 --> 00:38:01,010
但它也有可能不增大 管他呢

666
00:38:01,160 --> 00:38:03,650
只要你是在做常数个的数组里

667
00:38:03,720 --> 00:38:05,290
做常数次的扫描

668
00:38:05,360 --> 00:38:07,810
可能有些扫描是另一个的翻转

669
00:38:07,880 --> 00:38:10,850
它都要 线性的时间花费

670
00:38:10,930 --> 00:38:13,450
它跟你要读入的数据块成线性关系

671
00:38:13,520 --> 00:38:19,700
正啊！ 现在你学会翻转数组了 涨姿势了！

672
00:38:19,750 --> 00:38:32,230
我们再来试试另外一种简单的算法

673
00:38:45,550 --> 00:38:54,170
我们试试二分搜索 就像上星期

674
00:38:54,250 --> 00:38:56,040
我们回到我们的基础

675
00:38:56,120 --> 00:38:58,850
扫描算法其实还没讲过呢

676
00:38:58,890 --> 00:39:00,790
二分搜索倒是讲过一点点

677
00:39:00,850 --> 00:39:02,980
这是一个简单的分治法算法

678
00:39:03,100 --> 00:39:08,760
希望你们都能记牢 当我们观察一个数组时

679
00:39:08,840 --> 00:39:10,140
我这里就不把单元格都画出来了

680
00:39:10,210 --> 00:39:12,490
因为我想把它想象成一个超大型数组

681
00:39:12,570 --> 00:39:14,690
开始二分搜索 假设目标在左边

682
00:39:14,740 --> 00:39:17,080
我们先访问中间的元素

683
00:39:17,140 --> 00:39:19,200
然后它跳到1/4点

684
00:39:19,280 --> 00:39:21,380
然后再跳到1/8点

685
00:39:21,450 --> 00:39:26,810
好的 这就是我们假想的二分搜索

686
00:39:27,080 --> 00:39:29,250
最终 我们找到了我们要找的元素

687
00:39:29,310 --> 00:39:31,440
它就在不偏不倚的地方

688
00:39:31,510 --> 00:39:37,430
所以x就在这里 我们知道这要花费log N的时间

689
00:39:37,570 --> 00:39:41,320
那这里有多少存储传输量

690
00:39:42,260 --> 00:39:46,420
现在 我把这个数组分成大小为B的小块

691
00:39:46,530 --> 00:39:50,190
大小为B 那我一共要访问多少块

692
00:39:50,290 --> 00:39:53,590
好像越来越微妙了

693
00:40:16,150 --> 00:40:18,770
这取决于N和B的相对大小 耶啊

694
00:40:20,320 --> 00:40:22,910
以B为底的log N是一个不错的选择

695
00:40:22,980 --> 00:40:25,410
我们希望它会是

696
00:40:25,420 --> 00:40:30,850
希望它是log_B(N)  因为我们知道

697
00:40:30,900 --> 00:40:34,130
B树的搜索就是这样

698
00:40:34,220 --> 00:40:36,650
它本质上就是用log_B(N)的时间 搜索一个顺序表

699
00:40:36,710 --> 00:40:40,450
这其实就是缓参无关模型里的最优解

700
00:40:40,520 --> 00:40:42,170
或者说两层模型里的

701
00:40:42,240 --> 00:40:44,220
你必须花费log_B(N)时间

702
00:40:44,280 --> 00:40:46,070
我就不证明了

703
00:40:46,140 --> 00:40:49,350
这跟普通的二分搜索

704
00:40:49,470 --> 00:40:53,020
需要做log N步比较是一样道理

705
00:40:53,090 --> 00:40:57,510
可惜啊 就算不知道B是多少

706
00:40:57,580 --> 00:41:03,300
取得log_B(N)也是可能的 只是二分搜索做不到

707
00:41:07,080 --> 00:41:09,920
正确答案是log N/B

708
00:41:15,430 --> 00:41:18,670
所以 N个元素的存储传输量

709
00:41:18,740 --> 00:41:24,950
就是log N/B 又可以看做是——漏了个+1

710
00:41:25,050 --> 00:41:29,890
也可以看做是log N - log B

711
00:41:31,030 --> 00:41:38,110
而log_B(N)则可以看成log N / log B

712
00:41:38,340 --> 00:41:41,900
很显然 除法要比减法强多了

713
00:41:41,980 --> 00:41:45,160
所以 这个是牛叉 这个是渣渣

714
00:41:45,190 --> 00:41:47,300
大部分情况下 这里就是log N

715
00:41:47,370 --> 00:41:50,200
这跟没有划分数据块的情况一样

716
00:41:50,270 --> 00:41:52,070
并没有什么改善

717
00:41:52,140 --> 00:41:53,950
正确的思路是 这个地方

718
00:41:54,050 --> 00:41:56,380
有个很小的数据块包含了这个二分点

719
00:41:56,450 --> 00:41:59,600
当然“很小”也要取决于B的大小

720
00:41:59,630 --> 00:42:02,000
但这些二分点一般都会在不同的数据块之中

721
00:42:02,070 --> 00:42:07,310
直到你的数据块包含了x为止

722
00:42:07,410 --> 00:42:08,590
当你搜索到包含x的数据块时

723
00:42:08,660 --> 00:42:11,230
你可能再搜索几步就到达x了

724
00:42:11,340 --> 00:42:14,420
而这时 这个数据块就包含了接下来所有的二分点

725
00:42:14,490 --> 00:42:16,940
有多少个这样的二分点 就是log B个

726
00:42:17,010 --> 00:42:18,670
因为你只需要通过log B步搜索

727
00:42:18,740 --> 00:42:21,150
就像 当你在一个大小为k的区间里

728
00:42:21,220 --> 00:42:24,250
你就只要做log k步搜索

729
00:42:24,330 --> 00:42:26,050
所以 这里你就可以省掉log B了

730
00:42:26,160 --> 00:42:27,220
但全局来讲 你的花费是log N

731
00:42:27,290 --> 00:42:31,040
所以 你就得到了log N - log B加上一个常数

732
00:42:31,670 --> 00:42:33,750
所以 这对于二分搜索是个坏消息

733
00:42:33,820 --> 00:42:35,610
不是所有的算法

734
00:42:35,650 --> 00:42:37,100
都适合这种模型

735
00:42:37,170 --> 00:42:39,650
我们在解决二分搜索的问题前

736
00:42:39,710 --> 00:42:41,340
还要先考虑很多的东西

737
00:42:41,450 --> 00:42:43,370
在不知道B的情况下 要如何

738
00:42:43,420 --> 00:42:46,890
用log_B(N)的时间搜索顺序表

739
00:42:47,190 --> 00:42:49,180
好吧 我们可以用B树

740
00:42:49,250 --> 00:42:54,360
如果你知道B的话 正！搞定了 而且是最优解

741
00:42:54,470 --> 00:42:57,520
但我们不知道B 这就有难度了

742
00:42:57,590 --> 00:43:00,870
然后 我们就看到分治法的圣光在召唤了

743
00:43:03,110 --> 00:43:06,200
就像上周一样

744
00:43:06,280 --> 00:43:09,560
同时也像最开始那几周一样

745
00:43:10,780 --> 00:43:13,540
分治法与你同在！

746
00:43:18,130 --> 00:43:21,530
其实 分治法不是唯一的方法

747
00:43:21,600 --> 00:43:22,960
但对于设计缓参无关算法来说

748
00:43:23,030 --> 00:43:30,010
它确实好使好用 我来解释下为什么

749
00:43:42,320 --> 00:43:45,620
那么 我们将会看到很多分治法算法

750
00:43:46,350 --> 00:43:48,520
都是缓参无关的

751
00:43:49,230 --> 00:43:53,470
直观来看

752
00:43:53,640 --> 00:43:56,420
我们可以我们喜爱的算法都拿来谈谈

753
00:43:56,530 --> 00:43:58,220
虽然这肯定不是都起作用

754
00:43:58,300 --> 00:44:00,000
二分法就是一个分治法算法

755
00:44:00,070 --> 00:44:02,240
它的表现并不太好 但一般来说

756
00:44:02,280 --> 00:44:05,420
我们要的就是 算法能够做出

757
00:44:05,490 --> 00:44:07,430
分治法所做的事 对吧

758
00:44:07,520 --> 00:44:09,420
你把你的问题分成子问题

759
00:44:09,490 --> 00:44:11,410
把问题越分不断细化

760
00:44:11,480 --> 00:44:16,020
直到问题分成了常数的大小

761
00:44:17,610 --> 00:44:22,440
好的 跟以前一样 但如果你不断递归

762
00:44:22,510 --> 00:44:24,500
把大问题分成小问题

763
00:44:24,570 --> 00:44:26,660
到一定程度时 你可能就会想到

764
00:44:26,730 --> 00:44:28,590
等一等 算法还在不断地细分

765
00:44:28,660 --> 00:44:30,130
但我们可以想 到了某个地步

766
00:44:30,160 --> 00:44:33,410
问题刚好吻合数据块的大小或者缓存的大小

767
00:44:33,520 --> 00:44:35,400
好的 这就是分析节奏了

768
00:44:35,470 --> 00:44:39,730
我们要考虑 当问题被充分细分

769
00:44:39,800 --> 00:44:41,710
我们就能用另外的方法来分析了

770
00:44:41,780 --> 00:44:44,700
通常我们都用递归分析 建立一个迭代过程

771
00:44:44,760 --> 00:44:47,640
要改变的 基本上就只有考虑最小子问题的单位情况

772
00:44:50,010 --> 00:44:51,520
那么 在单位情况中

773
00:44:51,590 --> 00:44:53,740
我们不想细分到常数大小

774
00:44:53,850 --> 00:44:57,780
因为那样已经太过了 我举些例子

775
00:44:57,850 --> 00:45:01,950
我想考虑的是在递归过程中

776
00:45:01,990 --> 00:45:07,660
问题大小刚好与缓存大小吻合的一刻

777
00:45:11,710 --> 00:45:15,440
所以 问题大小小于或等于M

778
00:45:15,540 --> 00:45:20,980
又或者刚好是一个数据块大小

779
00:45:21,050 --> 00:45:23,380
这又是一个恰当的时机

780
00:45:27,200 --> 00:45:30,540
跟块大小吻合其实比跟缓存吻合还要好

781
00:45:30,610 --> 00:45:32,850
所以 这就是B阶的大小

782
00:45:35,310 --> 00:45:39,580
好的 这就要改变迭代的单位情况了

783
00:45:39,650 --> 00:45:41,010
而且 结果其实蛮不错

784
00:45:41,080 --> 00:45:45,160
一点都不赖 我们来做个简单的例子吧

785
00:45:46,380 --> 00:45:50,940
接下来要登场的是——顺序统计量

786
00:45:52,590 --> 00:45:55,210
它是求中位数时 你最好的朋友

787
00:45:59,300 --> 00:46:02,350
所以 我希望你们都能狠狠地记住它

788
00:46:02,460 --> 00:46:06,180
下面是最坏情况线性时间

789
00:46:06,250 --> 00:46:10,790
布霖教授等人的求中位数算法

790
00:46:10,860 --> 00:46:14,750
我会写的很快 我们先给数组分段

791
00:46:14,820 --> 00:46:17,090
这真的是一个感人至深的好算法

792
00:46:17,200 --> 00:46:27,290
我们有意地把数组分为N/5段

793
00:46:27,400 --> 00:46:31,570
每一段里面有5个元素

794
00:46:31,640 --> 00:46:33,500
这可能跟我以前写的有所不同

795
00:46:33,570 --> 00:46:38,860
但我不纠结了 毕竟算法是一样的

796
00:46:39,570 --> 00:46:44,130
然后 求出每5个元素的中位数

797
00:46:47,430 --> 00:46:50,760
然后 你再递归计算出

798
00:46:50,830 --> 00:46:54,810
这些中位数之中的中位数X

799
00:47:08,960 --> 00:47:12,550
然后 用中位数X把数组分为两段

800
00:47:13,030 --> 00:47:15,190
然后 就会得到一些大致在中间的数

801
00:47:15,260 --> 00:47:18,910
至少是在中间的那一片

802
00:47:19,330 --> 00:47:25,040
再用X来将数组对半分 然后我们表示

803
00:47:25,090 --> 00:47:28,460
我们总能在某一半上 递归求出中位数

804
00:47:36,760 --> 00:47:39,320
好的 这个算法是我们的好朋友

805
00:47:39,390 --> 00:47:42,800
无论是求顺序统计量 还是中位数神马的

806
00:47:43,680 --> 00:47:46,340
那这要用多少时间呢 啊

807
00:47:46,410 --> 00:47:47,580
我们已经知道答案了

808
00:47:47,650 --> 00:47:48,630
就是线性的时间

809
00:47:48,690 --> 00:47:53,950
但它又要用多少存储传输量呢

810
00:47:54,020 --> 00:47:57,390
在这里 有意划分也就是说 我可以不划分

811
00:47:57,400 --> 00:47:59,390
可能我有必要划分成N/5段 但这不重要

812
00:47:59,410 --> 00:48:01,920
我们又不是在考虑计算量

813
00:48:02,030 --> 00:48:05,420
我想找出每一小段的中位数

814
00:48:05,490 --> 00:48:08,000
所以 数组元素的分布就会有影响

815
00:48:08,040 --> 00:48:12,620
但是 我要做的是选择我的数组

816
00:48:12,690 --> 00:48:15,360
选择前5个元素

817
00:48:15,400 --> 00:48:18,610
接着 再选择5个元素 如此类推

818
00:48:18,720 --> 00:48:20,950
每个小段有5个元素

819
00:48:21,290 --> 00:48:23,610
所以 我可以直接用扫描

820
00:48:23,760 --> 00:48:26,200
求出这5个元素的中位数

821
00:48:26,240 --> 00:48:28,210
它们可以直接存在CPU的寄存器里

822
00:48:28,250 --> 00:48:30,830
我假设寄存器是足够的

823
00:48:30,860 --> 00:48:33,730
然后 我求出中位数

824
00:48:33,800 --> 00:48:37,130
把它写在一个数组里

825
00:48:37,350 --> 00:48:38,680
然后这就有了一个元素

826
00:48:38,750 --> 00:48:40,120
这小段的中位数写在这儿

827
00:48:40,190 --> 00:48:42,000
这小段的中位数写在这儿 如此类推

828
00:48:42,070 --> 00:48:43,340
我一边扫描这个数组

829
00:48:43,380 --> 00:48:45,580
一边并发地扫描这个输出数组

830
00:48:45,620 --> 00:48:47,110
两个并行扫描

831
00:48:47,180 --> 00:48:48,900
都是线性的时间

832
00:48:49,170 --> 00:48:57,470
所以 这就需要N/B+1的传输量

833
00:48:57,530 --> 00:49:01,870
然后我们递归地求出中位数的中位数

834
00:49:01,940 --> 00:49:07,250
这一步的花费本来是T(N/5）

835
00:49:07,320 --> 00:49:10,140
现在则是MT(N/5)

836
00:49:10,210 --> 00:49:12,540
用的是一样的参数B和M

837
00:49:12,570 --> 00:49:14,150
然后用X来将数组分成两半

838
00:49:14,190 --> 00:49:17,330
分段跟三重并行扫描相似

839
00:49:17,410 --> 00:49:19,000
你试试就知道了

840
00:49:19,070 --> 00:49:26,110
所以 这也要用线性的存储传输量

841
00:49:26,180 --> 00:49:28,200
是N/B+1

842
00:49:28,270 --> 00:49:30,590
接着 我们对数组某一边进行递归

843
00:49:30,630 --> 00:49:33,550
这是当时分析中最有趣的部分

844
00:49:33,590 --> 00:49:35,010
我就不再安可了

845
00:49:35,080 --> 00:49:39,350
但我们得到的是MT(3N/4)

846
00:49:39,420 --> 00:49:40,670
原本应该是7/10的

847
00:49:40,710 --> 00:49:42,200
不过我们化简成3/4了

848
00:49:42,270 --> 00:49:45,610
这应该是比7/10要大

849
00:49:45,680 --> 00:49:51,730
应该没错 好的 这就是新的分析

850
00:49:51,800 --> 00:49:54,010
现在 我们得到了一条递归式

851
00:49:54,140 --> 00:49:57,060
那就来解这条式吧

852
00:50:14,040 --> 00:50:22,390
根据分析 我们有MT(N)等于MT(N/5)

853
00:50:22,460 --> 00:50:29,440
加上MT(3N/4) 这都跟以前一样

854
00:50:29,510 --> 00:50:31,840
以前 这里是线性的工作量

855
00:50:31,910 --> 00:50:33,210
而现在 它就变成了

856
00:50:33,270 --> 00:50:37,200
线性的存储传输量 线性数量的数据块

857
00:50:37,430 --> 00:50:41,610
我大概会省略掉这个+1 因为它不是很重要

858
00:50:43,730 --> 00:50:47,420
好了 这就是我们的递归式

859
00:50:47,490 --> 00:50:49,400
现在就看单位情况怎么定义了

860
00:50:49,470 --> 00:50:53,520
通常 单位情况都会定义成常数大小

861
00:50:53,600 --> 00:50:55,360
那我们就来看看

862
00:50:56,090 --> 00:50:58,790
单位情况是常数大小会如何

863
00:50:58,790 --> 00:51:02,220
我们要弄清楚 为什么这个单位情况很重要

864
00:51:02,330 --> 00:51:06,310
这种式子就是我们所说的毛烦递归

865
00:51:06,420 --> 00:51:09,140
我不会真的用替换法解出来

866
00:51:09,180 --> 00:51:10,930
我只是想直观地说明

867
00:51:11,000 --> 00:51:14,150
这条式解出来是一个很大的东西

868
00:51:14,500 --> 00:51:18,140
对我而言 最好的直观的做法就是递归树

869
00:51:18,210 --> 00:51:20,110
如果你事先不知道递归式的解

870
00:51:20,210 --> 00:51:23,230
而你又需要一个好的猜想 那就用递归树吧

871
00:51:23,260 --> 00:51:25,680
因为今天 我只想给出一个好的猜想

872
00:51:25,740 --> 00:51:27,760
我不想用替换法来做证明

873
00:51:27,800 --> 00:51:29,920
因为我的目标是讨论更大的课题

874
00:51:29,960 --> 00:51:34,690
其实从递归树的角度来看 这可能还会更麻烦

875
00:51:34,730 --> 00:51:37,430
因为你会得到的树是不平衡的

876
00:51:37,500 --> 00:51:40,130
一开始 你的根的大小为N/B

877
00:51:40,200 --> 00:51:45,630
然后它岔开成一个N/5B的分支

878
00:51:45,740 --> 00:51:49,460
和一个3N/4B的分支

879
00:51:49,530 --> 00:51:51,430
这有点麻烦 因为这边的子树

880
00:51:51,500 --> 00:51:53,570
会比这一边的要大

881
00:51:53,630 --> 00:51:55,510
这边会结束的更快

882
00:51:55,580 --> 00:51:58,120
所以 这会变得很不平衡 但我们可以

883
00:51:58,200 --> 00:52:01,350
对每一层都求和好像也帮不了你

884
00:52:01,420 --> 00:52:03,140
但我们来看看最底层

885
00:52:03,210 --> 00:52:05,880
看看这棵树的叶节点

886
00:52:05,920 --> 00:52:07,590
那它们就是单位情况了

887
00:52:07,630 --> 00:52:10,240
那会有多少个单位情况呢

888
00:52:10,380 --> 00:52:11,410
这个问题很有趣

889
00:52:11,480 --> 00:52:14,140
因为这是条递归式 所以我们从没想过

890
00:52:14,210 --> 00:52:15,890
它会给出一个很意外的结果

891
00:52:15,960 --> 00:52:20,960
当我第一次算出来时 我就觉得很意外

892
00:52:23,690 --> 00:52:28,610
那么 这棵递归树会有多少个叶节点

893
00:52:28,670 --> 00:52:33,720
额 我们可以再写一条递归式

894
00:52:33,730 --> 00:52:37,400
这个大小为N的问题里 叶节点的数量

895
00:52:37,470 --> 00:52:39,060
等于这个子问题的叶节点数

896
00:52:39,100 --> 00:52:42,330
加上这个子问题的叶节点数 再加0

897
00:52:42,370 --> 00:52:43,910
好的 我们又得到一条递归式

898
00:52:43,980 --> 00:52:45,830
我们可以叫它L(N)

899
00:52:56,340 --> 00:52:58,770
现在 这个单位情况就很重要了

900
00:52:58,840 --> 00:53:01,550
它决定了这个主问题的解

901
00:53:01,610 --> 00:53:04,880
那让我们再次假设问题大小为1的情况

902
00:53:04,950 --> 00:53:09,070
我们有一个叶节点 这就是我们的单位情况

903
00:53:10,750 --> 00:53:14,670
我觉得呢 其实我们这里应该要猜想一下

904
00:53:14,710 --> 00:53:16,590
因为这并不明显

905
00:53:16,660 --> 00:53:20,240
有没有助教能猜到 这个解的形式是怎么样的

906
00:53:20,310 --> 00:53:22,030
谁都行 不仅是助教

907
00:53:22,100 --> 00:53:24,710
这就像比智招亲啊

908
00:53:24,780 --> 00:53:27,880
如果查哥在的话 我肯定会问他

909
00:53:28,930 --> 00:53:32,850
我们来考虑一下 这应该不是线性的对吧

910
00:53:32,920 --> 00:53:35,440
因为它每一步都递减不少

911
00:53:35,590 --> 00:53:36,980
它应该比线性还要小

912
00:53:37,020 --> 00:53:38,390
但又比常数要大

913
00:53:38,460 --> 00:53:43,000
实际上 它也比log多项式要大

914
00:53:43,390 --> 00:53:47,270
那么 你们还能想到什么更中间的函数？

915
00:53:49,810 --> 00:53:52,450
N/logN 还是太大了

916
00:53:53,110 --> 00:53:56,520
继续想 爆种吧 骚年

917
00:53:56,590 --> 00:53:59,470
N^k 嗯嗯 很接近了

918
00:53:59,540 --> 00:54:01,020
我是说 k通常是个整数

919
00:54:01,130 --> 00:54:04,010
不如说是N^α  0到1之间的实数

920
00:54:04,080 --> 00:54:05,010
你说的是这个吧

921
00:54:05,050 --> 00:54:08,260
抱歉 这就像是最短数学的冷笑话

922
00:54:08,300 --> 00:54:11,520
令ε小于0 又或者

923
00:54:11,530 --> 00:54:14,980
令ε充分大 好冷

924
00:54:15,050 --> 00:54:18,600
所以说 符号很重要

925
00:54:18,700 --> 00:54:21,870
那我们假设它是N^α

926
00:54:22,780 --> 00:54:29,600
所以我们得到 这是(N/5)^α

927
00:54:29,670 --> 00:54:33,710
这个是(3N/4)^α

928
00:54:33,780 --> 00:54:35,240
当你的递归式是这么有美感的话

929
00:54:35,290 --> 00:54:39,510
你就可以直接猜一个结果代入 看看可不可行

930
00:54:39,620 --> 00:54:42,980
这当然是对的咯 只要α找对

931
00:54:43,080 --> 00:54:45,690
那么 我们会得到一个关于α的方程

932
00:54:45,730 --> 00:54:48,380
所有东西都是N^α

933
00:54:48,450 --> 00:54:49,830
没错 每一项都是

934
00:54:49,870 --> 00:54:51,950
那么 我可以两边都除以N^α

935
00:54:52,020 --> 00:54:54,290
这相当于假设它不为0

936
00:54:54,330 --> 00:54:55,560
挺合理的嘛

937
00:54:55,630 --> 00:55:00,060
那么 我们有1等于(1/5)^α

938
00:55:00,150 --> 00:55:02,600
加上(3/4)^α

939
00:55:02,640 --> 00:55:05,030
放心 这个期末不会考

940
00:55:05,060 --> 00:55:07,040
因为我都不知道有什么好的解法

941
00:55:07,110 --> 00:55:09,240
这时用Maple或Mathematica就好了

942
00:55:09,280 --> 00:55:12,430
要是你很有才的话 你一样能很好地解出来

943
00:55:12,480 --> 00:55:22,530
而结果大致是α=0.8

944
00:55:22,880 --> 00:55:27,850
所以 叶节点的数量

945
00:55:27,890 --> 00:55:32,250
介乎于常数和线性之间

946
00:55:32,320 --> 00:55:36,880
虽然一般多项式都是指整数幂

947
00:55:40,020 --> 00:55:42,510
我们姑且叫它多项式吧

948
00:55:43,860 --> 00:55:46,520
重点是这有很多的叶节点

949
00:55:46,590 --> 00:55:47,830
如果每一个都要花费

950
00:55:47,910 --> 00:55:51,070
常数阶的存储传输量 我们就有麻烦了

951
00:55:51,110 --> 00:55:52,880
因为如果这样 存储的传输量

952
00:55:52,950 --> 00:55:57,030
至少都有这么多 如果这是至少的话

953
00:55:57,090 --> 00:56:00,880
它就很有可能超越N/B

954
00:56:00,990 --> 00:56:02,560
如果用渐进分析来看的话

955
00:56:02,630 --> 00:56:10,540
这个就是ω(N/B) 如果B足够大...

956
00:56:10,690 --> 00:56:15,520
如果B至少有N^0.2这么大

957
00:56:17,970 --> 00:56:19,350
或者是N^(1/7)这么大

958
00:56:19,390 --> 00:56:22,680
如果B恰恰至少是N^0.2这么大

959
00:56:22,720 --> 00:56:25,720
那么这个就会比它要大了

960
00:56:25,790 --> 00:56:27,690
所以根据分析 这也不给力

961
00:56:27,730 --> 00:56:29,790
因为它是不我们想要的 不是N/B

962
00:56:29,830 --> 00:56:31,870
求中位数最好的性能是N/B

963
00:56:31,940 --> 00:56:33,140
因为你必须读取所有的元素

964
00:56:33,170 --> 00:56:34,880
你必须花费线性的时间

965
00:56:35,130 --> 00:56:36,340
所以 我们要的是N/B

966
00:56:36,410 --> 00:56:39,180
这个算法是N/B+1

967
00:56:39,250 --> 00:56:42,720
所以 这就是为什么单位情况那么重要的原因了

968
00:56:42,800 --> 00:56:45,930
这就说到点上了

969
00:56:45,970 --> 00:56:51,030
那么问题就来了 我要用什么样的单位情况呢

970
00:57:02,460 --> 00:57:05,660
现在 我们有这条递归式

971
00:57:19,380 --> 00:57:24,650
我应该给它什么样的单位条件 常数就太小了

972
00:57:24,800 --> 00:57:29,030
上面这里列出了好几种选择

973
00:57:44,970 --> 00:57:46,860
元芳 你怎么看

974
00:57:48,080 --> 00:57:54,680
B 好的 MT(B)是多少

975
00:57:54,750 --> 00:57:58,270
啊哈 被难住了吧

976
00:57:58,390 --> 00:58:01,040
如果我的问题 或是我的数组大小

977
00:58:01,100 --> 00:58:05,970
跟数据块大小吻合 数据都能放在一个块里

978
00:58:06,160 --> 00:58:09,790
那一共要多少存储传输量

979
00:58:12,960 --> 00:58:18,410
1 或者是常数个 要看对齐的情况如何

980
00:58:18,520 --> 00:58:21,510
或者只需要两个传输量 但还是常数阶

981
00:58:22,070 --> 00:58:25,830
不错 这明显比这个单位条件好

982
00:58:25,870 --> 00:58:28,920
这是MT(1)=O(1) 完爆啊

983
00:58:28,960 --> 00:58:30,640
所以 这应该是正解没跑了

984
00:58:30,680 --> 00:58:32,520
确实如此

985
00:58:35,530 --> 00:58:39,400
我非常喜欢这个分析 喜欢到手舞足蹈

986
00:58:39,800 --> 00:58:41,910
好的 但这又说明了什么

987
00:58:41,950 --> 00:58:43,770
回想下前面的分析

988
00:58:43,810 --> 00:58:46,130
叶节点的数量会是多少呢

989
00:58:46,270 --> 00:58:50,110
好 在叶节点的分析里 现在L(B)=1

990
00:58:50,170 --> 00:58:52,050
不再是L(1)=1

991
00:58:52,120 --> 00:58:54,960
所以 递归提早终止了 具体是什么时候

992
00:58:55,030 --> 00:58:59,460
现在不是N^0.8神马的了

993
00:58:59,540 --> 00:59:04,120
现在是(N/B)^0.8神马的了

994
00:59:04,430 --> 00:59:09,990
所以现在变成 叶节点数为(N/B)^α

995
00:59:10,060 --> 00:59:12,580
也就是o(N/B)

996
00:59:12,620 --> 00:59:15,320
这个很小 所以不重要了

997
00:59:15,420 --> 00:59:17,500
你再看看根节点

998
00:59:17,570 --> 00:59:19,140
它的花费是N/B

999
00:59:19,220 --> 00:59:21,230
而叶节点数则是o(N/B)

1000
00:59:21,300 --> 00:59:25,210
然后 你头发甩甩 挥手摆摆 你就能知道

1001
00:59:25,290 --> 00:59:29,550
花费是顺着树往下几何递减的

1002
00:59:29,620 --> 00:59:31,170
我觉得差不多是这样了

1003
00:59:31,240 --> 00:59:34,090
可能有一点乱 因为节点终结速度不一样

1004
00:59:34,170 --> 00:59:38,730
不过 它大致上是几何递减的

1005
00:59:38,820 --> 00:59:40,840
期末考试就不要这要写了

1006
00:59:40,910 --> 00:59:43,660
不过你也不会碰到这种毛烦递归的

1007
00:59:43,780 --> 00:59:45,050
放心吧

1008
00:59:46,830 --> 00:59:52,910
沿着树往下 额 这个你是要证明的

1009
00:59:52,990 --> 00:59:57,020
我这里只断言 根节点的花费占支配地位

1010
00:59:58,020 --> 01:00:00,750
然后 根节点花费为N/B

1011
01:00:11,660 --> 01:00:17,100
所以 我们得到N/B 好 这是一个

1012
01:00:17,170 --> 01:00:21,140
很不错的线性顺序统计量算法

1013
01:00:21,220 --> 01:00:27,010
对于缓参无关算法来说 强大

1014
01:00:27,070 --> 01:00:29,160
虽然你们会有点蛋疼

1015
01:00:29,230 --> 01:00:31,930
但即使像这样的最最简单算法

1016
01:00:32,110 --> 01:00:34,750
一样可能会有最最复杂的分析

1017
01:00:34,820 --> 01:00:37,120
以后 我们的算法会越来越复杂

1018
01:00:37,160 --> 01:00:39,430
分析却反而相对地简单

1019
01:00:39,480 --> 01:00:42,330
一般来说 缓参无关算法就是这种性质

1020
01:00:42,420 --> 01:00:44,350
为什么这样就够了呢

1021
01:00:44,410 --> 01:00:45,900
我大致给了你们一些直观的解释

1022
01:00:45,970 --> 01:00:47,530
而你们则要去自己证明

1023
01:00:47,880 --> 01:00:51,700
好的 我们来看下一个算法

1024
01:00:52,120 --> 01:00:54,350
这次分治法就很有用了

1025
01:00:54,440 --> 01:00:58,020
又来一个老朋友——矩阵乘法

1026
01:00:58,120 --> 01:01:01,180
我都不知道在这门课上讲过多少次了

1027
01:01:01,270 --> 01:01:03,130
其实上周我们才讲过

1028
01:01:03,180 --> 01:01:06,870
那时是讲多线程算法 递归的矩阵相乘

1029
01:01:07,000 --> 01:01:09,390
所以 我就不再具体说算法了

1030
01:01:09,470 --> 01:01:12,980
但我们会用另一种方法来分析它

1031
01:01:13,070 --> 01:01:18,510
好的 我们有C 我们有A...

1032
01:01:18,610 --> 01:01:21,880
还是看你们怎么选吧

1033
01:01:21,950 --> 01:01:25,730
我可以将基本的矩阵乘法

1034
01:01:25,800 --> 01:01:28,580
也就是一行一行 一列一列这样相乘

1035
01:01:28,670 --> 01:01:31,890
我们可以看看为什么是这样不好 然后

1036
01:01:31,960 --> 01:01:34,510
我们再做递归乘法 看看为什么这样会比较好

1037
01:01:34,590 --> 01:01:37,960
或者 我们直接跳过基本算法

1038
01:01:38,030 --> 01:01:39,330
那么 有多少人愿意看

1039
01:01:39,410 --> 01:01:40,940
为什么基本算法不好

1040
01:01:41,020 --> 01:01:42,720
因为这真的不是很显然的事

1041
01:01:43,040 --> 01:01:45,810
1 2 3 4 5 一半的同学

1042
01:01:45,890 --> 01:01:46,980
不错哦 很多人想看

1043
01:01:47,060 --> 01:01:50,140
有多少人想直接看重点

1044
01:01:50,350 --> 01:01:54,350
没有 哦 有一个 然后其他人都睡着了

1045
01:01:54,430 --> 01:01:58,060
看来还行啊 有一半人没被我催眠

1046
01:01:58,140 --> 01:02:03,750
那么 我们先做基本矩阵乘法吧

1047
01:02:03,860 --> 01:02:06,880
我会做得很快的 因为嘛

1048
01:02:06,960 --> 01:02:09,440
你们都很熟悉它了 是吧

1049
01:02:09,520 --> 01:02:14,200
要计算结果矩阵C

1050
01:02:14,290 --> 01:02:19,140
在A矩阵里 你是取行 在B矩阵 你是取列

1051
01:02:19,210 --> 01:02:21,220
不好意思 我画得马虎了

1052
01:02:21,300 --> 01:02:23,370
但这两个向量应该是对齐的

1053
01:02:23,450 --> 01:02:24,440
那么 我用这些东西

1054
01:02:24,510 --> 01:02:27,270
乘上这些东西 再加起来

1055
01:02:27,380 --> 01:02:29,970
这就是点乘运算 得出这一个元素

1056
01:02:30,050 --> 01:02:33,230
然后 我们按照这个顺序一行一行乘下来

1057
01:02:33,300 --> 01:02:35,280
对于矩阵C中的每一个元素

1058
01:02:35,440 --> 01:02:37,600
每步循环里 我都把这一行跟着一列

1059
01:02:37,650 --> 01:02:42,020
相乘起来 这就是它内存的读取模式

1060
01:02:42,100 --> 01:02:45,580
那花费的多少是取决于

1061
01:02:45,680 --> 01:02:48,540
这个矩阵在内存里的分布形式

1062
01:02:48,570 --> 01:02:50,910
这种事太琐碎了 我们之前都不会考虑的

1063
01:02:50,990 --> 01:02:52,640
因为所有东西都是均匀的

1064
01:02:52,720 --> 01:02:58,960
我假设我们的基本算法

1065
01:02:59,030 --> 01:03:01,020
在它最好的情况下运作

1066
01:03:01,100 --> 01:03:04,910
我要按行来存储矩阵C

1067
01:03:04,980 --> 01:03:08,840
矩阵A也是按行存储 而矩阵B则是按列存储

1068
01:03:08,900 --> 01:03:11,440
所以 当你做扫描时 一切都是很顺手的

1069
01:03:11,480 --> 01:03:13,210
所以 每一个点乘运算都是一次扫描

1070
01:03:13,290 --> 01:03:19,000
酷炫啊 好像很厉害的样子 其实就是渣渣

1071
01:03:19,100 --> 01:03:28,830
假设矩阵A按行存储 矩阵B按列存储

1072
01:03:28,930 --> 01:03:31,290
而矩阵C 你想怎么都可以

1073
01:03:31,350 --> 01:03:35,940
但如果我是一行一行地做 我就按行存储

1074
01:03:36,830 --> 01:03:39,150
这就是我说的存储分布

1075
01:03:39,230 --> 01:03:41,920
这些矩阵在内存里的分布

1076
01:03:42,470 --> 01:03:44,290
这对于算法来说是不错的

1077
01:03:44,360 --> 01:03:46,290
但这个算法本身太废了

1078
01:03:46,380 --> 01:03:48,560
所以 结果就不行了

1079
01:04:10,900 --> 01:04:13,340
这需要花多长时间

1080
01:04:13,410 --> 01:04:15,980
又需要多少存储传输量 我们知道它要花M^3的时间

1081
01:04:16,130 --> 01:04:18,940
我们不是要让时间突破M^3的界限

1082
01:04:19,010 --> 01:04:21,970
我们只是想把基本矩阵乘法加快一点

1083
01:04:22,040 --> 01:04:28,290
所以呢 对于矩阵C的每一个元素

1084
01:04:28,340 --> 01:04:33,220
我都要花费N/B来扫描并做点乘运算

1085
01:04:33,290 --> 01:04:38,980
每个元素都要N/B 所以要计算C_ij

1086
01:04:41,010 --> 01:04:43,580
可能我这里也要写一个+1

1087
01:04:43,650 --> 01:04:48,840
花费就是N/B 这就意味着

1088
01:04:48,910 --> 01:04:52,920
它的上界至少是N^3/B

1089
01:04:54,860 --> 01:04:57,610
实际上 这也是它的确界 也就是Θ符号

1090
01:04:57,680 --> 01:05:03,540
这个是存储传输量 很显然 这不是时间

1091
01:05:07,040 --> 01:05:10,600
这是真实的情况 因为如果你连续地做点乘

1092
01:05:10,670 --> 01:05:13,080
我先做这个C_ij 然后做这个 这个

1093
01:05:13,080 --> 01:05:17,260
保持i不变 不断增大j 对吧

1094
01:05:17,320 --> 01:05:20,950
所以我在很长一段时间内 都停留在这一行

1095
01:05:21,020 --> 01:05:24,430
如果它跟数据块大小吻合的话

1096
01:05:25,340 --> 01:05:28,050
我可以不断重用这一行的数据

1097
01:05:28,210 --> 01:05:31,160
我可以重用这一行好几次

1098
01:05:31,270 --> 01:05:33,170
如果它跟缓存大小吻合

1099
01:05:34,060 --> 01:05:37,360
但这些列就每次都在变化了

1100
01:05:37,760 --> 01:05:40,890
所以 每次我移动一格 计算下一个C_ij时

1101
01:05:40,960 --> 01:05:43,420
就算一列跟缓存吻合

1102
01:05:43,490 --> 01:05:45,580
我也不能把所有列都放进缓存里

1103
01:05:45,640 --> 01:05:48,740
而要访问的列就一直往这边移动

1104
01:05:48,780 --> 01:05:50,030
我们要这样扫过去

1105
01:05:50,070 --> 01:05:51,830
我每次都要扫描一整个矩阵

1106
01:05:51,900 --> 01:05:54,450
除非你能把整个矩阵装进缓存

1107
01:05:54,480 --> 01:05:57,110
这样你就万能了 我什么都不用管

1108
01:05:57,180 --> 01:06:00,000
这就只需要常数时间就好 或者是M/B的时间

1109
01:06:00,060 --> 01:06:01,390
够你把它读到缓存里

1110
01:06:01,420 --> 01:06:04,110
干完你要干的事 把东西写回

1111
01:06:04,190 --> 01:06:06,650
而在这种没意思的情况中

1112
01:06:06,800 --> 01:06:13,030
你只需要做N^2/B次读取 来计算这里的每一行

1113
01:06:13,130 --> 01:06:16,480
因为你需要把所有的列都扫描一遍

1114
01:06:16,510 --> 01:06:18,790
这里每做一行 就要扫描这里一整个矩阵

1115
01:06:18,830 --> 01:06:22,200
所以你整个做下来真的要花费N^3/B

1116
01:06:22,500 --> 01:06:24,670
所以 这一般都用Θ符号

1117
01:06:27,070 --> 01:06:29,520
你可能会说 很好很强大

1118
01:06:29,630 --> 01:06:30,820
这就是用我问题的大小

1119
01:06:30,850 --> 01:06:33,480
也就是一般的运行时间 除以B

1120
01:06:33,560 --> 01:06:36,320
但这种想法只适用于线性时间的情况上

1121
01:06:36,390 --> 01:06:37,630
N对应N/B

1122
01:06:37,670 --> 01:06:40,180
如果问题大小为N 要比N/B更好确实很难

1123
01:06:40,230 --> 01:06:43,920
但现在我们的问题是N^3 这就回到了

1124
01:06:43,960 --> 01:06:48,560
数据的空间局部性问题

1125
01:06:48,590 --> 01:06:50,540
当我读取一个数据块 我会就用到整一块

1126
01:06:50,580 --> 01:06:51,950
不错 好像挺高效

1127
01:06:52,010 --> 01:06:54,050
但我们没有良好的时间局部性

1128
01:06:54,090 --> 01:06:56,780
假设我们(在缓存里)存了合适的数据块

1129
01:06:56,820 --> 01:06:59,250
我把它一直留着 然后可以不断重用

1130
01:06:59,290 --> 01:07:02,750
因为每一个元素我都要用N^3次

1131
01:07:02,790 --> 01:07:04,130
这样说好像不太对

1132
01:07:04,170 --> 01:07:09,450
但我们还是会经常地重用这些元素

1133
01:07:09,480 --> 01:07:12,220
如果我们要在N^2的数据上做N^3的操作

1134
01:07:12,290 --> 01:07:18,220
那就要重用很多次了 所以 要做得比这个更好

1135
01:07:18,260 --> 01:07:22,250
那就要用递归算法 我们也学过了

1136
01:07:22,290 --> 01:07:24,060
我们应该对它很了解

1137
01:07:24,090 --> 01:07:26,830
我只需要说明它是如何分布的

1138
01:07:30,060 --> 01:07:33,170
那么 我们就把矩阵C

1139
01:07:33,240 --> 01:07:36,350
分割成C_1-1 C_1-2 如此类推

1140
01:07:37,370 --> 01:07:42,140
原矩阵是N*N的

1141
01:07:42,210 --> 01:07:47,220
我现在把它分割为N/2 * N/2的子矩阵

1142
01:07:47,750 --> 01:07:50,030
把矩阵A B C都分割开

1143
01:07:54,650 --> 01:07:56,800
然后乘上矩阵B

1144
01:08:03,120 --> 01:08:06,070
我就不把所有东西重画一遍了

1145
01:08:06,450 --> 01:08:09,900
我可以递归地计算

1146
01:08:09,970 --> 01:08:12,990
这里八个矩阵的相乘

1147
01:08:13,070 --> 01:08:15,010
然后再做矩阵相加

1148
01:08:15,080 --> 01:08:17,180
我都不乎有多少个了 反正是常数个

1149
01:08:17,370 --> 01:08:21,520
因为我们至少做过2遍了 所以我就不画出来了

1150
01:08:21,820 --> 01:08:24,720
那么 我要怎么安排这个矩阵的分布

1151
01:08:25,440 --> 01:08:29,220
要不要再问问元芳怎么看

1152
01:08:29,260 --> 01:08:32,740
我可以把它们按行分布

1153
01:08:32,810 --> 01:08:34,530
我就直接叫行分布得了

1154
01:08:34,850 --> 01:08:37,610
但现在事情好像不那么自然了

1155
01:08:37,620 --> 01:08:40,140
因为现在既不是按行 也不是按列运算

1156
01:08:57,500 --> 01:09:01,760
那我该用什么分布

1157
01:09:08,900 --> 01:09:12,810
啥 四重分布

1158
01:09:12,880 --> 01:09:17,590
你想说四分分布吧 都快成四重奏了

1159
01:09:17,700 --> 01:09:19,520
嗯 想法不错

1160
01:09:19,590 --> 01:09:20,860
你们其实见过这种分布

1161
01:09:20,920 --> 01:09:22,580
虽然好像不太自然

1162
01:09:22,660 --> 01:09:26,060
我的确想设法把它们聚拢成块

1163
01:09:26,410 --> 01:09:28,400
好的 我想就是这样了

1164
01:09:28,840 --> 01:09:33,110
我的意思是 它是一个递归的分布

1165
01:09:34,160 --> 01:09:36,600
这不是简简单单的事 但还凑合

1166
01:09:36,820 --> 01:09:44,470
递归地用数据块来存储一个矩阵

1167
01:09:47,530 --> 01:09:48,890
我其实走的不是寻常路

1168
01:09:48,960 --> 01:09:50,610
我把问题重新定义一下

1169
01:09:50,680 --> 01:09:53,030
假设你的矩阵是这样分布的

1170
01:09:53,070 --> 01:09:55,190
但其实也影响不大

1171
01:09:55,300 --> 01:09:56,610
我们可以走点捷径 是吧

1172
01:09:56,680 --> 01:09:58,110
真的 这不会有很大影响

1173
01:09:58,180 --> 01:10:00,710
你可以把矩阵换成这种分布

1174
01:10:00,780 --> 01:10:04,580
只需要花费线性的工作量 不多

1175
01:10:04,790 --> 01:10:08,220
几乎是线性的功 可能还带log因子

1176
01:10:08,420 --> 01:10:12,460
如果我想把矩阵A存成线性的样子

1177
01:10:12,530 --> 01:10:15,090
我就可以递归地把分布定义为

1178
01:10:15,130 --> 01:10:19,610
递归地存储左上角

1179
01:10:19,670 --> 01:10:21,660
然后是右上角

1180
01:10:21,730 --> 01:10:23,770
这个顺序无所谓的

1181
01:10:23,880 --> 01:10:25,710
我把它画得宽一些

1182
01:10:25,780 --> 01:10:28,840
然后存左下角

1183
01:10:28,880 --> 01:10:32,250
然后再递归地存右下角

1184
01:10:32,320 --> 01:10:34,350
那么 你要怎么存这一块 简单 你再分成四块

1185
01:10:34,410 --> 01:10:36,670
然后再存左上角 如此类推

1186
01:10:36,740 --> 01:10:38,210
这个就是如何递归地

1187
01:10:38,280 --> 01:10:41,450
把矩阵元素存在线性数组里

1188
01:10:41,600 --> 01:10:44,770
虽然有点奇怪 但却是非常给力的想法

1189
01:10:44,850 --> 01:10:46,420
对于缓参无关算法来说

1190
01:10:46,460 --> 01:10:50,160
我们会多次用到这个思想

1191
01:10:50,370 --> 01:10:53,220
而现在 我们要做的

1192
01:10:53,290 --> 01:10:56,780
就是分析存储传输量

1193
01:10:58,500 --> 01:11:01,940
感觉嘛...好像好难啊

1194
01:11:01,980 --> 01:11:05,130
所以 我们按照这种方式把矩阵存起来

1195
01:11:05,260 --> 01:11:06,210
然后 我们要计算

1196
01:11:06,230 --> 01:11:10,380
N*N矩阵的存储传输量

1197
01:11:11,120 --> 01:11:14,290
有没有看到 我这失手写成小写n了

1198
01:11:14,360 --> 01:11:16,290
但这一周里 我其实应该

1199
01:11:16,330 --> 01:11:19,550
都用大写N写 由于某些历史问题

1200
01:11:19,620 --> 01:11:23,380
所有的外部存储算法

1201
01:11:23,420 --> 01:11:25,910
比如两层算法 总是用到大写N

1202
01:11:25,980 --> 01:11:28,720
有事就去问神奇海螺吧

1203
01:11:28,760 --> 01:11:31,820
你们应该看看他们对小写n都做了什么

1204
01:11:31,920 --> 01:11:39,870
好的 现在你们对这个递归式有什么想法

1205
01:11:39,940 --> 01:11:45,740
虽然这个递归式的设定好像很繁琐 但其实它并不难

1206
01:11:46,740 --> 01:11:51,800
首先 它肯定包含了

1207
01:11:51,870 --> 01:11:53,750
N/2 * N/2的矩阵乘法

1208
01:11:53,820 --> 01:11:57,470
那这里是多少

1209
01:12:01,260 --> 01:12:03,810
是8 唔该晒

1210
01:12:03,880 --> 01:12:05,020
这个你们应该能想到

1211
01:12:05,120 --> 01:12:07,470
然而 接下来的步骤就有技巧性了

1212
01:12:07,530 --> 01:12:10,650
那这里是什么

1213
01:12:10,720 --> 01:12:12,800
实际上 我只写这一个也没问题

1214
01:12:12,870 --> 01:12:15,430
后面的是矩阵加法

1215
01:12:15,470 --> 01:12:17,400
现在可以无视它 当它不存在

1216
01:12:17,470 --> 01:12:19,570
我只需要考虑递归相乘

1217
01:12:19,640 --> 01:12:22,470
而这里 导致8乘以MT(N/2)的情况

1218
01:12:22,510 --> 01:12:26,520
完全跟这一个矩阵分布有关

1219
01:12:26,630 --> 01:12:29,350
好了 我假设我给出的这个数组

1220
01:12:29,380 --> 01:12:31,980
它在内存里是一段连续的空间

1221
01:12:32,050 --> 01:12:33,420
如果不是的话

1222
01:12:33,480 --> 01:12:35,470
如果它们是分散存放在内存里 我就GG了

1223
01:12:35,540 --> 01:12:36,820
难为巧妇啊

1224
01:12:36,890 --> 01:12:39,610
但如果我假设我有这样的递归分布

1225
01:12:39,660 --> 01:12:41,900
我就知道 递归相乘总是会

1226
01:12:41,940 --> 01:12:45,490
调用到三块连续的内存

1227
01:12:45,550 --> 01:12:48,870
一块是矩阵A 一块是B 一块是C

1228
01:12:48,980 --> 01:12:51,600
那无论我做什么都好

1229
01:12:51,670 --> 01:12:53,740
因为它们是连贯地存储在一起的

1230
01:12:53,820 --> 01:12:56,990
递归下来也是如此

1231
01:12:57,280 --> 01:12:59,410
然后我就不断递归

1232
01:12:59,450 --> 01:13:01,480
而我总是会调用三块连续的内存

1233
01:13:01,520 --> 01:13:04,520
我要这种分布的原因就是为了这样子

1234
01:13:04,590 --> 01:13:08,020
那么 矩阵相加的花费是多少

1235
01:13:08,060 --> 01:13:09,400
我给你两个矩阵

1236
01:13:09,470 --> 01:13:11,330
它们是线性存储的

1237
01:13:12,240 --> 01:13:14,880
这三个矩阵都是一样的线性存储

1238
01:13:14,950 --> 01:13:18,900
我要操心线性存储吗

1239
01:13:24,440 --> 01:13:30,460
我要怎么把两个矩阵相加 然后得到结果的

1240
01:13:40,280 --> 01:13:41,490
请说

1241
01:13:49,080 --> 01:13:51,770
对了 如果我要调用的这三个数组

1242
01:13:51,840 --> 01:13:52,850
都是用一样的存储形式

1243
01:13:52,920 --> 01:13:55,560
我可以直接并行地扫描它们三个

1244
01:13:55,630 --> 01:13:58,760
把两个数组相加 结果放到第三个数组里

1245
01:13:58,790 --> 01:14:00,270
那我就不用管具体什么形式了

1246
01:14:00,340 --> 01:14:03,960
只要它们是一致的 我就能得到N^2/B

1247
01:14:04,110 --> 01:14:06,310
这里我就省略+1了

1248
01:14:06,380 --> 01:14:09,630
这是从整个矩阵来看的结果

1249
01:14:09,700 --> 01:14:12,160
好吧 又有一条递归式

1250
01:14:12,200 --> 01:14:15,050
我们才讲过 如果这是N^2 结果解出来就是N^3

1251
01:14:15,100 --> 01:14:17,730
但现在 如果我们用对了基础条件

1252
01:14:17,770 --> 01:14:20,940
我们好像可以得到更加帅气的东西

1253
01:14:21,010 --> 01:14:24,850
那就又轮到单位情况的回合了 啊 又有秘技了

1254
01:14:24,990 --> 01:14:28,880
谁来说说这次我要用什么单位情况

1255
01:14:34,860 --> 01:14:37,100
数据块大小 好想法

1256
01:14:37,140 --> 01:14:39,110
如果我们有个B阶大小的东西

1257
01:14:39,160 --> 01:14:41,210
我们就知道它需要常数阶的存储传输量

1258
01:14:41,260 --> 01:14:43,070
但其实这还不够

1259
01:14:43,100 --> 01:14:44,360
还不能解决问题

1260
01:14:44,440 --> 01:14:47,020
但猜得有一手 虽然在这里不是正确答案

1261
01:14:47,090 --> 01:14:49,250
我给你们一些直观的解释吧

1262
01:14:49,320 --> 01:14:51,910
我们想对N^3/B做改进

1263
01:14:51,980 --> 01:14:53,480
如果你只是想通过除以B来改进

1264
01:14:53,520 --> 01:14:55,220
这个单位情况就挺好

1265
01:14:55,290 --> 01:14:57,230
但在这 我们意识到

1266
01:14:57,310 --> 01:14:59,020
仅仅通过块大小来改进还不够

1267
01:14:59,060 --> 01:15:02,140
我们要利用到缓存很大这个条件

1268
01:15:02,210 --> 01:15:05,630
缓存大小是M 不管M具体多少 反正是很大

1269
01:15:05,700 --> 01:15:08,370
如果我们要对这个做改进

1270
01:15:08,440 --> 01:15:10,610
那这条式子里面要用到参数M

1271
01:15:10,650 --> 01:15:11,740
但这里还没有

1272
01:15:11,810 --> 01:15:15,680
那我们就设法把它加进来 你说啥

1273
01:15:15,780 --> 01:15:24,030
MT(M/B) 我看行 其实MT(M)就好了

1274
01:15:24,100 --> 01:15:27,230
应该说 常数c乘以M才对

1275
01:15:27,340 --> 01:15:29,450
我想让这个常数足够小

1276
01:15:29,490 --> 01:15:31,740
这样整个问题都能放进缓存里了

1277
01:15:31,780 --> 01:15:35,440
所以 它大致是1/3 可能不是那么的准确

1278
01:15:35,580 --> 01:15:41,550
哦 等一下 好像应该是M的平方根

1279
01:15:41,900 --> 01:15:45,490
没错 这是N*N矩阵

1280
01:15:45,530 --> 01:15:49,750
所以这应该是c乘以M的平方根 不好意思

1281
01:15:51,770 --> 01:15:54,700
M的平方根乘以M的平方根就得到M个条目

1282
01:15:54,740 --> 01:15:57,180
如果我把c设定成1/3神马的

1283
01:15:57,290 --> 01:16:00,190
我就刚好能把三个矩阵都放进缓存里了

1284
01:16:00,240 --> 01:16:02,570
其实根号3分之一就好了 但管他呢

1285
01:16:02,640 --> 01:16:05,500
所以 对于某个常数c而言 所有东西都能装进缓存

1286
01:16:05,540 --> 01:16:08,580
那这一共要多少存储传输量

1287
01:16:10,930 --> 01:16:12,450
一个

1288
01:16:13,240 --> 01:16:15,160
太小了吧

1289
01:16:16,920 --> 01:16:19,850
因为我要把整个问题都读进来

1290
01:16:20,590 --> 01:16:22,080
现在的话 这是1

1291
01:16:22,120 --> 01:16:23,680
因为这只有一个数据块

1292
01:16:23,710 --> 01:16:26,170
那这里要读多少个块

1293
01:16:26,720 --> 01:16:28,540
常数个 不对

1294
01:16:29,050 --> 01:16:32,640
B 错了 是M/B 终于说对了

1295
01:16:32,820 --> 01:16:34,310
你们是乱猜的吗

1296
01:16:34,380 --> 01:16:37,120
爆种不是这么爆的啊 骚年们

1297
01:16:37,160 --> 01:16:39,050
不要一直乱猜啊

1298
01:16:39,440 --> 01:16:42,130
M/B是因为我们缓存大小是M

1299
01:16:42,170 --> 01:16:47,200
所以缓存里一共有M/B个块 如果把全部都读进来的话

1300
01:16:47,240 --> 01:16:49,630
这可能是因为你们已经忘掉M了

1301
01:16:49,670 --> 01:16:51,440
因为我们没提到它很久了

1302
01:16:51,510 --> 01:16:53,820
但M是缓存里的元素容量

1303
01:16:53,860 --> 01:16:57,150
而M/B则是缓存里的块的数量

1304
01:16:57,520 --> 01:16:59,120
有些人说是B

1305
01:16:59,160 --> 01:17:02,020
如果要假设M/B就是B也是合理的

1306
01:17:02,060 --> 01:17:03,630
那样缓存就是正方形的了

1307
01:17:03,670 --> 01:17:07,130
但一般我们不会这么假设

1308
01:17:07,370 --> 01:17:09,460
我们讲到哪了 希望已经讲完了

1309
01:17:09,500 --> 01:17:11,450
因为就快要...很好 我们还有三分钟

1310
01:17:11,490 --> 01:17:14,550
所以 这就是我们的单位情况 这是一个平方根

1311
01:17:14,620 --> 01:17:18,150
我刚刚忘记了 现在我们就来解它

1312
01:17:18,190 --> 01:17:24,090
那么 这个递归式还算简单吧

1313
01:17:24,200 --> 01:17:25,870
我不想用主方法了

1314
01:17:25,910 --> 01:17:29,040
因为主方法管不了这些参数B和M

1315
01:17:29,080 --> 01:17:30,910
还有这个暴走的单位情况

1316
01:17:30,980 --> 01:17:35,140
主方法会证明出N^3来 无敌了

1317
01:17:36,970 --> 01:17:40,240
主方法不会考虑这些情况的

1318
01:17:40,310 --> 01:17:42,570
但对于递归树来说 如果你还记得

1319
01:17:42,610 --> 01:17:45,020
主方法是怎么证明的

1320
01:17:45,060 --> 01:17:46,390
就是先看递归树

1321
01:17:46,460 --> 01:17:48,600
它要不是几何递增递减 要不就是都相等

1322
01:17:48,640 --> 01:17:50,990
而你只需要把每层都加起来

1323
01:17:51,030 --> 01:17:52,780
重点是 这是一个很漂亮的递归式

1324
01:17:52,830 --> 01:17:55,170
所有的子问题大小都一样

1325
01:17:55,210 --> 01:17:58,820
而且这个分析一直都是成立的

1326
01:17:58,860 --> 01:18:06,320
我是说 所有子节点大小都一样

1327
01:18:10,930 --> 01:18:13,840
那么 这就是递归树

1328
01:18:13,890 --> 01:18:16,450
根部是N^2/B

1329
01:18:16,490 --> 01:18:21,020
我们把它分成8个子问题

1330
01:18:21,060 --> 01:18:28,910
每一个都是N^2/B的一半

1331
01:18:28,970 --> 01:18:31,050
我就不都写出来了 它们都是一样的

1332
01:18:31,090 --> 01:18:33,360
你把它们加起来 然后得到多少

1333
01:18:33,430 --> 01:18:38,060
嗯 一共有八个 8乘以1/2等于2 是吧

1334
01:18:38,090 --> 01:18:44,050
额 4才对 谢谢 是4吧

1335
01:18:44,120 --> 01:18:49,660
我的数学老师死得早 让你们贱笑了

1336
01:18:49,690 --> 01:18:51,930
世上只有三种数学家

1337
01:18:51,970 --> 01:18:54,430
一种会数数 另一种不会

1338
01:18:55,180 --> 01:18:58,700
我还看这个干啥 这显然如此

1339
01:18:58,740 --> 01:19:00,350
好的 我们继续

1340
01:19:00,420 --> 01:19:04,790
这看起来像是几何递增 是吧

1341
01:19:05,020 --> 01:19:08,160
是4 没错吧 你要记住

1342
01:19:08,230 --> 01:19:10,590
如果你有一条递归式 先解出前两层

1343
01:19:10,660 --> 01:19:12,920
然后你就能分辨它是几何递增 还是递减

1344
01:19:13,000 --> 01:19:14,020
还是都相等

1345
01:19:14,030 --> 01:19:16,700
或者其他神马 但要你自己想

1346
01:19:16,740 --> 01:19:18,640
但我看这个应该是几何递增

1347
01:19:18,670 --> 01:19:21,520
它下一层应该会是16 我觉得

1348
01:19:21,660 --> 01:19:23,110
应该是这样

1349
01:19:23,600 --> 01:19:27,190
所以 它是递增的 这意味着叶节点也有用

1350
01:19:27,230 --> 01:19:28,880
那我们就来算算叶节点

1351
01:19:28,950 --> 01:19:31,200
而这也是我们用到单位条件的地方

1352
01:19:31,330 --> 01:19:34,450
那么 我们的问题大小是根号M

1353
01:19:34,530 --> 01:19:37,360
所以 你有什么高见

1354
01:19:40,770 --> 01:19:42,960
哦 确实 我就觉得有问题

1355
01:19:43,030 --> 01:19:45,240
我知道这应该是2的

1356
01:19:45,430 --> 01:19:50,320
非常感谢 这说明了你们来上课绝非打酱油

1357
01:19:50,430 --> 01:19:55,240
这实际上是(N/2)^2/B 谢谢

1358
01:19:55,290 --> 01:19:59,930
我把N/2替换了成这个

1359
01:20:01,070 --> 01:20:04,270
所以这个实际上是N^2/4B

1360
01:20:04,350 --> 01:20:09,240
所以 求出来得到是2 因为是8乘以1/4嘛

1361
01:20:09,310 --> 01:20:12,730
好吧 其实我没算错

1362
01:20:12,770 --> 01:20:16,840
这依然还是几何递增的 还是这样吧

1363
01:20:16,880 --> 01:20:18,710
但现在 这已经不重要了

1364
01:20:18,780 --> 01:20:22,240
无论花费是多少 只要是大于1的话 好的

1365
01:20:22,310 --> 01:20:23,980
我们还是看叶节点吧

1366
01:20:24,010 --> 01:20:26,260
叶节点是根号M乘根号M

1367
01:20:26,290 --> 01:20:28,770
我把根号M替换成这个

1368
01:20:28,810 --> 01:20:31,550
我得到M/B和一些不重要的常数

1369
01:20:31,710 --> 01:20:35,410
每一个叶节点都是M/B

1370
01:20:35,560 --> 01:20:38,500
有很多叶节点 很多是多少

1371
01:20:38,570 --> 01:20:41,450
这就只是解递归树了

1372
01:20:41,520 --> 01:20:44,570
每次数叶节点数量都是很麻烦的

1373
01:20:44,610 --> 01:20:47,680
骚年啊 我们还是从N*N矩阵开始吧

1374
01:20:47,760 --> 01:20:52,380
一直到根号N乘根号N矩阵结束

1375
01:20:52,470 --> 01:20:57,800
这看起来像是...

1376
01:20:58,500 --> 01:21:06,440
我要看看作弊小抄 真的 有这么多

1377
01:21:06,510 --> 01:21:11,730
好像还是有理的 好吧 我出千了

1378
01:21:11,760 --> 01:21:13,570
我要用外挂直接出答案

1379
01:21:13,650 --> 01:21:16,920
然后再讨论为什么是这个

1380
01:21:17,370 --> 01:21:24,300
N除以N^3的平方根

1381
01:21:26,390 --> 01:21:30,560
不勒个是吧 虽然在树里很难看出来

1382
01:21:30,630 --> 01:21:33,280
但在矩阵里就比较容易了

1383
01:21:33,630 --> 01:21:36,310
来进入黑客帝国吧 

1384
01:21:36,380 --> 01:21:38,950
我们有一个大矩阵 我们把它对半分

1385
01:21:39,020 --> 01:21:39,030
不断递归地对半分

1386
01:21:39,070 --> 01:21:42,940
不断递归地对半分

1387
01:21:43,020 --> 01:21:44,420
你懂的

1388
01:21:44,500 --> 01:21:48,700
好了 到了某个地步 这些分段..

1389
01:21:48,730 --> 01:21:52,150
或者说某一个分段 每一个分段

1390
01:21:52,230 --> 01:21:54,660
与缓存大小吻合 三小段恰好填满缓存

1391
01:21:54,700 --> 01:21:57,790
这就是我们停止递归分析的地方

1392
01:21:57,830 --> 01:21:59,190
这个算法会不断跑下去

1393
01:21:59,260 --> 01:22:02,440
但在分析里 我们会在M停止

1394
01:22:03,140 --> 01:22:07,880
那么 现在我有多少个叶节点

1395
01:22:07,950 --> 01:22:10,330
坑爹啊 这还是不怎么明显

1396
01:22:10,370 --> 01:22:14,690
好吧 这些小方块的数量是

1397
01:22:14,770 --> 01:22:20,710
大概是N除以根号M吧

1398
01:22:20,970 --> 01:22:23,070
对了 是小方块的数量

1399
01:22:23,150 --> 01:22:26,590
但这样说好像不太清楚 因为这里有很多个小方块

1400
01:22:26,660 --> 01:22:29,750
但好吧 我们不如假设

1401
01:22:29,830 --> 01:22:32,520
我们考虑的 是普通又无趣的矩阵乘法

1402
01:22:32,600 --> 01:22:34,450
它就是用这种大小的方块

1403
01:22:34,530 --> 01:22:36,980
而这个大小是通过叶节点求得的

1404
01:22:37,070 --> 01:22:38,510
我从这个大问题开始

1405
01:22:38,580 --> 01:22:43,890
递归地把问题缩小 拿这个(小块)乘以那个

1406
01:22:43,970 --> 01:22:48,350
就是这个根号M * 根号M的小块

1407
01:22:50,270 --> 01:22:51,840
那要做多少运算

1408
01:22:51,920 --> 01:22:55,630
我要做多少次乘法 N^3

1409
01:22:55,720 --> 01:22:58,470
但对应整个矩阵而言 大小才为N

1410
01:22:58,520 --> 01:23:01,950
而对于这些子矩阵来说 大小就是N/M

1411
01:23:02,000 --> 01:23:11,850
所以 子问题的大小应该是O((N/M)^3)

1412
01:23:13,710 --> 01:23:15,310
如果你继续向下算

1413
01:23:15,360 --> 01:23:19,210
一般我们会递减到常数级的大小

1414
01:23:19,290 --> 01:23:21,250
然后我们恰好有N^3个子问题

1415
01:23:21,320 --> 01:23:23,970
那现在 我们做到这一步就停止了

1416
01:23:24,010 --> 01:23:27,280
这有多少个叶节点 N^3个

1417
01:23:27,380 --> 01:23:28,940
好的 你们可以欢呼雀跃了

1418
01:23:29,110 --> 01:23:31,350
其实不用解递归式 你也可以

1419
01:23:31,410 --> 01:23:33,770
求出叶节点数 就是这样

1420
01:23:33,830 --> 01:23:39,570
所以 总数就是N除以...我们算一下吧

1421
01:23:39,620 --> 01:23:46,650
是N^3除以M^(3/2) 这是叶子的数量

1422
01:23:46,690 --> 01:23:50,930
再乘以每一个叶子的花费 也就是M/B

1423
01:23:51,370 --> 01:24:04,700
有些M被消掉了 然后我们得到N^3 / (B * M^0.5)

1424
01:24:06,420 --> 01:24:09,650
这跟N^3/B相比少了一个根号M的因子

1425
01:24:09,710 --> 01:24:13,500
这其实已经很多了 是缓存大小的平方根这么多

1426
01:24:13,570 --> 01:24:14,830
是一个最优解了

1427
01:24:14,910 --> 01:24:17,730
最好的两层模型矩阵相乘算法

1428
01:24:17,810 --> 01:24:22,750
就是要N^3 / (B * M^0.5)这么多的存储传输量

1429
01:24:22,840 --> 01:24:27,570
简直是个奇迹 然后我又拖堂了

1430
01:24:29,060 --> 01:24:31,830
你们可以把这些都演化成各种强大的东西

1431
01:24:31,910 --> 01:24:35,420
但至少可以肯定的一点是

1432
01:24:35,500 --> 01:24:37,510
用递归来做矩阵乘法实在是太棒了

1433
01:24:37,590 --> 01:24:40,380
我们之后再继续讨论缓参无关算法

1434
01:24:40,430 --> 01:24:41,910
周三见

