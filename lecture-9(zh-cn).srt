1
00:00:09,280 --> 00:00:12,870
我们今天将讨论二叉搜索树

2
00:00:15,260 --> 00:00:18,480
也就是我们所说的随机二叉搜索树

3
00:00:31,350 --> 00:00:33,310
在这堂课里  我会——

4
00:00:33,400 --> 00:00:35,710
把二叉搜索树简称为BST

5
00:00:35,810 --> 00:00:39,270
其实你们都已经接触过二叉搜索树了

6
00:00:39,360 --> 00:00:41,450
就譬如 在上周五的复习课程中

7
00:00:41,540 --> 00:00:44,660
我们先学习一下基本概念

8
00:00:44,750 --> 00:00:48,820
然后讲一下如何随机化

9
00:00:48,900 --> 00:00:50,340
和如何优化它们

10
00:00:50,430 --> 00:00:54,200
大家都知道好的二叉搜索树是怎样的

11
00:00:54,280 --> 00:00:59,340
要相对平衡的  像这种

12
00:00:59,420 --> 00:01:01,000
高度是log n

13
00:01:01,100 --> 00:01:05,030
我们说这种树是平衡的  这是种好的情况

14
00:01:05,120 --> 00:01:07,350
复杂度是log n阶的算法都是不错的

15
00:01:07,430 --> 00:01:10,240
查询的时候 它只需要花费log n阶的时间

16
00:01:10,340 --> 00:01:12,230
但也有一些不太好的二叉搜索树

17
00:01:12,310 --> 00:01:18,480
高度太大  甚至可能是n

18
00:01:18,580 --> 00:01:22,540
所以 这种是好的 这种是坏的

19
00:01:22,630 --> 00:01:23,900
我们想知道

20
00:01:24,000 --> 00:01:25,110
如何去构造那种

21
00:01:25,210 --> 00:01:28,110
能一直保持是复杂度良好

22
00:01:28,210 --> 00:01:30,520
或是在大多数时间下保持良好

23
00:01:30,610 --> 00:01:32,120
其实有很多种方法

24
00:01:32,230 --> 00:01:36,540
在接下来几周  我们就会见到4种

25
00:01:36,630 --> 00:01:39,730
翻翻习题册就能看到

26
00:01:39,820 --> 00:01:43,100
今天  我们用随机化的方法

27
00:01:43,200 --> 00:01:46,730
使得二叉树在大部分情况下都能保持平衡

28
00:01:46,810 --> 00:01:48,640
然后 在习题册中

29
00:01:48,730 --> 00:01:51,530
你们会做得更为深入一些

30
00:01:51,620 --> 00:01:54,920
进入这个课题之前

31
00:01:55,010 --> 00:01:56,070
我不准备再花时间

32
00:01:56,180 --> 00:01:59,140
去定义随机二叉搜索树

33
00:01:59,230 --> 00:02:00,650
其实  这个课题

34
00:02:00,760 --> 00:02:03,760
是跟我们的好朋友 排序相关的

35
00:02:03,870 --> 00:02:07,270
所以 二叉搜索树也可以很自然地

36
00:02:07,360 --> 00:02:09,310
用来对n个数排序

37
00:02:09,400 --> 00:02:11,220
比如这里有个数组A

38
00:02:11,290 --> 00:02:15,010
你准备怎么用封装好的二叉树操作

39
00:02:15,090 --> 00:02:19,330
对它进行来排序呢?

40
00:02:22,570 --> 00:02:23,750
很简单  先为数组构造一个二叉树

41
00:02:23,850 --> 00:02:25,580
然后按中序遍历它

42
00:02:25,660 --> 00:02:29,360
好  我们有棵初始树

43
00:02:29,470 --> 00:02:36,330
只是空树而已  然后我们把数组每一个数...

44
00:02:36,410 --> 00:02:39,260
都插入到树中

45
00:02:39,350 --> 00:02:45,620
这样就是构造二叉树的过程

46
00:02:46,730 --> 00:02:48,660
我们将A[i]插入到树中

47
00:02:48,750 --> 00:02:52,310
这是二叉树标准的插入操作

48
00:02:52,400 --> 00:02:55,050
然后  我们做一次中序遍历

49
00:02:55,150 --> 00:03:02,570
书里叫做中根遍历

50
00:03:08,020 --> 00:03:10,380
你们都应该知道这些算法

51
00:03:10,480 --> 00:03:13,070
但还是简单地回顾一下

52
00:03:13,160 --> 00:03:16,230
进行插入操作时  首先应该在树中查找A[i]

53
00:03:16,320 --> 00:03:19,190
直到找到它合适位置为止

54
00:03:19,280 --> 00:03:20,870
前提是  A[i]已经在树中的话

55
00:03:20,960 --> 00:03:24,240
然后再在那位置加上新的叶结点来插入这个值

56
00:03:24,330 --> 00:03:27,530
树的遍历是先递归地遍历左子树,

57
00:03:27,620 --> 00:03:29,210
然后打印根结点

58
00:03:29,300 --> 00:03:31,940
再接着递归遍历右子树

59
00:03:32,040 --> 00:03:33,360
根据二叉搜索树的特性

60
00:03:33,450 --> 00:03:36,330
这些元素就会被按顺序打印出来

61
00:03:36,430 --> 00:03:39,070
举个例子

62
00:03:39,160 --> 00:03:41,180
这个算法跟我们

63
00:03:41,270 --> 00:03:42,750
之前学过的一个排序算法是有关的

64
00:03:42,840 --> 00:03:47,870
虽然例子会很简单  但我们会发现

65
00:03:47,950 --> 00:03:50,130
两个算法之间的关系还是挺微妙的

66
00:03:50,210 --> 00:03:58,000
我第一次上这门课时也是这么想的

67
00:04:00,810 --> 00:04:10,170
那么 我的数组里有3,1,8,2,6,7,5

68
00:04:10,240 --> 00:04:12,040
然后 我要从左往右地

69
00:04:12,220 --> 00:04:13,380
来访问这些元素

70
00:04:13,470 --> 00:04:15,000
并建立二叉树

71
00:04:15,090 --> 00:04:17,180
第一个元素是3

72
00:04:17,270 --> 00:04:19,910
我把3插入到树中

73
00:04:20,020 --> 00:04:22,070
一开始不需要经过比较

74
00:04:22,160 --> 00:04:26,440
接着插入1 先看看1是小于3还是大于3?

75
00:04:26,540 --> 00:04:28,540
小于3 所以把它放这里

76
00:04:28,650 --> 00:04:30,250
然后我插入8

77
00:04:30,360 --> 00:04:33,790
比3要大 所以这里多了新的叶结点

78
00:04:33,890 --> 00:04:35,200
接着插入2

79
00:04:35,290 --> 00:04:36,990
大小在1和3之间

80
00:04:37,100 --> 00:04:40,550
所以它要落入1的右子树

81
00:04:40,660 --> 00:04:42,200
我把2加在这里

82
00:04:42,300 --> 00:04:45,280
6比3大  比8要小

83
00:04:45,370 --> 00:04:49,650
把它搁这  7比3大

84
00:04:49,730 --> 00:04:52,150
比8小  比6大

85
00:04:52,240 --> 00:04:58,760
所以它就来到这 然后5在3和5之间

86
00:04:58,860 --> 00:05:00,940
是3和6之间才对

87
00:05:01,030 --> 00:05:03,540
那么 一棵二叉搜索树完成了

88
00:05:03,620 --> 00:05:05,730
接着我对它进行中序遍历

89
00:05:05,840 --> 00:05:11,310
依次打印出1,2,3,5,6,7,8

90
00:05:11,410 --> 00:05:12,690
在我脑子里很快就能跑完这个

91
00:05:12,790 --> 00:05:14,180
因为我脑里有个大堆栈

92
00:05:14,270 --> 00:05:15,920
不过我得细心一点

93
00:05:16,010 --> 00:05:17,160
当然  你应该检查

94
00:05:17,300 --> 00:05:18,810
这些排出来的数是否按顺序

95
00:05:18,900 --> 00:05:25,110
1,2,3,5,6,7,8

96
00:05:25,220 --> 00:05:28,650
如果你们脑子里没有这个栈 你们可以给自己买一个

97
00:05:28,740 --> 00:05:30,870
还是非常有用的

98
00:05:30,970 --> 00:05:33,620
最近内存条价格也变得有升有降的

99
00:05:33,710 --> 00:05:37,290
是由于政策原因什么的

100
00:05:37,380 --> 00:05:41,920
价格调整了 管他呢

101
00:05:42,020 --> 00:05:45,330
问题是  这个算法的时间复杂度是多少?

102
00:05:45,420 --> 00:05:49,490
这里 我给出其中一个可能的答案

103
00:05:49,580 --> 00:05:55,960
整个流程里  容易分析的有初始化部分

104
00:05:56,050 --> 00:05:59,400
还有就是中序遍历 这要花多少时间?

105
00:05:59,490 --> 00:06:03,130
n  没错 遍历需要n阶的时间

106
00:06:03,220 --> 00:06:07,340
而初始化的话只需要常数时间

107
00:06:07,470 --> 00:06:19,560
问题是  n次插入要花多少时间?

108
00:06:19,650 --> 00:06:21,600
谁来猜一猜

109
00:06:21,690 --> 00:06:24,530
谁来回答问题  还是先观望下？

110
00:06:24,630 --> 00:06:29,000
我听到这边有人说了

111
00:06:29,080 --> 00:06:30,330
[教授]什么?

112
00:06:30,410 --> 00:06:32,810
[学生]...

113
00:06:32,890 --> 00:06:34,750
[教授]Ω(n log n) 很好

114
00:06:34,830 --> 00:06:40,680
[教授]至少要n log n的时间  为什么?

115
00:06:40,760 --> 00:06:55,680
[学生]...

116
00:06:55,760 --> 00:06:57,510
对  你给出了两个原因

117
00:06:57,600 --> 00:07:00,190
一个是决策树的时间下界

118
00:07:00,270 --> 00:07:03,240
但这其实并没有证明这个观点

119
00:07:03,340 --> 00:07:04,420
你需要再细心地想想

120
00:07:04,530 --> 00:07:08,670
从你的论据来看二叉树的复杂度总是Ω(n log n)

121
00:07:08,740 --> 00:07:10,460
那样的话 最坏情况当然也是Ω(n log n)

122
00:07:10,540 --> 00:07:13,430
对于任何基于比较的排序算法而言

123
00:07:13,510 --> 00:07:15,270
在最坏情况下都至少需要Ω(n log n)的时间

124
00:07:15,360 --> 00:07:17,930
而二叉树的每一次都是花n log n的时间

125
00:07:18,010 --> 00:07:21,500
然而会出现Ω(n log n)的情况  是由于你的第二个条件

126
00:07:21,600 --> 00:07:24,320
也就是最优情况的出现

127
00:07:24,410 --> 00:07:26,780
一棵完全平衡的二叉树

128
00:07:26,880 --> 00:07:31,140
这是我在黑板上画得最多的图了

129
00:07:31,220 --> 00:07:35,030
今天我又刷新纪录了

130
00:07:35,110 --> 00:07:39,980
15个结点的完全二叉树

131
00:07:40,060 --> 00:07:41,490
运气好的话  我们就能得到这样的树

132
00:07:41,570 --> 00:07:44,330
如果你把所有结点的深度都加起来

133
00:07:44,420 --> 00:07:46,840
那就得到总的查询时间

134
00:07:46,900 --> 00:07:53,610
最底层的这n/2个结点  每个点的深度都是log n

135
00:07:53,690 --> 00:07:55,050
那么你的操作

136
00:07:55,130 --> 00:07:57,200
就要花上至少n log n的时间

137
00:07:57,270 --> 00:07:59,930
但是 如果树越不平衡 情况就会越差

138
00:08:00,020 --> 00:08:02,320
这点需要证明  但确实如此

139
00:08:02,400 --> 00:08:08,290
这样的话  它确实总是Ω(n log n)的

140
00:08:10,050 --> 00:08:12,460
当然  如果你用的是一些别的算法

141
00:08:12,540 --> 00:08:14,130
而你又已经知道这些元素是有序的

142
00:08:14,210 --> 00:08:17,100
你可以用线性时间来做一次比较

143
00:08:17,190 --> 00:08:19,680
但你用二叉树就不行

144
00:08:19,770 --> 00:08:24,010
还有人有别的答案吗?

145
00:08:24,120 --> 00:08:26,190
[教授]嗯嗯?

146
00:08:26,290 --> 00:08:27,620
[学生]...

147
00:08:27,720 --> 00:08:31,710
[教授]O(n^2)?  很好 为什么?

148
00:08:31,800 --> 00:08:38,220
[学生]...

149
00:08:38,330 --> 00:08:39,520
[教授]对  我们进行n次操作

150
00:08:39,610 --> 00:08:41,390
而每个结点的深度都达到最大值n

151
00:08:41,490 --> 00:08:43,950
那么  我们每插入一个数所做的比较次数

152
00:08:44,040 --> 00:08:49,420
就是最大值n  换句话说  总共最大为n^2

153
00:08:49,510 --> 00:08:52,820
还有别的答案吗?

154
00:08:55,720 --> 00:08:58,900
这个算法真的会比较n^2次吗?

155
00:08:58,990 --> 00:09:04,600
有没例子可以说明它得到Θ(n^2)?

156
00:09:06,320 --> 00:09:10,880
如果数组已经有序的话,这种情况很差

157
00:09:14,820 --> 00:09:17,820
那么,假设它已经是有序的

158
00:09:17,890 --> 00:09:23,310
不管顺序逆序  这时树的形状都很差

159
00:09:23,390 --> 00:09:25,730
树的形状会是这样子的

160
00:09:25,810 --> 00:09:29,780
在有序的情况下  你们算算

161
00:09:29,860 --> 00:09:34,250
总的花费时间应该是

162
00:09:34,330 --> 00:09:42,410
树中每个结点X的深度的总和

163
00:09:42,490 --> 00:09:44,830
在这里 它就是1+2+3+4

164
00:09:44,920 --> 00:09:46,120
等差级数

165
00:09:46,210 --> 00:09:49,200
有n个点 那么这里就是n的平方

166
00:09:49,280 --> 00:09:52,800
准确点是n的平方除以二

167
00:09:52,880 --> 00:09:55,240
这是条坏消息

168
00:09:55,320 --> 00:10:01,340
最坏情况下算法的时间复杂度为n^2

169
00:10:01,440 --> 00:10:03,100
是不是有点似曾相识？

170
00:10:03,190 --> 00:10:05,420
算法最坏情况的时间复杂度为n^2

171
00:10:05,510 --> 00:10:08,750
特别是 处理有序元素的情况？

172
00:10:08,830 --> 00:10:13,140
但是  运气好的话

173
00:10:13,220 --> 00:10:17,610
我们得到的是一棵平衡树

174
00:10:17,690 --> 00:10:18,760
很不错吧？

175
00:10:18,830 --> 00:10:24,880
只要树的高度是Ω(log n)的话

176
00:10:24,960 --> 00:10:31,260
我们的排序算法跑起来就只用n log n

177
00:10:32,390 --> 00:10:34,870
所以 在最好的情况下 我们只要花n log n的时间

178
00:10:34,950 --> 00:10:37,550
而最坏的情况下就是n^2

179
00:10:37,630 --> 00:10:41,820
最坏情况就是碰到有序元素

180
00:10:43,500 --> 00:10:47,750
有没有联想到以前见过的某种算法?

181
00:10:47,820 --> 00:10:50,920
快速排序

182
00:10:58,570 --> 00:11:01,410
其实二叉树算法运行时间

183
00:11:01,480 --> 00:11:04,540
跟快排的运行时间是一样的

184
00:11:04,620 --> 00:11:07,730
非常的相似

185
00:11:07,820 --> 00:11:10,320
事实上  二叉树里用的比较方法

186
00:11:10,400 --> 00:11:13,820
和快排里用的比较方法是完全一样的

187
00:11:13,890 --> 00:11:16,170
虽然它们比较的的顺序不一样

188
00:11:16,250 --> 00:11:21,560
但实际上它们是失散多年的亲兄弟

189
00:11:26,590 --> 00:11:32,700
算法世界真奇妙

190
00:11:32,770 --> 00:11:34,970
既然我们已经分析过快速排序算法

191
00:11:35,050 --> 00:11:43,350
那我们就要把分析的结果消化为自己的知识

192
00:11:52,740 --> 00:11:56,750
BST排序跟快排的关系就是

193
00:11:56,830 --> 00:12:04,540
它们其实做的是相同的比较

194
00:12:12,820 --> 00:12:17,120
只是比较的顺序不一样

195
00:12:24,800 --> 00:12:31,970
让我用之前的例子给大家回顾一遍:

196
00:12:32,050 --> 00:12:40,620
3,1,8,2,6,7,5

197
00:12:40,700 --> 00:12:41,790
这个是数组

198
00:12:41,870 --> 00:12:44,360
我们跑一下快速排序特别版

199
00:12:44,450 --> 00:12:48,920
这里要注意

200
00:12:49,010 --> 00:12:51,030
快排的版本有很多

201
00:12:51,120 --> 00:12:53,760
记得我们最标准、最老套的快排

202
00:12:53,840 --> 00:12:56,420
它是选取第一个元素来作为划分元素的

203
00:12:56,500 --> 00:12:58,900
这里我选3

204
00:12:58,990 --> 00:13:00,930
先分出小于3的元素

205
00:13:01,010 --> 00:13:02,990
有1和2

206
00:13:03,070 --> 00:13:05,080
其他的是大于3的

207
00:13:05,140 --> 00:13:08,150
有8,6,7,5

208
00:13:08,230 --> 00:13:09,380
在这个版本的快排中

209
00:13:09,480 --> 00:13:12,500
我先不改变元素的顺序 8 6 7 5

210
00:13:12,590 --> 00:13:14,940
先保持这些元素之间的顺序

211
00:13:15,030 --> 00:13:18,370
因为只有这样做才符合上面的性质

212
00:13:18,460 --> 00:13:22,600
这个是划分算法是稳定的

213
00:13:22,670 --> 00:13:26,480
算法很简单  是典型的快速排序

214
00:13:26,560 --> 00:13:27,810
之后我们要将它随机化

215
00:13:27,890 --> 00:13:31,650
随机化之后  这些区别的影响就不重要了

216
00:13:31,730 --> 00:13:32,820
好的 在左边这个递归部分里

217
00:13:32,970 --> 00:13:34,930
我们再用划分元素来分割

218
00:13:35,020 --> 00:13:36,070
这边是小于1的元素

219
00:13:36,160 --> 00:13:40,190
也就是空集  这边是大于1的  只有2

220
00:13:40,270 --> 00:13:42,810
然后 这又是新的划分元素

221
00:13:42,900 --> 00:13:46,240
左边的做完了  再用8来做右边的划分

222
00:13:46,330 --> 00:13:47,880
所有数都比8小

223
00:13:47,960 --> 00:13:52,850
那么 左边有6 7 5  右边为空

224
00:13:52,930 --> 00:13:55,080
然后再用6来划分

225
00:13:55,170 --> 00:13:57,870
得出比6小的数  只有5

226
00:13:57,950 --> 00:14:00,860
比6大的 只有7

227
00:14:00,940 --> 00:14:05,670
这就是用很普通的方法划分出来的元素

228
00:14:05,760 --> 00:14:12,080
现在,通过划分元素得出的这棵树

229
00:14:12,160 --> 00:14:15,050
跟这棵树非常相像

230
00:14:15,130 --> 00:14:17,380
好吧  它们完全就是同一棵树

231
00:14:17,460 --> 00:14:20,070
你们自己再回想下

232
00:14:20,150 --> 00:14:21,280
快排做了哪些比较?

233
00:14:21,360 --> 00:14:25,970
一开始  3被用来跟所有数比较

234
00:14:26,060 --> 00:14:27,890
当然  除了3自身外

235
00:14:27,980 --> 00:14:29,030
现在你看这边

236
00:14:29,130 --> 00:14:30,670
我们插入元素的时候发生了什么?

237
00:14:30,750 --> 00:14:32,380
每次插入新元素时

238
00:14:32,450 --> 00:14:34,180
所做的第一件事就是与3比较

239
00:14:34,260 --> 00:14:36,120
如果是小于 我们就走左分支

240
00:14:36,200 --> 00:14:38,390
如果是大于 我们就走右分支

241
00:14:38,470 --> 00:14:42,440
在两种方法里我们都拿3跟所有数比较

242
00:14:42,530 --> 00:14:44,110
然后 如果有比3小的数

243
00:14:44,200 --> 00:14:45,310
就是1或2

244
00:14:45,390 --> 00:14:51,190
如果是1 结束  1和1之间不用比较

245
00:14:51,270 --> 00:14:52,540
我们比较的是2和1

246
00:14:52,620 --> 00:14:54,480
实际上 当我们将2插入到这里时

247
00:14:54,560 --> 00:14:57,060
它跟3比较完之后  再跟1比较

248
00:14:57,140 --> 00:14:58,900
这时 我们会发现这里所做的操作

249
00:14:58,980 --> 00:15:00,730
跟快速排序是一样的

250
00:15:00,820 --> 00:15:02,480
对于大于3的元素

251
00:15:02,560 --> 00:15:04,870
我们全都拿去跟8比较

252
00:15:04,960 --> 00:15:08,230
因为在快排这里 我们是用8来划分的

253
00:15:08,310 --> 00:15:11,900
而在二叉树这里 8则是3的下一个结点

254
00:15:12,000 --> 00:15:14,090
所以在插入8之后  后面的数

255
00:15:14,180 --> 00:15:17,670
都要跟8比较  即使它们都比8要小

256
00:15:17,750 --> 00:15:21,150
所以 我们都在做相同的比较 只是比较的顺序不同

257
00:15:21,230 --> 00:15:27,430
角度不一样了  很神奇
So, we turn 90°. Kind of cool.

258
00:15:27,510 --> 00:15:34,930
通过分析我们能得到一些推论

259
00:15:49,680 --> 00:15:54,050
而其中一个  在最坏情况下 它的时间复杂度为Θ(n^2)

260
00:15:54,130 --> 00:15:55,570
并不是那么给力

261
00:15:55,650 --> 00:16:00,740
所以 我们真正关心的是随机化版本

262
00:16:02,130 --> 00:16:03,790
因为它的运行效率很不错

263
00:16:03,870 --> 00:16:10,410
随机化的BST排序就跟随机化的快排一样

264
00:16:10,490 --> 00:16:12,030
所以你要做的第一件事就是

265
00:16:12,130 --> 00:16:17,460
随机、均匀地打乱数组的序列

266
00:16:17,540 --> 00:16:21,650
使得任意排列都有同样的概率出现

267
00:16:21,730 --> 00:16:28,270
然后 我们再调用BST排序

268
00:16:28,340 --> 00:16:30,400
好的 这个基本上

269
00:16:30,470 --> 00:16:33,930
也就是随机化快速排序算法的大体结构

270
00:16:34,020 --> 00:16:36,080
在这之后  随机化的BST排序

271
00:16:36,150 --> 00:16:39,150
和随机化的快排做的就是相同的比较了

272
00:16:39,240 --> 00:16:44,580
这里 我们主要是要随机选出一个根结点

273
00:16:44,670 --> 00:16:46,340
而在快速排序里的话

274
00:16:46,420 --> 00:16:49,410
就是要随机地选出一个划分元素

275
00:16:49,490 --> 00:16:52,170
就是同样的算法

276
00:16:52,260 --> 00:16:57,130
所以这个算法的时间复杂度

277
00:16:57,220 --> 00:17:05,560
跟随机化快排的时间复杂度是一样的

278
00:17:05,640 --> 00:17:06,930
因为我们做的都是一样的比较

279
00:17:07,000 --> 00:17:09,230
比较的次数是一样的

280
00:17:09,320 --> 00:17:11,010
这是因为

281
00:17:11,100 --> 00:17:12,550
它的随机变量 运行时间

282
00:17:12,630 --> 00:17:15,380
跟快速排序都是同样的

283
00:17:15,450 --> 00:17:21,040
两种算法花费期望时间的都是相等的

284
00:17:32,000 --> 00:17:34,960
对于n个元素的随机化快速排序

285
00:17:35,030 --> 00:17:39,060
我们都应该知道它的期望运行时间是多少吧?

286
00:17:42,900 --> 00:17:50,510
骚年啊  是n log n  还好 刚刚我都不淡定了

287
00:17:50,600 --> 00:17:51,820
好的 同样地

288
00:17:51,910 --> 00:17:54,210
BST排序的期望运行时间也是n log n

289
00:17:54,290 --> 00:17:57,860
显然 从排序层面上看这结论也没什么

290
00:17:57,940 --> 00:18:01,820
排序只是为了研究两个算法的关系

291
00:18:01,900 --> 00:18:03,460
我们真正关心的是

292
00:18:03,540 --> 00:18:05,410
也是我给你们介绍BST排序的原因

293
00:18:05,490 --> 00:18:07,090
就是为了研究树的形状

294
00:18:07,170 --> 00:18:09,080
我们想要的是这棵搜索树

295
00:18:09,160 --> 00:18:11,520
搜索树能做的不仅仅是排序和n阶的遍历

296
00:18:11,610 --> 00:18:13,800
这对于搜索树而言只是一个普通的应用

297
00:18:13,870 --> 00:18:15,770
你可以在搜索树里进行查找

298
00:18:15,860 --> 00:18:17,830
好吧 这也是没什么大不了的

299
00:18:17,920 --> 00:18:19,530
因为你也能够先将元素排序

300
00:18:19,610 --> 00:18:21,810
然后再把元素放回数组中做二分查找

301
00:18:21,890 --> 00:18:24,330
但是 二叉搜索树的重点

302
00:18:24,410 --> 00:18:26,590
它和普通有序数组所不一样的地方

303
00:18:26,670 --> 00:18:29,090
就是你能更新树里的元素

304
00:18:29,170 --> 00:18:31,130
这堂课里我不讲动态的更新操作

305
00:18:31,210 --> 00:18:33,780
星期三会讲 习题册里也有

306
00:18:33,860 --> 00:18:36,030
现在只是预习一下

307
00:18:36,120 --> 00:18:37,910
假设说这些元素都是不变的

308
00:18:38,000 --> 00:18:41,210
我们重新建立一棵树

309
00:18:41,300 --> 00:18:43,420
之前说了有n个元素

310
00:18:43,500 --> 00:18:44,890
然后我们随机地建立一棵树

311
00:18:44,970 --> 00:18:46,040
先将数组随机打乱

312
00:18:46,120 --> 00:18:49,410
接着将全部元素都加到二叉搜索树中

313
00:18:49,490 --> 00:18:52,470
这个是BST排序的过程  然后再遍历一次

314
00:18:52,550 --> 00:18:55,010
我并不关心这个遍历本身

315
00:18:55,090 --> 00:18:57,710
我只是想通过遍历来分析

316
00:18:57,800 --> 00:19:01,860
我应该很快能讲完

317
00:19:01,940 --> 00:19:04,830
我们想研究的是这棵随机化的二叉树

318
00:19:04,910 --> 00:19:09,620
用这个算法求得的二叉树

319
00:19:09,700 --> 00:19:18,940
因此 这个就是用随机化BST排序得到的结果树

320
00:19:25,270 --> 00:19:27,370
好的  先把数组排列随机化

321
00:19:27,470 --> 00:19:29,500
再把这个数组的元素...

322
00:19:29,580 --> 00:19:35,210
用简单的算法 插入到树里 就是我们要的结果

323
00:19:35,290 --> 00:19:40,790
问题是,这棵树是什么样子的

324
00:19:40,870 --> 00:19:42,250
更重要的是 我们又能从这其中

325
00:19:42,330 --> 00:19:46,190
得出什么结论来?

326
00:19:46,260 --> 00:19:52,530
BST排序的期望运行时间为n log n

327
00:19:53,300 --> 00:19:55,570
嗯  我好几次粗略地

328
00:19:55,640 --> 00:19:59,600
提到过BST排序的运行时间

329
00:19:59,680 --> 00:20:11,650
它是深度的和  嗯...这个是n个元素的BST排序时间

330
00:20:11,730 --> 00:20:18,650
它是所有结点的深度的和  X是某个结点的深度

331
00:20:18,730 --> 00:20:20,530
好的,深度是从0开始算的

332
00:20:20,610 --> 00:20:23,670
然后越往下深度越大 因为在插入根结点时

333
00:20:23,750 --> 00:20:24,760
你不用做任何比较

334
00:20:24,840 --> 00:20:30,890
但之后 你每往深处走一步都要做比较

335
00:20:30,960 --> 00:20:34,960
所以 我们知道BST的排序时间

336
00:20:35,040 --> 00:20:40,750
它的期望大小为n log n

337
00:20:40,830 --> 00:20:42,900
这点跟树有什么关系?

338
00:20:42,990 --> 00:20:48,820
这对于树里的任意结点X来说

339
00:20:54,160 --> 00:20:55,360
它是否就告诉我们

340
00:20:55,450 --> 00:20:59,490
比如说  树的高度是多少  嗯嗯?

341
00:20:59,560 --> 00:21:03,640
[学生]...

342
00:21:03,750 --> 00:21:05,500
[教授]对  直观的角度来讲

343
00:21:05,610 --> 00:21:08,140
它说明树的高度是Θ(logn)

344
00:21:08,220 --> 00:21:11,820
而不是n  但实际上 它并没有表现这一点

345
00:21:11,900 --> 00:21:14,550
这就是为什么这只是从直观的角度来讲

346
00:21:14,630 --> 00:21:16,790
它可能有问题  而实际上 它确实错了

347
00:21:16,860 --> 00:21:19,660
我来告诉你们正确的结论

348
00:21:19,750 --> 00:21:26,320
如果我们对等式两边求期望值  这里是n log n

349
00:21:26,400 --> 00:21:32,700
这边的期望值是n log n

350
00:21:32,780 --> 00:21:41,340
而另一边  我们得到的是总深度的期望值

351
00:21:41,410 --> 00:21:42,680
也没什么特别

352
00:21:42,750 --> 00:21:46,620
我们再看看平均深度的期望值

353
00:21:46,700 --> 00:21:48,320
如果我用1/n

354
00:21:48,390 --> 00:21:52,900
乘以树所有结点X的深度之和

355
00:21:52,980 --> 00:21:58,030
就得出所有结点深度的平均值

356
00:21:58,130 --> 00:22:05,070
我应该得到Θ(n log n)/n

357
00:22:05,150 --> 00:22:08,230
因为我两边都除以n了

358
00:22:08,320 --> 00:22:13,230
然后根据期望的线性性质  算出log n

359
00:22:13,300 --> 00:22:16,800
所以这个运行时间的期望值告诉我

360
00:22:16,870 --> 00:22:20,760
树结点的平均深度为log n

361
00:22:20,830 --> 00:22:27,320
并不相当于说树的高度就是log n

362
00:22:33,920 --> 00:22:35,030
你们要记住树的高度

363
00:22:35,120 --> 00:22:39,460
是指所有结点中的最大深度

364
00:22:39,540 --> 00:22:44,630
这里我们只是估计平均深度的范围

365
00:23:03,690 --> 00:23:08,820
我们来看一个例子

366
00:23:11,860 --> 00:23:15,200
平衡树神马的最喜欢画了

367
00:23:17,800 --> 00:23:19,470
现在我们有一棵还算漂亮的平衡树

368
00:23:19,540 --> 00:23:24,430
应该说  起码有一半以上的节点都还分布得不错

369
00:23:24,500 --> 00:23:27,490
但在其中某个结点下面

370
00:23:27,600 --> 00:23:32,130
伸出了一条很长的树径

371
00:23:32,210 --> 00:23:33,340
是哪个点并不重要

372
00:23:33,420 --> 00:23:36,260
这条路径的长度呢

373
00:23:36,340 --> 00:23:39,180
就是树的总高度   我假设它为根号n

374
00:23:39,260 --> 00:23:42,140
要比log n大很多

375
00:23:42,210 --> 00:23:43,920
这边的高度差不多是log n

376
00:23:44,000 --> 00:23:50,560
大约是log(n-√n)

377
00:23:50,640 --> 00:23:54,330
大多数结点有着对数级的高度

378
00:23:54,420 --> 00:23:56,730
错了,是对数级的深度

379
00:23:56,810 --> 00:24:01,340
如果你算算这颗树的平均深度

380
00:24:01,420 --> 00:24:03,320
对于大多数结点而言

381
00:24:03,410 --> 00:24:10,580
最多的话 有n个结点的深度为log n

382
00:24:10,670 --> 00:24:12,620
然后这边最多有根号n个结点

383
00:24:12,700 --> 00:24:17,310
一直下来  最大深度为根号n

384
00:24:17,390 --> 00:24:20,610
所以最多有根号n乘以根号n

385
00:24:20,690 --> 00:24:23,320
实际上只有一半那么多  不过影响不大

386
00:24:23,400 --> 00:24:29,330
所以这里是n 这里是n log n  嗯不好意思

387
00:24:29,510 --> 00:24:35,080
因为是平均深度 所以全部都要除以n

388
00:24:35,150 --> 00:24:41,630
n log n 作为平均深度就太大了

389
00:24:41,710 --> 00:24:43,790
所以这里的平均深度为log n

390
00:24:43,880 --> 00:24:46,660
但树的高度是根号n

391
00:24:46,730 --> 00:24:49,280
说明刚刚的结论是不充分的

392
00:24:49,350 --> 00:24:51,330
只知道平均深度为log n的话

393
00:24:51,410 --> 00:24:54,790
并不代表树的高度就是log n

394
00:24:54,870 --> 00:25:00,130
好的 但今天要证明一个定理

395
00:25:00,220 --> 00:25:05,330
那就是一颗随机化的二叉搜索树

396
00:25:05,400 --> 00:25:15,930
它的高度的期望值确实是log n

397
00:25:16,020 --> 00:25:21,950
BST是log n阶的

398
00:25:22,030 --> 00:25:25,500
这就是我们想研究的内容  因为这说明

399
00:25:25,580 --> 00:25:29,360
只要我们建立随机化二叉搜索树

400
00:25:29,440 --> 00:25:32,470
我们就能实现log n的查询时间

401
00:25:32,560 --> 00:25:36,030
好吧 对于排序的话就没那么重要

402
00:25:36,110 --> 00:25:40,100
因为那样我们只关心建立树的运行时间

403
00:25:40,190 --> 00:25:43,100
但这里  现在我们知道一旦我们证明这定理

404
00:25:43,180 --> 00:25:47,340
我们就能够快速地查询

405
00:25:47,420 --> 00:25:50,860
而且是在大多数情况下都可以

406
00:25:50,940 --> 00:25:53,030
今天这堂课剩下的时间就是要证明这个定理

407
00:25:53,110 --> 00:25:55,040
有一点技巧 正如你所想的那样

408
00:25:55,120 --> 00:25:57,360
是另一个大型的概率分析

409
00:25:57,430 --> 00:26:02,730
涉及到快排等等的一切

410
00:26:20,900 --> 00:26:26,680
所以我准备先列出证明过程的纲领

411
00:26:28,230 --> 00:26:29,950
除非对定理本身有问题

412
00:26:30,030 --> 00:26:32,740
否则 我们要证明的目标应该是很明确的

413
00:26:32,830 --> 00:26:36,860
这个证明比我们之前见过的所有分析都要奇怪

414
00:26:36,940 --> 00:26:40,970
会用到一个很有趣的技巧

415
00:26:41,060 --> 00:26:44,080
对一个随机变量取幂

416
00:26:44,170 --> 00:26:51,930
还要用到一个工具就是Jenson不等式

417
00:26:52,020 --> 00:26:53,440
先证明这个不等式吧

418
00:26:53,530 --> 00:26:55,640
通常来说我们不去证明概率学工具

419
00:26:55,710 --> 00:26:57,700
但这个我们还是去证明一次

420
00:26:57,780 --> 00:27:06,620
不是很难 也是一些基本的分析

421
00:27:06,710 --> 00:27:11,880
那么 有个引理指出 如果我们..

422
00:27:11,970 --> 00:27:14,270
有一个凹函数f

423
00:27:14,350 --> 00:27:16,070
你们应该都知道这个是什么

424
00:27:16,150 --> 00:27:21,000
忘了的话我等下会再定义一次

425
00:27:21,070 --> 00:27:22,390
假设你有个凹函数f

426
00:27:22,470 --> 00:27:23,890
还有个随机变量X

427
00:27:23,980 --> 00:27:25,520
用X的期望值代入f中

428
00:27:25,600 --> 00:27:30,140
得到的最大值不会超过f(X)的期望值

429
00:27:30,240 --> 00:27:33,200
自己想一想 画个凹函数看看

430
00:27:33,290 --> 00:27:35,960
我觉得这个是相当直观的

431
00:27:36,050 --> 00:27:38,410
但我们会证明它的

432
00:27:38,490 --> 00:27:46,470
我们能做的

433
00:27:46,550 --> 00:27:54,670
并不是直接分析用来代表树高度的随机变量

434
00:27:54,760 --> 00:27:59,350
X_n用来表示随机化的...

435
00:27:59,430 --> 00:28:08,250
BST的高度 我们要分析的

436
00:28:08,350 --> 00:28:17,340
是n个节点的随机化的BST

437
00:28:17,420 --> 00:28:21,860
好的 我们分析的并不是这个随机变量X_n

438
00:28:21,930 --> 00:28:27,070
不好意思  这应该是大写的X

439
00:28:27,150 --> 00:28:32,270
我们转而分析关于X_n的任意凹函数

440
00:28:32,360 --> 00:28:35,930
而且 我们准备分析的是取幂函数

441
00:28:36,010 --> 00:28:43,440
那么 我定义Y_n为2的X_n次方

442
00:28:43,520 --> 00:28:47,220
问题是为什么要这么做?

443
00:28:47,300 --> 00:28:48,850
原因是这么做很有用

444
00:28:48,930 --> 00:28:51,090
而且我们只分析X_n的话是没用的

445
00:28:51,170 --> 00:28:54,230
我们待会儿再直观地看一下

446
00:28:54,310 --> 00:28:56,070
其实也并不是很直观

447
00:28:56,150 --> 00:29:00,680
在这个分析里你就要用到特别的技巧

448
00:29:00,770 --> 00:29:03,550
我们先要算Y_n期望值的上下界

449
00:29:03,630 --> 00:29:05,650
再在那个基础上运用Jensen不等式

450
00:29:05,740 --> 00:29:08,940
来求出X_n的期望值的界限

451
00:29:09,010 --> 00:29:11,420
实际上 它的界限相当的紧凑

452
00:29:11,500 --> 00:29:15,200
这样做是因为 如果能给指数函数找到常数界限

453
00:29:15,280 --> 00:29:16,910
也就是给取幂结果找到常数界限

454
00:29:17,000 --> 00:29:19,800
那我们就能更方便地算出X_n的界限

455
00:29:19,880 --> 00:29:23,240
因为那时只要取Y_n对数就得到X_n

456
00:29:23,320 --> 00:29:26,780
我们甚至能找出这个常数是多少

457
00:29:26,870 --> 00:29:32,610
那么,我们将要证明的重点

458
00:29:32,690 --> 00:29:37,660
就是Y_n的期望值是n^3阶的

459
00:29:37,750 --> 00:29:40,220
这里我们没法知道这个常数多大

460
00:29:40,310 --> 00:29:42,770
也不需要知道

461
00:29:42,850 --> 00:29:45,230
最后再来做总结

462
00:29:45,310 --> 00:29:48,030
开始证明吧

463
00:29:48,100 --> 00:29:52,920
我们真正关心的是X_n的期望

464
00:29:53,000 --> 00:29:55,000
也就是我们的树的高度

465
00:29:55,070 --> 00:29:59,920
我们要证明的是这条式子

466
00:30:00,010 --> 00:30:05,070
呃,这里留一点空间

467
00:30:05,150 --> 00:30:08,540
我们要求出2的X_n次方的期望值

468
00:30:08,620 --> 00:30:13,330
也就是Y_n的期望值

469
00:30:13,410 --> 00:30:16,770
假设我们知道这个是n^3阶的

470
00:30:16,840 --> 00:30:18,840
那么 Jensen不等式告诉我们,

471
00:30:18,930 --> 00:30:21,870
如果我们把这个函数2的X次方

472
00:30:21,950 --> 00:30:26,360
把它放这里  那么在等号的左边

473
00:30:26,440 --> 00:30:29,670
我们就有2的E(X)次方

474
00:30:29,750 --> 00:30:36,870
那么 我们就得出2^E(X_n) 最大不超过 2^X_n的期望

475
00:30:36,960 --> 00:30:38,750
这就是我们用到Jensen不等式的地方

476
00:30:38,830 --> 00:30:41,670
因为我们关心的是X_n的期望值

477
00:30:41,750 --> 00:30:42,810
现在 因为我们有了它的范围了

478
00:30:42,930 --> 00:30:47,160
我们现在发现2^E(X_n) 最大为n^3

479
00:30:47,240 --> 00:30:49,020
然后只要两边同时取对数

480
00:30:49,100 --> 00:30:58,060
就能得出X_n的期望不超过log(n^3)

481
00:30:58,140 --> 00:31:01,740
嗯  我把它写得有趣点 log(O(n^3))

482
00:31:01,820 --> 00:31:04,220
这就样我们就知道那个常数是多少了

483
00:31:04,310 --> 00:31:12,330
它等于3 log n加上O(1)

484
00:31:12,400 --> 00:31:14,660
所以我们就证明了

485
00:31:14,740 --> 00:31:17,470
一个n结点的随机化二叉树的期望高度

486
00:31:17,550 --> 00:31:23,630
大约为3 log n

487
00:31:23,710 --> 00:31:28,400
这个结果我待会儿会讲得更详细一点

488
00:31:28,470 --> 00:31:32,100
现在大家都知道证明到最后就是这样子

489
00:31:32,200 --> 00:31:33,430
这是给你们提前剧透下

490
00:31:33,520 --> 00:31:35,850
刚刚我们从上而下做了一次模拟

491
00:31:35,930 --> 00:31:37,930
你们大概知道证明的步骤了

492
00:31:38,010 --> 00:31:39,670
现在 我们将要把这些步骤过一遍

493
00:31:39,750 --> 00:31:43,250
好的 第一步要花点工夫 不过很简单

494
00:31:43,330 --> 00:31:45,530
因为都是基础的东西

495
00:31:45,600 --> 00:31:48,460
第二步只是一个定义而且我们已经完成了

496
00:31:48,540 --> 00:31:50,960
第三步应该算是最难的部分

497
00:31:51,040 --> 00:31:53,450
第四步,我们已经证明完了

498
00:31:53,530 --> 00:31:59,660
那我们从第一步开始

499
00:32:16,090 --> 00:32:18,920
第一件事就是去定义一个凹函数

500
00:32:19,000 --> 00:32:24,600
因为我们要多次运用到这个定义

501
00:32:25,760 --> 00:32:31,010
这个是正式的分析里来的一个概念

502
00:32:34,040 --> 00:32:35,900
对于微积分来说分析是一个独特的词汇

503
00:32:35,990 --> 00:32:38,850
如果你没上过那些数学分析的课的话

504
00:32:38,930 --> 00:32:42,090
你们也应该在微积分课上见过函数的凹凸性

505
00:32:42,180 --> 00:32:44,640
凹函数是这个样子的

506
00:32:44,730 --> 00:32:50,570
将这个概念写成公式就是

507
00:32:50,670 --> 00:32:53,320
在弧上选取两个点

508
00:32:53,400 --> 00:32:56,200
我只关注实数函数

509
00:32:56,270 --> 00:32:59,770
所以 它看起来是这样子的 这个是f某某

510
00:32:59,850 --> 00:33:02,570
这个是某某

511
00:33:02,650 --> 00:33:04,810
如果我从弧线上选取两点

512
00:33:04,890 --> 00:33:07,750
画一条线段来连接它们

513
00:33:07,820 --> 00:33:10,350
那么这条线段总是在弧线上的

514
00:33:10,430 --> 00:33:13,080
这就是凹性

515
00:33:13,170 --> 00:33:15,710
它还有个几何上的概念 不过基本上是一样的

516
00:33:15,810 --> 00:33:19,560
但对于函数而言 线段总是在弧上方

517
00:33:19,640 --> 00:33:21,060
但直线并不在弧的上方

518
00:33:21,150 --> 00:33:24,330
如果我把它延伸一下 它当然就在弧线下面了

519
00:33:24,430 --> 00:33:27,480
但是这条线段应该在弧的上方

520
00:33:27,560 --> 00:33:29,330
我准备将这个定义公式化

521
00:33:29,420 --> 00:33:33,450
我们设这个为x  那这就是f(x)

522
00:33:33,530 --> 00:33:38,480
这个为y  这就是f(y)

523
00:33:38,560 --> 00:33:43,180
而需要证明的 就是我在x y之间任意选一个点

524
00:33:43,260 --> 00:33:47,710
当我往上面看 好的 弧上面有一个点

525
00:33:47,800 --> 00:33:49,730
线段上也有一个点

526
00:33:49,810 --> 00:33:52,870
线段上的点的y坐标值  这里

527
00:33:52,950 --> 00:33:57,570
应该大于或等于弧上的点的y坐标值  对吧?

528
00:33:57,650 --> 00:33:59,700
要理解这个点的性质

529
00:33:59,770 --> 00:34:04,110
我们需要用到一些几何知识

530
00:34:04,200 --> 00:34:06,330
我敢保证它也是数学分析中的一个概念

531
00:34:06,410 --> 00:34:09,880
但我是研究几何的  所以我叫它几何学

532
00:34:09,960 --> 00:34:14,690
如果你有p q两点

533
00:34:14,800 --> 00:34:18,180
而你想用参数来表示它们之间的线段

534
00:34:18,270 --> 00:34:21,180
比如我想将这几个点参数化

535
00:34:21,260 --> 00:34:25,620
一个方法就是用线性组合

536
00:34:25,700 --> 00:34:29,090
如果你们学过了线性代数的话

537
00:34:29,170 --> 00:34:31,990
这种就叫线性组合

538
00:34:32,070 --> 00:34:33,720
而且我们实际上还用到

539
00:34:33,800 --> 00:34:39,260
一种叫做仿射组合的东西  α+β=1

540
00:34:39,330 --> 00:34:43,990
这表明  如果你把满足这条式的点都找出来

541
00:34:44,070 --> 00:34:48,070
任意取一个α值  乘以点p  加上

542
00:34:48,150 --> 00:34:50,450
任意β乘以点q  而且满足α+β=1

543
00:34:50,540 --> 00:34:51,780
如果找出所有这样的点

544
00:34:51,870 --> 00:34:55,090
你会得到一整条漂亮的直线

545
00:34:55,160 --> 00:34:56,580
但我们不想要一整条直线

546
00:34:56,660 --> 00:35:00,140
如果你同时限定α和β都是非负的话

547
00:35:00,220 --> 00:35:02,220
你就刚好得到一条线段

548
00:35:02,300 --> 00:35:04,980
那么α和β都只能在0和1之间取值

549
00:35:05,060 --> 00:35:07,200
因为它们加起来要等于1

550
00:35:07,280 --> 00:35:08,560
而且它俩都是非负的

551
00:35:08,640 --> 00:35:10,240
所以我们这里要做的是

552
00:35:10,320 --> 00:35:13,500
用αx 加上 βy

553
00:35:13,600 --> 00:35:17,210
这些就是在x、y之间 符合我们条件的点

554
00:35:17,290 --> 00:35:18,600
α+β=1

555
00:35:18,690 --> 00:35:20,290
α和β都大于0

556
00:35:20,370 --> 00:35:24,590
然后 这点是αx+βy的f值

557
00:35:24,670 --> 00:35:29,500
这个是f(αx+βy)

558
00:35:29,580 --> 00:35:34,940
而这个点是在f(x)与f(y)之间的

559
00:35:35,020 --> 00:35:37,650
线段上的一个插值 同样的

560
00:35:37,730 --> 00:35:43,670
它就是αf(x)+βf(y)

561
00:35:43,750 --> 00:35:45,900
好的,这个是直觉推论

562
00:35:45,980 --> 00:35:48,980
如果有人没跟上的话  也没关系

563
00:35:49,060 --> 00:35:50,100
因为我们关心的是

564
00:35:50,200 --> 00:35:53,180
证明出来的符号化的答案

565
00:35:53,270 --> 00:35:55,160
但是答案就从这里来的

566
00:35:55,250 --> 00:35:57,490
那么 这里就是定义

567
00:35:57,570 --> 00:36:00,600
我们定义凹函数为...

568
00:36:00,680 --> 00:36:11,130
对于任意x和y以及任意的α和β

569
00:36:11,210 --> 00:36:17,780
满足α、β≥0，α+β=1

570
00:36:17,840 --> 00:36:27,490
我们有f(αx+βy)是小于

571
00:36:27,580 --> 00:36:33,100
或等于αf(x)+βf(y)

572
00:36:33,190 --> 00:36:35,820
也就是说在函数线上的y坐标是

573
00:36:35,900 --> 00:36:40,270
小于线段上的y坐标的

574
00:36:40,340 --> 00:36:46,570
好的  这式子就是那个图的数学符号表示

575
00:36:46,660 --> 00:36:49,180
那好 我们现在想证明Jensen不等式

576
00:36:49,260 --> 00:36:51,340
其实离证明完还差得远呢

577
00:36:51,420 --> 00:36:55,300
我们先要证明一个引理

578
00:36:55,390 --> 00:37:00,930
有了它就容易推导出Jensen不等式

579
00:37:01,570 --> 00:37:05,400
这就是我们要证明的定理

580
00:37:11,670 --> 00:37:15,810
那么 有个关于凹凸函数的引理

581
00:37:15,890 --> 00:37:17,960
你们之前可能见过了

582
00:37:18,040 --> 00:37:22,710
它对Jensen不等式至关重要

583
00:37:30,780 --> 00:37:32,630
假设这个命题不仅适用于两点

584
00:37:32,700 --> 00:37:37,810
而且适用于函数上的n个点的仿射组合

585
00:37:37,900 --> 00:37:39,030
这么一来 函数的凹性就可以

586
00:37:39,100 --> 00:37:43,870
推广至n个点

587
00:37:43,950 --> 00:37:46,970
假设我们有n个实数

588
00:37:48,510 --> 00:37:52,840
以及n个α值  从α_1到α_n

589
00:37:52,930 --> 00:37:55,180
它们全都是非负的

590
00:37:55,270 --> 00:37:57,870
而且它们的和为1

591
00:37:57,950 --> 00:38:01,590
我写成α_k的总和

592
00:38:01,670 --> 00:38:07,550
k从1到n  它们的总和是1

593
00:38:07,640 --> 00:38:09,410
那么,这些都是假定给出的条件

594
00:38:09,490 --> 00:38:16,130
结论是一致的 不过换成了k个值的总和

595
00:38:16,210 --> 00:38:20,520
k从1到n  算出α_k * x_k的总和

596
00:38:20,610 --> 00:38:27,810
代入f中  再和α_k * f(x_k)的总和比较

597
00:38:27,900 --> 00:38:31,660
k从1到n

598
00:38:31,750 --> 00:38:35,640
由此发现  凹性的定义正跟刚刚的命题一致

599
00:38:35,720 --> 00:38:38,200
只是刚刚那个是当n=2时

600
00:38:38,280 --> 00:38:42,110
是吧  α1和α2分别对应α和β

601
00:38:42,190 --> 00:38:48,660
这个是对于n个值的一般化的命题

602
00:38:48,740 --> 00:38:52,950
你们也可以用更有趣的方法来解释这条式子

603
00:38:53,030 --> 00:38:57,040
不过人家才不会这么做呢  骗你的 能不会吗?

604
00:38:57,120 --> 00:38:58,500
我可是几何学者

605
00:38:58,580 --> 00:39:02,420
那么 比如你在弧线上选取若干个点

606
00:39:02,500 --> 00:39:06,360
你再从这些点中构成多边形

607
00:39:06,440 --> 00:39:07,850
这些都是直线段

608
00:39:07,920 --> 00:39:10,350
你取中间部分

609
00:39:10,440 --> 00:39:12,160
如果像那样运用仿射组合

610
00:39:12,230 --> 00:39:14,760
你就会在多边形中得到一点

611
00:39:14,850 --> 00:39:16,240
又或者在边上得到一点

612
00:39:16,330 --> 00:39:19,300
这说明这些点都是在弧线上方的

613
00:39:19,390 --> 00:39:22,350
而且 直观上看就是真的 如果你画的是一个漂亮的

614
00:39:22,440 --> 00:39:25,490
正规的凹弧线的话

615
00:39:25,570 --> 00:39:27,150
但事实上  在代数里也是对的

616
00:39:27,240 --> 00:39:29,770
这都是好事

617
00:39:29,860 --> 00:39:32,920
怎么证明这些定理、引理？ 有人有什么想法吗?

618
00:39:33,000 --> 00:39:40,800
其实相当简单 那么 我们用什么技巧去证明它?

619
00:39:45,310 --> 00:39:47,900
一个词: 归纳法

620
00:39:47,940 --> 00:39:51,380
一直好方法 从未被超越

621
00:39:52,160 --> 00:39:54,500
你应该大声喊出归纳法

622
00:39:54,590 --> 00:39:55,960
因为我们都已经知道

623
00:39:56,040 --> 00:39:58,820
当n=2时 函数凹性定义为真

624
00:39:58,890 --> 00:40:00,860
这样 基础命题解决了

625
00:40:00,940 --> 00:40:02,360
实际上 这还不算最基础的

626
00:40:02,440 --> 00:40:05,560
最基础是当n等于1时

627
00:40:05,660 --> 00:40:10,820
如果n=1 那你仅有一个数而且和为1

628
00:40:10,900 --> 00:40:15,080
所以α1=1  那这里没有别的东西了

629
00:40:15,160 --> 00:40:22,430
这就是说f(1*x_1)

630
00:40:22,510 --> 00:40:26,930
最大不超过1乘以f(x_1)

631
00:40:27,010 --> 00:40:32,930
也不是什么神奇的东西  因为这等式本身就是成立的

632
00:40:33,030 --> 00:40:36,940
好的 我们甚至没用到n=2时的基础命题

633
00:40:37,030 --> 00:40:38,270
有趣的地方来了

634
00:40:38,350 --> 00:40:42,000
虽然不是特别有趣 其实就是归纳法

635
00:40:42,090 --> 00:40:45,770
但这是数学归纳法的好应用

636
00:40:45,860 --> 00:40:51,990
那么 我们关心的是f的线性组合

637
00:40:52,070 --> 00:40:58,260
对于所有k  α_k * x_k的总和代入f的值

638
00:40:58,340 --> 00:41:01,220
现在要用到归纳法了

639
00:41:01,300 --> 00:41:05,410
我先从归纳中得知 这个和的f值

640
00:41:05,490 --> 00:41:07,440
假设已经知道它加到n-1的和

641
00:41:07,530 --> 00:41:09,150
而不是加到n的和

642
00:41:09,240 --> 00:41:12,470
比n小的情况都从归纳中解决了

643
00:41:12,560 --> 00:41:14,480
那么  我要尝试处理掉第n项

644
00:41:14,560 --> 00:41:16,780
我想将它分离出来

645
00:41:16,860 --> 00:41:21,370
很自然就能写出来

646
00:41:21,460 --> 00:41:23,750
只要你之前用过仿射组合的话

647
00:41:23,830 --> 00:41:27,620
就只是一些代数而已

648
00:41:30,710 --> 00:41:35,120
我想提出α_n * x_n这一项

649
00:41:35,210 --> 00:41:39,010
而且写成仿射组合的形式

650
00:41:39,100 --> 00:41:41,370
这就是个小技巧

651
00:41:44,340 --> 00:41:47,060
不好意思 这里没f的

652
00:41:53,670 --> 00:41:55,790
因为我把最后一项提出来了

653
00:41:55,870 --> 00:41:57,800
那这里就是α_k从1数到n-1

654
00:41:57,880 --> 00:41:59,390
所以它们加起来就不等于1了

655
00:41:59,470 --> 00:42:01,080
它们加起来要小于1

656
00:42:01,160 --> 00:42:02,740
所以我不能简单地去掉这一项

657
00:42:02,830 --> 00:42:13,390
这里要到一点小技巧  这里是x_k..都在f里面

658
00:42:14,330 --> 00:42:18,020
好的 你们要知道这条等式是成立的

659
00:42:18,100 --> 00:42:20,280
因为1-α_n能消掉后面的分母

660
00:42:20,370 --> 00:42:23,320
消掉后  这边就剩下α_k * x_k的和

661
00:42:23,400 --> 00:42:27,080
k从1到n-1  再加上α_n * x_n项

662
00:42:27,160 --> 00:42:28,500
所以这里啥都没动过

663
00:42:28,590 --> 00:42:29,930
等号两边是相等的

664
00:42:30,010 --> 00:42:32,370
但现在我们却得到了个漂亮的特征

665
00:42:32,460 --> 00:42:34,790
一方面 这两个数

666
00:42:34,870 --> 00:42:37,770
α_n以及1-α_n加起来等于1

667
00:42:37,860 --> 00:42:39,460
另一方面  如果我没错的话

668
00:42:39,540 --> 00:42:42,660
这些数加起来应该等于1

669
00:42:42,750 --> 00:42:46,230
就是从1到n-1的和

670
00:42:46,320 --> 00:42:48,380
为什么它们的和为1?

671
00:42:48,470 --> 00:42:53,210
分子全部加起来等于1-α_n

672
00:42:53,290 --> 00:42:55,390
然后这些加起来的和再除以1-αn

673
00:42:55,470 --> 00:42:56,830
所以它们和仍然为1

674
00:42:56,910 --> 00:42:58,950
所以现在我有两个仿射组合

675
00:42:59,030 --> 00:43:01,260
把两个已知条件都用上

676
00:43:01,340 --> 00:43:08,590
我知道这里要用到仿射组合  为什么？

677
00:43:08,670 --> 00:43:13,880
为什么这个等于α_n * f(x_n)

678
00:43:13,970 --> 00:43:19,610
加上1-α_n乘以这一大坨东西？

679
00:43:33,710 --> 00:43:38,460
大声说 我听到有两个答案

680
00:43:38,540 --> 00:43:41,820
一个是对的  另一个是错的

681
00:43:41,890 --> 00:43:44,330
会是哪个呢?

682
00:43:51,140 --> 00:43:55,110
这个应该是小于等于号

683
00:43:55,200 --> 00:43:57,200
很重要的  别搞错

684
00:44:00,370 --> 00:44:03,840
答案就写在黑板上  不可能太难

685
00:44:16,450 --> 00:44:20,600
我现在把这整个当成一个大X

686
00:44:20,680 --> 00:44:26,390
这里有些x_n  还有个超大的X

687
00:44:26,480 --> 00:44:29,260
我想让这两个X的仿射组合的f值

688
00:44:29,340 --> 00:44:35,760
最大不超过它们的f(X)的仿射组合值

689
00:44:35,840 --> 00:44:41,820
就是说? 它又回归到n=2的时候归纳假设

690
00:44:41,910 --> 00:44:44,870
悲剧了  我们还没证明n=2时的情况

691
00:44:44,950 --> 00:44:46,820
因为这是个特殊基础命题

692
00:44:46,910 --> 00:44:48,760
所以这里不能用归纳法

693
00:44:48,840 --> 00:44:50,170
因为我们给出的基础条件是n=1

694
00:44:50,250 --> 00:44:52,000
如果你证明了n=2的情况

695
00:44:52,080 --> 00:44:55,450
你就可以那么做 但这里我们不能

696
00:44:55,540 --> 00:44:59,030
所以第二个方法就是用 凹凸性 很好

697
00:44:59,120 --> 00:45:01,100
就是这个式子

698
00:45:01,190 --> 00:45:04,830
如果说f是个凹函数  对于任意两个X

699
00:45:04,930 --> 00:45:09,050
如果这两项的系数的和为1时 这条式就成立了

700
00:45:09,140 --> 00:45:12,330
好吧 既然是成立的

701
00:45:12,630 --> 00:45:15,910
现在就是用归纳法的时候了

702
00:45:27,820 --> 00:45:33,870
那么 我们就对等号右边进行归纳

703
00:45:33,950 --> 00:45:35,670
我们不需要知道

704
00:45:35,760 --> 00:45:38,480
n比2大

705
00:45:38,560 --> 00:45:41,230
但是,我们知道n是比n-1大的

706
00:45:41,320 --> 00:45:43,890
这我点我是能肯定的

707
00:45:43,970 --> 00:45:51,360
所以 这里是1-α_n乘以,

708
00:45:51,440 --> 00:45:56,360
α_k*f(x_k)/(1-α_n),k从1到n-1的总和

709
00:45:56,460 --> 00:46:04,520
如果我没错的话

710
00:46:04,610 --> 00:46:10,680
这里就可以用归纳法 归纳假设

711
00:46:10,760 --> 00:46:14,780
因为这α_k/(1-α_n)的总和为1

712
00:46:14,860 --> 00:46:19,490
然后 消掉1-αn

713
00:46:19,570 --> 00:46:22,010
我们就得到了我们想要的

714
00:46:22,100 --> 00:46:30,380
刚好就是α_k*f(x_k)的总和

715
00:46:30,470 --> 00:46:35,000
所以我们推出把和的f值 最大不超过所有f值的和

716
00:46:35,100 --> 00:46:36,910
引理得证

717
00:46:37,010 --> 00:46:40,750
有点繁琐  但每一步都很明了

718
00:46:40,830 --> 00:46:43,430
你们觉得呢?

719
00:46:45,940 --> 00:46:47,330
那现在 我们就应该

720
00:46:47,410 --> 00:46:49,360
用它用来证明Jensen不等式

721
00:46:49,450 --> 00:46:51,760
下面是见证奇迹的时刻

722
00:46:58,620 --> 00:47:01,860
我们要先做一下期望分析

723
00:47:01,940 --> 00:47:08,930
这里要用到我们的好朋友 指标随机变量

724
00:47:09,010 --> 00:47:14,230
现在 我们想证明这个命题

725
00:47:18,830 --> 00:47:21,820
如果我们有个凹函数f  那f(E[X])

726
00:47:21,930 --> 00:47:27,350
就小于等于E[f(X)]

727
00:47:27,430 --> 00:47:29,870
这个是随机变量 是吧?

728
00:47:29,950 --> 00:47:33,120
比如你想对它采样

729
00:47:33,200 --> 00:47:35,320
你就先从X采样  然后代入f中

730
00:47:35,400 --> 00:47:38,870
这就是这个符号的意义 f(X)

731
00:47:38,960 --> 00:47:41,960
因为X就是随机变量

732
00:47:45,470 --> 00:47:48,570
我们设f为一个凹函数

733
00:47:48,660 --> 00:47:52,750
这个并不难

734
00:47:52,850 --> 00:47:55,830
如果还记得期望的定义的话

735
00:47:55,930 --> 00:47:58,640
对了 我想再做多一点假设

736
00:47:58,730 --> 00:48:04,060
假设X是整数值

737
00:48:05,220 --> 00:48:07,320
那它就是一个整型随机变量

738
00:48:07,400 --> 00:48:11,850
这说明它是一个整型

739
00:48:11,950 --> 00:48:13,090
这里也是要注意一下的

740
00:48:13,220 --> 00:48:14,190
因为我们观察的是运行时间

741
00:48:14,210 --> 00:48:17,380
虽然这个命题对于连续随机变量而言也是成立的

742
00:48:17,480 --> 00:48:19,420
但我们研究的是离散的情况

743
00:48:19,500 --> 00:48:25,140
要不然我还要写下X的域是多少

744
00:48:25,220 --> 00:48:31,360
那么  E[X]的定义是什么?

745
00:48:32,970 --> 00:48:36,190
X只能取整数值

746
00:48:38,030 --> 00:48:40,850
这很简单但是你们要记住它

747
00:48:43,190 --> 00:48:45,220
这是道好题目

748
00:48:49,420 --> 00:48:50,850
我真的对X了解不多

749
00:48:50,940 --> 00:48:52,940
只知道它取整数值

750
00:48:53,020 --> 00:48:57,350
有没人知道X的期望还告诉我们什么?

751
00:49:07,240 --> 00:49:09,300
有多少人完全理解这个?

752
00:49:10,230 --> 00:49:12,170
好吧  好像有点难

753
00:49:16,170 --> 00:49:19,590
期望这东西跟概率有关的 对吧?

754
00:49:20,190 --> 00:49:23,730
所以 从概率的角度上看

755
00:49:23,810 --> 00:49:26,590
当X等于某个值 它有个概率

756
00:49:26,670 --> 00:49:28,870
这是一个提示

757
00:49:34,100 --> 00:49:36,610
然后这里可以看成?

758
00:49:39,890 --> 00:49:41,560
一个和,对

759
00:49:42,330 --> 00:49:44,660
一个和  嗯  X可以在

760
00:49:44,750 --> 00:49:46,230
正负无穷之间取值

761
00:49:46,310 --> 00:49:47,980
这是当然的

762
00:49:48,060 --> 00:49:50,170
还有呢?

763
00:49:51,620 --> 00:49:52,800
这里还少了点东西

764
00:49:52,880 --> 00:49:56,750
如果就这样看  它的和是多少？

765
00:49:57,140 --> 00:50:00,220
对于任意的整形随机变量来说？

766
00:50:00,700 --> 00:50:02,510
是1 很好

767
00:50:02,600 --> 00:50:07,620
所以 我还要在这里加上一个X

768
00:50:08,250 --> 00:50:10,840
这就是期望的定义

769
00:50:10,930 --> 00:50:14,260
现在又是总和的f值

770
00:50:14,340 --> 00:50:18,680
而且这些系数的和又是1

771
00:50:18,780 --> 00:50:22,260
这就跟我们之前证明过的引理非常相像

772
00:50:22,360 --> 00:50:23,730
我们已经在有限大的情况下证明了它

773
00:50:23,810 --> 00:50:28,860
但实际上 即使所有整数放进去它还是成立的

774
00:50:28,950 --> 00:50:30,740
好 我先假设是这样

775
00:50:30,820 --> 00:50:37,560
因为这些概率 也就是α 加起来等于1

776
00:50:38,460 --> 00:50:40,610
所以  我可以用这个不等式

777
00:50:40,680 --> 00:50:45,360
所以它小于或等于  让我整理下

778
00:50:45,450 --> 00:50:47,460
对应引理中的α  这里是Σ求和

779
00:50:47,550 --> 00:50:52,610
x从负无穷到正无穷

780
00:50:52,700 --> 00:50:54,780
α在这里就是概率

781
00:50:54,870 --> 00:51:02,660
概率Pr(X=x)乘以f(x)

782
00:51:06,010 --> 00:51:09,410
好的 就是这样 引理用过了

783
00:51:09,480 --> 00:51:14,050
现在可能我要把引理擦掉了

784
00:51:21,070 --> 00:51:24,570
我偷懒只用引理的可数版本

785
00:51:24,660 --> 00:51:29,120
来证明有限的情况

786
00:51:31,810 --> 00:51:33,890
但课堂上只能做这么多了

787
00:51:35,530 --> 00:51:37,240
那么 这些都是从引理推出的

788
00:51:41,910 --> 00:51:45,460
现在  我想证明的是  这里留点空白

789
00:51:45,540 --> 00:51:48,850
就是  最大为E[f(X)]

790
00:51:51,820 --> 00:51:53,320
就是说这个和

791
00:51:53,410 --> 00:51:55,480
最大为E[f(X)]

792
00:51:55,560 --> 00:51:58,800
实际上它等于E[f(X)]

793
00:51:59,460 --> 00:52:01,130
看起来它们就是相等的  对吧？

794
00:52:01,210 --> 00:52:03,810
一些概率乘以f(X) 然后再求和

795
00:52:03,900 --> 00:52:07,740
看起来就像是E[f(X)]的定义  但其实它不是

796
00:52:07,830 --> 00:52:10,220
这里要小心一点 因为E[f(X)]

797
00:52:10,310 --> 00:52:12,600
其实是指关于

798
00:52:12,690 --> 00:52:16,320
f(X)等于某个特定值时的概率

799
00:52:16,400 --> 00:52:20,570
我们可以把它们列出来

800
00:52:21,010 --> 00:52:22,420
不是很难

801
00:52:26,690 --> 00:52:30,510
这里的小x代表f所有的取值

802
00:52:35,130 --> 00:52:36,800
然后这里是所有

803
00:52:36,880 --> 00:52:39,020
满足f(k)=x的k值

804
00:52:39,100 --> 00:52:42,480
k作为X的取值 使得f(X)=x的

805
00:52:42,560 --> 00:52:46,830
X=k的概率

806
00:52:47,280 --> 00:52:48,600
好的 这是另外一种

807
00:52:48,690 --> 00:52:55,090
用来表示f(X)=x的概率的写法

808
00:52:57,900 --> 00:52:59,110
那么 也就是说

809
00:52:59,200 --> 00:53:00,940
我在用一个特别的方法将这些项组合起来

810
00:53:01,030 --> 00:53:05,360
我想说的是  f(X)有很多不同取值

811
00:53:07,950 --> 00:53:10,360
我又犯迷糊了

812
00:53:10,450 --> 00:53:12,070
我老是用到k

813
00:53:12,160 --> 00:53:13,840
应该换一个叫法

814
00:53:13,930 --> 00:53:19,690
设它为y 不好意思 换个符号表示

815
00:53:26,010 --> 00:53:27,270
这样就好点了

816
00:53:27,350 --> 00:53:30,260
我应该观察X=x时的概率

817
00:53:30,360 --> 00:53:31,650
那么  我真正关心的是

818
00:53:31,740 --> 00:53:33,170
f(X)到底能取什么值

819
00:53:33,250 --> 00:53:34,540
我们设他为y

820
00:53:34,620 --> 00:53:36,910
f能取到的所有的值 称为y

821
00:53:37,000 --> 00:53:39,060
其实就是f的值域  然后...

822
00:53:39,140 --> 00:53:43,160
我找出满足f(X)=y的所有X

823
00:53:43,250 --> 00:53:45,480
如果我把这些概率全加起来

824
00:53:45,560 --> 00:53:47,330
因为这些X都是不同的

825
00:53:47,410 --> 00:53:50,770
这都是一系列的独立事件

826
00:53:50,870 --> 00:53:58,460
所以这个和就是f(X)=y的概率

827
00:53:58,730 --> 00:54:00,400
这个是大写X

828
00:54:00,480 --> 00:54:02,240
小写y 然后

829
00:54:02,340 --> 00:54:07,020
如果我用y乘以它  就得到f(X)的期望

830
00:54:07,100 --> 00:54:11,870
你们思考一下  这两个不等式

831
00:54:16,680 --> 00:54:18,760
这里可能有点奇怪

832
00:54:18,850 --> 00:54:21,340
因为这些和可能是无穷大

833
00:54:21,430 --> 00:54:24,450
但它是成立的

834
00:54:27,550 --> 00:54:29,920
好的 这样就证明了Jensen不等式

835
00:54:30,000 --> 00:54:32,110
不是非常难  才写满了几块黑板

836
00:54:32,210 --> 00:54:36,520
一旦我们有了这个强大的凹性引理

837
00:54:37,990 --> 00:54:39,610
那么,我们只需要利用凹性

838
00:54:39,710 --> 00:54:42,100
我们利用期望的定义 利用凹凸性质

839
00:54:42,210 --> 00:54:44,610
它让我们将f代进去

840
00:54:44,690 --> 00:54:46,960
然后再重组一下 就发现

841
00:54:47,040 --> 00:54:49,130
噢  这就是E[f(X)]了

842
00:54:49,210 --> 00:54:52,640
所以这个不等式是从凹性得来的

843
00:54:54,430 --> 00:54:58,200
好吧,现在回归到算法上

844
00:54:58,280 --> 00:55:01,550
刚说的这些都是基本的概率学的东西

845
00:55:01,640 --> 00:55:06,930
很有实用性

846
00:55:08,430 --> 00:55:11,760
好吧 课堂测验里面会有的 别惊讶

847
00:55:11,840 --> 00:55:14,100
我也是这样过来的

848
00:55:14,180 --> 00:55:15,940
你学算法时会有很多直观的想法

849
00:55:16,040 --> 00:55:18,000
在算法的角度看 好像讲得通

850
00:55:18,100 --> 00:55:20,570
因为你是在根据一些已知的知识来看问题的

851
00:55:20,660 --> 00:55:24,980
因为你是个计算机学者 或是其它类似的

852
00:55:25,070 --> 00:55:27,620
从这门课的目的来看  你们就是计算机学者

853
00:55:27,700 --> 00:55:30,500
但在概率学角度上看

854
00:55:30,590 --> 00:55:34,880
除非你是个数学家  要不很难一眼看出来

855
00:55:34,970 --> 00:55:38,010
因此也很难迅速解决问题

856
00:55:38,090 --> 00:55:41,570
测验一里  速度是很重要的

857
00:55:41,660 --> 00:55:44,160
到期末测验  速度也很重要

858
00:55:44,240 --> 00:55:47,610
当然家庭作业影响不大

859
00:55:47,690 --> 00:55:52,020
所以作业更有趣点

860
00:55:52,100 --> 00:55:56,890
因为你得多用脑子

861
00:55:56,980 --> 00:55:59,240
你得更具有创造力

862
00:55:59,320 --> 00:56:01,360
而且 那是真正地在考验你的算法设计能力

863
00:56:01,440 --> 00:56:03,540
到目前为止 我们主要考的是分析 比如,

864
00:56:03,650 --> 00:56:05,490
你会用概率去证明吗?

865
00:56:05,570 --> 00:56:06,890
你能想到...

866
00:56:07,000 --> 00:56:08,940
你能记得随机化的快速排序

867
00:56:09,020 --> 00:56:12,780
它的运行时间是多少？诸如此类

868
00:56:12,870 --> 00:56:15,480
测验二就会考大家创造力

869
00:56:15,590 --> 00:56:17,270
因为给你们的时间更多了

870
00:56:17,350 --> 00:56:20,660
两个小时确实很难设计出什么

871
00:56:20,770 --> 00:56:23,340
好吧 那么我们想要分析一棵...

872
00:56:23,420 --> 00:56:27,730
随机构造的二叉搜索树的期望高度

873
00:56:27,810 --> 00:56:30,700
虽然我之前已经定义过了

874
00:56:30,800 --> 00:56:32,620
但我再重复一遍

875
00:56:32,710 --> 00:56:35,780
因为已经过了一段时间了

876
00:56:35,870 --> 00:56:37,860
我们要用到一个随机变量

877
00:56:37,950 --> 00:56:45,220
来表示一棵随机化的n结点二叉树的高度

878
00:56:51,470 --> 00:56:54,470
它的n个元素都已经被随机化过了

879
00:56:54,550 --> 00:56:56,080
用随机的排列顺序

880
00:56:56,160 --> 00:57:00,450
从左到右一个个插入到树中

881
00:57:00,530 --> 00:57:02,060
这样的话 树的高度是多少?

882
00:57:02,160 --> 00:57:05,160
所有点的最大深度是多少?

883
00:57:05,260 --> 00:57:06,860
我不研究X_n本身

884
00:57:06,950 --> 00:57:11,680
我先看X_n的期望

885
00:57:11,770 --> 00:57:14,540
我们仍然没什么直观的答案

886
00:57:14,630 --> 00:57:17,720
但是2的X次方就是一个凹函数

887
00:57:17,810 --> 00:57:21,790
好的  它看起来是这样的 非常陡

888
00:57:21,870 --> 00:57:25,910
原谅我的渣画工吧 这其实是2的X次方

889
00:57:26,000 --> 00:57:27,850
其实我的柱状图更瞎眼

890
00:57:27,940 --> 00:57:31,300
我们之所以要把它设成随机变量

891
00:57:31,400 --> 00:57:34,820
再写进这些代数式子里

892
00:57:34,910 --> 00:57:39,810
主要就是为了能够分情况讨论

893
00:57:39,910 --> 00:57:41,270
我们通常都会这么做

894
00:57:41,350 --> 00:57:45,670
因为这会分成很多种不同的情况

895
00:57:47,330 --> 00:57:51,690
我的意思是 我们一开始怎么建立这棵树?

896
00:57:51,790 --> 00:57:54,800
第一件事是我们找第一个结点

897
00:57:54,880 --> 00:57:56,660
加进树里 作为根

898
00:57:56,750 --> 00:57:59,810
好吧  所以不管数组的第一个数是什么

899
00:57:59,900 --> 00:58:01,180
我们并不关心这个数组...

900
00:58:01,280 --> 00:58:04,140
它是什么样顺序 我们把它放在根的位置

901
00:58:04,240 --> 00:58:05,370
它就成了根结点

902
00:58:05,470 --> 00:58:07,900
我们之后都不改变根结点

903
00:58:07,990 --> 00:58:10,190
现在 对于剩下的根结点

904
00:58:10,280 --> 00:58:14,450
有些是小于这个点 它们就往这边走

905
00:58:14,550 --> 00:58:17,660
我们设根结点为r吧

906
00:58:17,750 --> 00:58:20,030
然后有另外一些是大于r的

907
00:58:20,130 --> 00:58:21,370
就走到这里去了

908
00:58:21,460 --> 00:58:22,600
可能有些在这儿

909
00:58:22,690 --> 00:58:23,960
可能有些在那儿 谁知道呢？

910
00:58:24,000 --> 00:58:27,460
任意划分 实际上是均匀随机划分

911
00:58:27,540 --> 00:58:29,820
这样说你们可能更熟悉

912
00:58:29,910 --> 00:58:32,060
无论这边有k个元素

913
00:58:32,140 --> 00:58:35,730
还是那边有n-k个元素

914
00:58:35,830 --> 00:58:38,710
k取任意值  都是等可能的

915
00:58:38,790 --> 00:58:40,820
因为挑选k值的概率是均匀的

916
00:58:40,900 --> 00:58:42,050
挑选根节点的概率也是均匀的

917
00:58:42,130 --> 00:58:44,370
它只是随机全排列的第一个元素

918
00:58:44,460 --> 00:58:47,390
那么  我准备将这个参数化

919
00:58:47,470 --> 00:58:48,880
这里有多少个点

920
00:58:48,970 --> 00:58:50,630
这里又有多少个点?

921
00:58:50,730 --> 00:58:54,830
由于这棵树是 无论这里有多少结点

922
00:58:54,920 --> 00:58:56,860
它都是随机二叉搜索树

923
00:58:56,950 --> 00:58:58,140
那我选出了r之后

924
00:58:58,230 --> 00:59:00,580
哪些在左 哪些在右 就已经决定好了

925
00:59:00,670 --> 00:59:02,010
所以 我只要划分就行了

926
00:59:02,100 --> 00:59:03,350
就像快速排序过程一样

927
00:59:03,450 --> 00:59:07,170
我把元素划分到r的左边 r的右边

928
00:59:07,270 --> 00:59:10,250
然后我再递归地构建这棵树

929
00:59:10,340 --> 00:59:14,060
再在树两边的子排列上 构建随机二叉搜索树

930
00:59:14,150 --> 00:59:18,250
因为均匀打乱的全排列  它的子排列也是均匀打乱的

931
00:59:18,340 --> 00:59:22,150
好吧 这本质上是递归的问题

932
00:59:22,230 --> 00:59:24,550
我们知道怎么分析递归型的问题

933
00:59:24,640 --> 00:59:27,210
我们只需要知道

934
00:59:27,310 --> 00:59:29,310
这里有k-1个元素

935
00:59:29,400 --> 00:59:32,920
那里有n-k个元素

936
00:59:33,000 --> 00:59:37,900
然后 这表示r排在第k位

937
00:59:37,990 --> 00:59:42,700
要记住 这个"第几位"就是指排序后的数组下标

938
00:59:42,790 --> 00:59:48,160
那么 我们讲到哪了?

939
01:00:07,600 --> 01:00:15,220
如果这个根结点r排在第k位

940
01:00:15,300 --> 01:00:19,640
如果这是一次事件中的条件命题

941
01:00:19,720 --> 01:00:24,940
这事件是随机事件  那么我们就有X_n等于

942
01:00:25,020 --> 01:00:34,200
1加上X_k-1、X_n-k间的最大值

943
01:00:35,400 --> 01:00:37,170
因为整棵树的高度是

944
01:00:37,250 --> 01:00:40,630
两边子树的高度的最大值加一

945
01:00:40,720 --> 01:00:43,550
最顶层也要算一层

946
01:00:43,640 --> 01:00:46,250
所以 自然会有这条式子

947
01:00:46,340 --> 01:00:49,840
我们要分析的是Y_n  所以对于Y_n

948
01:00:49,930 --> 01:00:52,520
我们设它为2的X_n次方

949
01:00:52,620 --> 01:00:59,600
所以 它等于2乘以取最大值...2^X_k-1

950
01:00:59,680 --> 01:01:02,630
也就是Yk-1

951
01:01:02,710 --> 01:01:07,360
然后是2^X_n-k,也就是Yn-k

952
01:01:07,460 --> 01:01:13,160
也许你们已经开始明白 为什么我们对Y感兴趣

953
01:01:13,250 --> 01:01:17,500
而不是对X  因为要这样 我们才知道怎么做

954
01:01:17,580 --> 01:01:20,480
当我们要处理递归问题时

955
01:01:20,570 --> 01:01:22,480
例如  运行时间的期望

956
01:01:22,570 --> 01:01:24,710
我们这里还没求期望

957
01:01:24,800 --> 01:01:27,300
但是 当我们计算快排的运行时间的期望时

958
01:01:27,380 --> 01:01:30,530
我们也有像这样 用2乘以.. 我意思是

959
01:01:30,620 --> 01:01:32,820
我们会遇到一些递归的子问题

960
01:01:32,900 --> 01:01:34,390
它们会叠加起来

961
01:01:34,480 --> 01:01:36,130
就比如这里  我们有个因子2

962
01:01:36,210 --> 01:01:37,760
这里有个最大值

963
01:01:37,860 --> 01:01:40,930
但是 直观来讲 我们知道如何拿随机变量...

964
01:01:41,020 --> 01:01:42,980
去和一个常数相乘  就像

965
01:01:43,060 --> 01:01:44,280
这两个递归子问题

966
01:01:44,370 --> 01:01:47,260
这个值等于这两个中的最大值

967
01:01:47,350 --> 01:01:49,100
虽然我们并不知道它是多少

968
01:01:49,190 --> 01:01:52,290
但是 这里的话 由于是1加上某某

969
01:01:52,380 --> 01:01:54,530
我们就不好处理了

970
01:01:54,620 --> 01:01:56,130
而实际上 我们是能够

971
01:01:56,220 --> 01:01:58,290
很好地解决递归问题的

972
01:01:58,370 --> 01:02:00,760
除非遇到有常数因子的情况

973
01:02:00,850 --> 01:02:03,560
而且 这个1+看起来确实

974
01:02:03,650 --> 01:02:05,280
不怎么会影响常数因子 似乎是这样

975
01:02:05,360 --> 01:02:07,540
但它其实是有很大关系的

976
01:02:07,630 --> 01:02:09,390
如果取幂的话 它就变成因子2

977
01:02:09,490 --> 01:02:11,770
但这里 我们很难知道这个1+要怎么处理

978
01:02:11,860 --> 01:02:13,410
如果我们真要尝试分析它的话

979
01:02:13,510 --> 01:02:16,990
你们自己在家里自己试试也是不错的

980
01:02:17,080 --> 01:02:19,850
如果你尝试从X_n入手分析

981
01:02:19,940 --> 01:02:23,040
你可能会迷失在这个1+这里 然后就找不出头绪

982
01:02:23,140 --> 01:02:25,350
什么都证明不了

983
01:02:25,430 --> 01:02:27,210
当我们用因子2  情况就好多了

984
01:02:27,290 --> 01:02:29,680
我们就大概明白怎么处理它了

985
01:02:29,770 --> 01:02:34,260
我们完成证明之后 我们再继续讨论

986
01:02:36,540 --> 01:02:39,010
为什么这里要用Y_n来代替X_n

987
01:02:39,100 --> 01:02:40,560
但现在 我们要用Y_n

988
01:02:40,640 --> 01:02:42,020
那么 我们得到了一个递归方程

989
01:02:42,100 --> 01:02:44,070
但它还是被限制在这个特定的事件里

990
01:02:44,150 --> 01:02:48,330
那我们要怎么把递归转换成一个一般化的命题？

991
01:02:58,670 --> 01:03:02,320
抱歉 没听清？ 按照事件的概率来划分?

992
01:03:02,400 --> 01:03:09,370
差不多  实际上 这些事件都是独立的

993
01:03:09,460 --> 01:03:10,890
应该说 它们都是等可能事件

994
01:03:10,990 --> 01:03:12,140
它们并不是相互独立的

995
01:03:12,230 --> 01:03:14,720
实际上 是决定一个影响全局的关系

996
01:03:15,510 --> 01:03:20,560
那么 怎么去用代数式来表达一次事件?

997
01:03:24,060 --> 01:03:27,870
指标随机变量  很好

998
01:03:30,420 --> 01:03:33,930
还记得指标随机变量吗?

999
01:03:34,020 --> 01:03:37,710
所有分析里都用了指标随机变量

1000
01:03:37,800 --> 01:03:40,650
它们可以用来表示这一事件

1001
01:03:40,730 --> 01:03:45,260
用Z_nk来表示

1002
01:03:47,440 --> 01:03:52,560
当根结点为第k位时 Z为1

1003
01:03:55,900 --> 01:03:57,830
否则为0

1004
01:04:03,310 --> 01:04:07,130
所以 如果n是固定的

1005
01:04:07,210 --> 01:04:09,110
你取任意的k值

1006
01:04:09,190 --> 01:04:11,980
对应事件发生的概率都会是相等的

1007
01:04:12,070 --> 01:04:14,130
Z_nk=1的概率

1008
01:04:14,220 --> 01:04:22,000
等于这个指标随机变量的期望

1009
01:04:22,080 --> 01:04:25,400
因为Z_nk不是为1就是为0

1010
01:04:25,480 --> 01:04:27,730
加上0并不影响期望的大小

1011
01:04:27,810 --> 01:04:31,720
所以这个很可能是

1012
01:04:31,810 --> 01:04:33,900
1/n  如果我没错的话

1013
01:04:34,000 --> 01:04:35,600
所以这里一共有

1014
01:04:35,690 --> 01:04:36,920
n种可能的根结点

1015
01:04:37,010 --> 01:04:38,190
而它们都是等概率的

1016
01:04:38,280 --> 01:04:41,510
因为排列是被均匀打乱的

1017
01:04:41,600 --> 01:04:45,930
现在我就可以重写这个命题

1018
01:04:46,010 --> 01:04:49,210
写成Z_nk的形式

1019
01:04:49,290 --> 01:04:52,290
那我就可以选择一种情况来讨论

1020
01:04:52,800 --> 01:05:00,560
所以Y_n等于Σ求和  k从1到n

1021
01:05:00,640 --> 01:05:07,710
Z_nk 乘以2

1022
01:05:08,110 --> 01:05:14,060
再乘以 Y_k-1、Y_n-k间的最大值

1023
01:05:18,370 --> 01:05:21,550
现在 我们又看到老朋友——递归

1024
01:05:21,650 --> 01:05:23,080
我们要解开它

1025
01:05:23,170 --> 01:05:24,870
其实并不是解递归

1026
01:05:24,960 --> 01:05:26,100
因为这是一个随机变量

1027
01:05:26,190 --> 01:05:28,160
它还是个递推的随机变量

1028
01:05:28,250 --> 01:05:30,720
那么 我们首先对两边取期望

1029
01:05:30,810 --> 01:05:34,130
我们唯一能找到限界的东西

1030
01:05:34,210 --> 01:05:39,200
Y_n在坏情况下可能等于n^2  抱歉 不是n^2

1031
01:05:39,280 --> 01:05:41,950
它能等于n^2

1032
01:05:42,030 --> 01:05:47,570
但在更差的情况时它能等于2~n

1033
01:05:47,660 --> 01:05:50,880
因为树的高度X_n可能等于n

1034
01:05:50,960 --> 01:05:53,500
而且  Y_n等于2的X_n次方

1035
01:05:53,590 --> 01:05:54,830
所以 它可能是2的n次方

1036
01:05:54,910 --> 01:05:58,800
我们只想证明它的多项式阶为n

1037
01:05:58,890 --> 01:06:00,020
如果多项式只有n和常数时

1038
01:06:00,100 --> 01:06:02,720
我们对它取对数 它就等于log n了

1039
01:06:02,800 --> 01:06:05,480
好吧  那我们来计算期望

1040
01:06:05,560 --> 01:06:08,410
很明显这个是成立的

1041
01:06:08,490 --> 01:06:12,750
好的 指数随机变量乘以

1042
01:06:12,840 --> 01:06:19,710
递归随机变量 它们加起来总和的期望

1043
01:06:24,700 --> 01:06:27,790
那么 首先 哎呀  漏了一个括号

1044
01:06:27,880 --> 01:06:34,200
我们在这个分析中要做的第一件事是什么?

1045
01:06:36,390 --> 01:06:40,730
这个应该 是的 期望的线性性质

1046
01:06:40,820 --> 01:06:43,430
这点很容易记住

1047
01:06:44,260 --> 01:06:47,980
好的 我们有一个和 那我们把E放进去

1048
01:07:02,930 --> 01:07:07,360
好的 我们现在有个乘积的期望

1049
01:07:07,450 --> 01:07:11,680
有什么用? 独立性

1050
01:07:11,780 --> 01:07:13,710
显然 这些事件是相互独立

1051
01:07:13,800 --> 01:07:17,200
然后 我们可以这样写

1052
01:07:19,900 --> 01:07:23,080
它就等于两个期望的乘积

1053
01:07:23,160 --> 01:07:24,800
然后  我们把这个2放到外面

1054
01:07:24,870 --> 01:07:29,630
因为它不是...把它留在这里没用

1055
01:07:34,920 --> 01:07:36,320
Y是不是写得跟X有点像?

1056
01:07:36,410 --> 01:07:38,410
我都差点认不出来了 不好意思

1057
01:07:38,500 --> 01:07:40,960
这些应该全都是关于Y的

1058
01:07:46,920 --> 01:07:51,100
好的 很聪明 随机变量

1059
01:07:51,190 --> 01:07:54,930
那为什么它们是相互独立的?

1060
01:07:55,010 --> 01:07:57,940
这里我们关注的是根结点是哪个

1061
01:07:58,020 --> 01:08:01,500
在有n个结点时 根结点排第几位

1062
01:08:01,600 --> 01:08:05,460
在这里  我们关心根结点是什么 我的意思是

1063
01:08:05,540 --> 01:08:07,570
它可能会导致各种各样的情况

1064
01:08:07,670 --> 01:08:09,600
左边的树会是什么样子

1065
01:08:09,690 --> 01:08:11,090
右边的树会是什么样子

1066
01:08:11,200 --> 01:08:12,490
每种情况都是独立的

1067
01:08:12,570 --> 01:08:14,930
因为这些数都是均匀打乱的

1068
01:08:15,010 --> 01:08:17,340
所以 挑选这家伙的概率是均匀的

1069
01:08:17,420 --> 01:08:19,410
然后 这家伙也决定了

1070
01:08:19,490 --> 01:08:21,010
左边和右边又会选哪些点来做划分点

1071
01:08:21,100 --> 01:08:24,060
它们都是相互独立的递归的选择

1072
01:08:24,150 --> 01:08:26,370
比如哪个点会成为左子树的根?

1073
01:08:26,460 --> 01:08:29,010
哪个点又会是左子树的左子树的根  诸如此类

1074
01:08:29,100 --> 01:08:30,840
所以这里就更讲技巧

1075
01:08:30,930 --> 01:08:33,960
之前说它是算法里的随机选择的结果

1076
01:08:34,060 --> 01:08:36,400
现在说它在前面的随机数出来时

1077
01:08:36,490 --> 01:08:39,240
就已经被决定好了

1078
01:08:39,330 --> 01:08:41,750
虽然有点奇怪  但它仍然是独立的

1079
01:08:41,840 --> 01:08:46,310
这个过程就跟快速排序里的一样

1080
01:08:48,210 --> 01:08:54,820
好的  我们继续

1081
01:09:02,080 --> 01:09:05,020
接着  可能会讲得粗糙一点

1082
01:09:06,030 --> 01:09:08,050
有一件事我们是知道的

1083
01:09:08,140 --> 01:09:12,750
E[Z_nk],写在这里的

1084
01:09:12,840 --> 01:09:16,910
等于1/n  太好了

1085
01:09:17,000 --> 01:09:18,910
那我们外面就变成2/n了

1086
01:09:19,000 --> 01:09:21,300
那我们这里就变成

1087
01:09:21,390 --> 01:09:24,060
两者最大值的期望的总和

1088
01:09:24,140 --> 01:09:25,760
通常  我们写成

1089
01:09:25,850 --> 01:09:28,300
我想大家Tmax

1090
01:09:28,400 --> 01:09:30,230
或者用Ymax来表示的

1091
01:09:30,320 --> 01:09:33,800
总之你得用两者中较大那个来表示

1092
01:09:33,880 --> 01:09:38,340
然后 还有个小技巧  技巧从来不嫌多

1093
01:09:38,420 --> 01:09:42,110
技巧是两者的最大值不超过它们的和

1094
01:09:42,200 --> 01:09:44,160
因为它们是非负的

1095
01:09:44,240 --> 01:09:50,260
那么 我们还有2/n  对k从1到n求和

1096
01:09:50,350 --> 01:09:59,150
然后这里变为和的期望 而不是最大值的期望

1097
01:10:02,660 --> 01:10:05,060
好的 这个是关键步骤

1098
01:10:05,150 --> 01:10:07,820
我们开始把我们的限界放大了

1099
01:10:07,900 --> 01:10:09,130
在此之前  我们的限界都是精确的

1100
01:10:09,220 --> 01:10:11,810
现在 我们开始变得宽松了

1101
01:10:11,890 --> 01:10:14,130
的确  两者的最大值不超过它们的和

1102
01:10:14,210 --> 01:10:17,120
但是 它是一个很宽松的上界

1103
01:10:17,210 --> 01:10:20,840
这个我们先记住

1104
01:10:20,930 --> 01:10:23,990
求和有什么用?

1105
01:10:26,140 --> 01:10:28,420
这点看起来又挺熟悉的

1106
01:10:28,490 --> 01:10:30,890
现在我们有两样东西的和的总和

1107
01:10:30,980 --> 01:10:35,630
我想让它成为一样东西的和

1108
01:10:41,120 --> 01:10:44,480
大声点? 可以利用期望的线性性质 好的

1109
01:10:44,570 --> 01:10:47,000
我们要做的事第一件事是这个

1110
01:10:50,360 --> 01:10:52,310
根据线性将它们分离出来

1111
01:10:52,410 --> 01:10:55,340
现在我有2个n项的和

1112
01:10:58,690 --> 01:11:01,110
对 我可以将它分成这一部分的和

1113
01:11:01,210 --> 01:11:03,350
和那一部分的和

1114
01:11:03,440 --> 01:11:06,830
关于这两个和你知道什么?

1115
01:11:07,680 --> 01:11:10,140
我们已经知道什么?

1116
01:11:10,570 --> 01:11:12,050
它们实际上是相等的

1117
01:11:12,140 --> 01:11:14,430
每一项在这里都出现了两遍

1118
01:11:14,510 --> 01:11:15,940
一个是k-1

1119
01:11:16,030 --> 01:11:17,190
另一个是n-k

1120
01:11:17,270 --> 01:11:19,890
就算是奇数也是这样

1121
01:11:19,990 --> 01:11:22,720
那么 我们只需要算出其中一个和

1122
01:11:22,810 --> 01:11:25,320
再用它乘以2

1123
01:11:25,410 --> 01:11:28,070
所以这里是4/n乘以这个和

1124
01:11:28,150 --> 01:11:29,810
我在重新写一遍

1125
01:11:29,890 --> 01:11:34,630
对E[Y_k]求和  k从0到n-1

1126
01:11:34,720 --> 01:11:36,380
要知道每个Y_k

1127
01:11:36,480 --> 01:11:39,810
的出现次数刚好等于2

1128
01:11:39,890 --> 01:11:41,760
那我们现在有了这个递归

1129
01:11:41,850 --> 01:11:44,940
我推出了E[Y_n]最大等于这东西

1130
01:11:45,030 --> 01:11:49,350
这么写方便记忆

1131
01:11:51,040 --> 01:11:53,710
如何? 很给力吧？

1132
01:11:53,800 --> 01:11:56,710
现在 我只需要解这个递归

1133
01:11:56,800 --> 01:12:00,030
我要怎么解开这个恶心的递归?

1134
01:12:00,120 --> 01:12:07,460
代换法 嗯嗯 不是主方法

1135
01:12:08,890 --> 01:12:10,720
它是个相当恶心的递归

1136
01:12:10,810 --> 01:12:12,150
我准备要猜一个数

1137
01:12:12,250 --> 01:12:16,750
而我已经告诉过你们  我猜的是n^3

1138
01:12:21,060 --> 01:12:23,330
我觉得n^3相当准了

1139
01:12:23,430 --> 01:12:27,440
而且这个是能证明出来的

1140
01:12:30,670 --> 01:12:35,010
代换法 代换法

1141
01:12:35,130 --> 01:12:37,410
其实就是归纳法

1142
01:12:41,200 --> 01:12:44,860
所有归纳法都要求有两样东西

1143
01:12:44,960 --> 01:12:48,520
基本上每个都是  除非你这么有想象力

1144
01:12:48,620 --> 01:12:49,890
它要求有一个基础命题

1145
01:12:50,020 --> 01:12:51,660
这里的基础命题就是n为O(1)阶

1146
01:12:51,760 --> 01:12:53,140
我没写出来 不过这是肯定的

1147
01:12:53,250 --> 01:12:55,720
当你有常数级大小的树时  它的高度也是常数级的

1148
01:12:55,820 --> 01:12:58,250
所以这是成立的

1149
01:12:58,350 --> 01:13:07,260
只要我们设c充分大就为真

1150
01:13:12,850 --> 01:13:14,930
好的 别忘了基础命题

1151
01:13:15,030 --> 01:13:16,800
很多人考试的时候忘了这个

1152
01:13:16,900 --> 01:13:20,280
我们有时甚至在出题时提及了基础命题

1153
01:13:20,420 --> 01:13:22,250
虽然 通常我们并不提及基础命题

1154
01:13:22,360 --> 01:13:23,720
但你应该假设有这么一个存在

1155
01:13:23,820 --> 01:13:26,900
在使用代换法证明时 你就必须这么做

1156
01:13:27,010 --> 01:13:32,600
好的 现在我们进行归纳

1157
01:13:34,360 --> 01:13:36,930
我要证明E[Yn]最大为C(n^3)

1158
01:13:37,040 --> 01:13:39,100
同时假设 对较小的n它也成立

1159
01:13:39,210 --> 01:13:41,360
你应该把归纳假设写这里

1160
01:13:41,480 --> 01:13:44,070
但是我不写因为时间不够了

1161
01:13:44,170 --> 01:13:46,920
我们有这个递推式

1162
01:13:47,040 --> 01:13:50,300
E[Yn]最大等于 这东西

1163
01:13:50,830 --> 01:13:53,550
所以E[Yn]最大等于4/n

1164
01:13:53,670 --> 01:14:02,720
乘以ΣE[Yk] k从0到n-1

1165
01:14:02,810 --> 01:14:06,280
我们注意到k总是比n小的

1166
01:14:06,370 --> 01:14:08,800
所以我们用上归纳

1167
01:14:08,900 --> 01:14:12,880
这就是 最大为 4/n

1168
01:14:12,990 --> 01:14:20,000
乘以Σck^3   k从0到n-1

1169
01:14:20,100 --> 01:14:23,650
这个就是归纳假设

1170
01:14:25,970 --> 01:14:31,750
很好 现在 需要给这个和找到上界

1171
01:14:31,860 --> 01:14:35,740
如果你记性好的话

1172
01:14:35,860 --> 01:14:38,160
那你会知道一个接近这个和的式子

1173
01:14:38,260 --> 01:14:40,870
但我没这么好记性

1174
01:14:41,060 --> 01:14:42,830
但我从来没记过这个和

1175
01:14:42,950 --> 01:14:45,580
我都不记得

1176
01:14:45,680 --> 01:14:48,160
12岁以前学过的东西都忘了

1177
01:14:48,260 --> 01:14:51,300
不过我仍然记得圆周率

1178
01:14:51,400 --> 01:14:53,390
但是我现在想记住的东西

1179
01:14:53,490 --> 01:14:55,700
都没以前记得牢了

1180
01:14:55,820 --> 01:14:58,300
所以我认不出这个和

1181
01:14:58,460 --> 01:15:02,120
有什么好的方法去估算这个和吗?

1182
01:15:03,470 --> 01:15:05,080
积分 很好

1183
01:15:06,740 --> 01:15:11,060
那么,我准备将c提出来

1184
01:15:11,170 --> 01:15:13,450
这就变成4c/n

1185
01:15:13,550 --> 01:15:15,560
这个和最大等于这个积分

1186
01:15:15,680 --> 01:15:18,550
如果把范围写的正确一点  你还得加上1

1187
01:15:18,780 --> 01:15:21,190
不是n-1  要把它加到n

1188
01:15:22,080 --> 01:15:24,720
书上面有的

1189
01:15:24,830 --> 01:15:27,570
这又是直观的东西  只要说你有一个单调函数 这是关键

1190
01:15:27,670 --> 01:15:29,640
这样的话  你就有一个这样的曲线

1191
01:15:29,880 --> 01:15:32,960
然后 和就是将每个函数值都

1192
01:15:33,060 --> 01:15:36,590
按1加权相加得到的

1193
01:15:36,710 --> 01:15:39,830
积分就是计算弧线下面的面积

1194
01:15:39,970 --> 01:15:41,730
所以  如果你观察

1195
01:15:41,830 --> 01:15:43,230
这个积分的逼近

1196
01:15:43,340 --> 01:15:45,700
我的意思是 这东西就肯定是...

1197
01:15:45,810 --> 01:15:50,110
当积分范围往后加1后 它就是那个和

1198
01:15:50,220 --> 01:15:51,710
那它就是最大为 这个积分

1199
01:15:51,820 --> 01:15:53,170
那这就是这幅图的证明

1200
01:15:53,350 --> 01:15:55,970
书上面有写

1201
01:15:56,080 --> 01:15:58,800
第42面 好象是

1202
01:15:58,900 --> 01:16:01,620
现在 很容易就能算出这个积分

1203
01:16:01,810 --> 01:16:07,350
x^3的积分等于x^4/4

1204
01:16:07,470 --> 01:16:10,080
我写对了  然后,将n代进去

1205
01:16:10,200 --> 01:16:13,380
这个是0 减去0不影响

1206
01:16:13,480 --> 01:16:16,070
0的四次方还是0

1207
01:16:16,170 --> 01:16:19,890
所以它是n^4/4

1208
01:16:20,020 --> 01:16:24,900
所以有4c/n乘以n^4/4

1209
01:16:25,000 --> 01:16:28,540
刚刚好,4跟4约掉

1210
01:16:28,660 --> 01:16:30,830
这个4要变成3  因为这里消掉了

1211
01:16:30,930 --> 01:16:33,900
然后有n^3

1212
01:16:34,010 --> 01:16:37,880
我们得到cn^3 很顺利啊

1213
01:16:37,990 --> 01:16:40,420
因为这正是我们想证明的

1214
01:16:40,520 --> 01:16:46,700
好的 只是这个证明稍微绕了下弯  因为它没有残余项

1215
01:16:46,810 --> 01:16:49,830
这过程都很粗糙

1216
01:16:49,940 --> 01:16:51,520
但我们运气真的好

1217
01:16:51,800 --> 01:16:53,800
我们在适当的地方粗糙了点

1218
01:16:54,110 --> 01:16:55,480
所以这个证明也要有点技巧的

1219
01:16:55,590 --> 01:16:57,470
如果你自己试着做的话

1220
01:16:57,570 --> 01:16:59,750
很容易写得过分粗糙

1221
01:16:59,840 --> 01:17:03,250
这样就变得不容易得到正确结果

1222
01:17:03,360 --> 01:17:05,030
但这个就是恰好有用

1223
01:17:05,130 --> 01:17:08,690
关于它的话 我想多说一点

1224
01:17:08,800 --> 01:17:11,700
还剩一分钟

1225
01:17:11,790 --> 01:17:13,860
那么我们又得出新结论

1226
01:17:13,960 --> 01:17:17,250
没时间就不写了

1227
01:17:17,370 --> 01:17:21,740
但是这里 我们刚刚证明Y_n的一个界限

1228
01:17:21,870 --> 01:17:23,220
Y_n是2的X_n次方

1229
01:17:23,620 --> 01:17:26,300
但我们关心的是X_n

1230
01:17:26,420 --> 01:17:27,790
那我们用Jensen不等式

1231
01:17:27,900 --> 01:17:31,960
我们有2的E[X_n]次方小于等于2的X_n次方的期望值

1232
01:17:32,060 --> 01:17:34,630
这里就用上Y_n的定义

1233
01:17:34,730 --> 01:17:38,000
那现在我们知道E[Y_n]是O(n^3)

1234
01:17:38,100 --> 01:17:40,060
好 我们设这个常数

1235
01:17:40,160 --> 01:17:41,570
是充分大的

1236
01:17:41,670 --> 01:17:43,610
我们没有不知道这个常数有多大

1237
01:17:43,800 --> 01:17:46,820
但这不影响  因为我们要对两边取对数

1238
01:17:46,910 --> 01:17:50,080
我们得E[X_n]最大等于log O(n^3)

1239
01:17:50,220 --> 01:17:52,080
这个常数是乘上去的

1240
01:17:52,370 --> 01:17:54,160
所以 它在取对数时就成了加法的

1241
01:17:54,290 --> 01:17:56,890
这个常数是指数

1242
01:17:57,030 --> 01:17:59,710
取对数后变成乘数

1243
01:17:59,820 --> 01:18:01,680
3logn加上O(1)

1244
01:18:01,790 --> 01:18:06,040
这就是随机二叉搜索树高度

1245
01:18:06,140 --> 01:18:08,270
的一个很紧凑的一个上界

1246
01:18:08,370 --> 01:18:10,410
期望高度 应该这么说

1247
01:18:10,510 --> 01:18:14,240
实际上X_n的期望高度

1248
01:18:15,310 --> 01:18:23,850
等于 我是说大约等于

1249
01:18:23,940 --> 01:18:30,830
我这里没法太精确 2.9882乘以log n

1250
01:18:30,930 --> 01:18:34,250
这个是我的一个朋友算出来的

1251
01:18:34,680 --> 01:18:42,280
Luke Devroy 1986年的时候

1252
01:18:45,720 --> 01:18:49,620
他现在在McGill大学当教授

1253
01:18:49,730 --> 01:18:53,140
不过我们已经算得很接近了  3对2.98

1254
01:18:53,250 --> 01:18:54,590
我在这里不证了

1255
01:18:54,790 --> 01:18:56,120
最难的部分是计算下界

1256
01:18:56,220 --> 01:18:59,420
不过就这么多吧

1257
01:18:59,550 --> 01:19:02,320
我应该再说说

1258
01:19:02,420 --> 01:19:04,290
为什么用Y_n替换X_n

1259
01:19:04,480 --> 01:19:06,070
其实是马虎了

1260
01:19:06,180 --> 01:19:09,650
这一步 我们说

1261
01:19:09,750 --> 01:19:13,840
这两个数的最大值不超过它们的和

1262
01:19:14,010 --> 01:19:16,770
这个对于X成立

1263
01:19:16,880 --> 01:19:20,830
对于Y也是成立的 但对Y更合适

1264
01:19:20,960 --> 01:19:24,560
这里有点奇怪 因为

1265
01:19:24,660 --> 01:19:27,800
我们在这讨论的是k的所有可能的值

1266
01:19:27,900 --> 01:19:31,170
因为这必须对于所有k值都成立

1267
01:19:31,290 --> 01:19:33,530
我意思是 我们同一时间在估算所有这些情况的上下界

1268
01:19:33,640 --> 01:19:35,420
所有的情况

1269
01:19:35,550 --> 01:19:39,850
这里我们比较k-1和n-k

1270
01:19:39,950 --> 01:19:42,990
实际上 在这里 它是一个多项式的版本

1271
01:19:43,090 --> 01:19:50,540
但是 如果你取两个数a和b

1272
01:19:50,660 --> 01:19:55,140
你可以说 a、b的最大值是小于等于a+b

1273
01:19:55,240 --> 01:19:57,060
另一方面

1274
01:19:57,160 --> 01:20:01,020
2的a次方和2的b次方的最大值是

1275
01:20:01,130 --> 01:20:04,230
小于等于2^a+2^b

1276
01:20:04,380 --> 01:20:05,750
这个是不是比那个好理解

1277
01:20:05,860 --> 01:20:07,660
当然两种都是一样的

1278
01:20:07,760 --> 01:20:14,470
但当|a-b|逐渐变大时

1279
01:20:14,600 --> 01:20:17,110
这一个收敛的速度

1280
01:20:17,220 --> 01:20:20,330
比那个收敛的速度要快

1281
01:20:20,440 --> 01:20:21,650
因为我们从...

1282
01:20:21,740 --> 01:20:24,870
a、b间的差距的绝对值来看的

1283
01:20:25,030 --> 01:20:29,660
这就是为什么这个比那个更好

1284
01:20:29,790 --> 01:20:32,720
即使a和b差不多大  它表现还是会很糟糕

1285
01:20:32,820 --> 01:20:34,410
但是我们还是试着去解决这个问题

1286
01:20:34,520 --> 01:20:38,880
对于所有k-1和n-k的可能的划分来说

1287
01:20:38,980 --> 01:20:40,500
所以 尽管有些情况下是错的

1288
01:20:40,640 --> 01:20:42,790
例如它是刚好中分的时候 两边子树相等

1289
01:20:42,890 --> 01:20:44,420
但是当倾斜得比较多的时候

1290
01:20:44,570 --> 01:20:47,200
这个就非常接近这个了

1291
01:20:47,340 --> 01:20:49,530
然而这个离这个还是很远

1292
01:20:49,630 --> 01:20:51,010
那你就要在它放大的太多之前

1293
01:20:51,130 --> 01:20:52,800
迅速达到你想要的边界了

1294
01:20:52,900 --> 01:20:55,360
但是因为这里收敛速度很快  所以你不会放得太大

1295
01:20:55,460 --> 01:20:56,710
这只是直观的解释

1296
01:20:56,820 --> 01:20:58,690
你们试下 看看X_n会怎样

1297
01:20:58,790 --> 01:21:01,840
它解不出来

1298
01:21:02,800 --> 01:21:04,240
星期三见

