1
00:00:05,000 --> 00:00:09,580
OK, good morning. So today, we're going to

2
00:00:09,610 --> 00:00:15,330
continue our exploration of multithreaded algorithms.

3
00:00:15,360 --> 00:00:19,500
Last time we talked about some aspects of scheduling,

4
00:00:19,520 --> 00:00:23,630
and a little bit about linguistics

5
00:00:23,630 --> 00:00:28,070
to describe a multithreaded competition.

6
00:00:28,110 --> 00:00:29,450
And today, we're going to

7
00:00:29,460 --> 00:00:31,190
actually deal with some algorithms.

8
00:00:45,730 --> 00:00:48,130
So, we're going to start out with a really simple,

9
00:00:48,160 --> 00:00:50,330
actually, what's fun about this, actually,

10
00:00:50,360 --> 00:00:52,390
is that everything I'm going to teach you today

11
00:00:52,420 --> 00:00:56,020
I could have taught you in week two,

12
00:00:56,060 --> 00:00:58,380
OK, because basically it's just

13
00:00:58,420 --> 00:01:01,910
taking the divide and conquer hammer,

14
00:01:01,950 --> 00:01:05,520
and just smashing problem after problem with it.

15
00:01:05,550 --> 00:01:11,960
OK, and so, actually next week's lectures on caching,

16
00:01:11,980 --> 00:01:14,320
also very similar.

17
00:01:14,360 --> 00:01:18,920
So, everybody should bone up on their master theorem

18
00:01:18,960 --> 00:01:24,950
and substitution methods for occurrences, and so forth

19
00:01:24,990 --> 00:01:24,800
because that's our going to be doing.

20
00:01:24,820 --> 00:01:28,160
And of course, all the stuff will be on the final.

21
00:01:28,240 --> 00:01:31,480
So let's start with matrix multiplication.

22
00:01:38,290 --> 00:01:40,020
And we'll do n by n.

23
00:01:40,050 --> 00:01:47,980
So, our problem is to do C equals A times B.

24
00:01:48,020 --> 00:01:49,780
And the way we'll do that

25
00:01:49,800 --> 00:01:55,190
is using divide and conquer, as we saw before,

26
00:01:55,210 --> 00:01:59,600
although we're not going to use Strassen's method.

27
00:01:59,620 --> 00:02:03,040
OK, we'll just use the ordinary thing,

28
00:02:03,070 --> 00:02:06,460
and I'll leave Strassen's as an exercise.

29
00:02:06,480 --> 00:02:11,300
So, the idea is we're going to look at

30
00:02:11,320 --> 00:02:15,560
matrix multiplication in terms of an n by n matrix,

31
00:02:15,580 --> 00:02:17,650
in terms of n over 2 by n over 2 matrices.

32
00:02:17,680 --> 00:02:21,500
So, I partition C into four blocks,

33
00:02:26,060 --> 00:02:27,610
and likewise with A and B.

34
00:02:47,990 --> 00:02:51,140
OK, and we multiply those out,

35
00:02:51,160 --> 00:02:56,540
and that gives us the following.

36
00:03:00,440 --> 00:03:02,290
Make sure I get all my indices right.

37
00:03:37,230 --> 00:03:42,020
OK, so it gives us the sum of these two n by n matrices.

38
00:03:42,050 --> 00:03:45,290
OK, so for example,

39
00:03:45,330 --> 00:03:48,480
if I multiply the first row by the first column,

40
00:03:48,500 --> 00:03:50,150
I'm putting the first term,

41
00:03:50,170 --> 00:03:54,550
A_11 times B_11 in this matrix, in the second one,

42
00:03:54,570 --> 00:04:00,630
A_12 times B_21 gets placed here.

43
00:04:00,650 --> 00:04:03,000
So, when I sum them, and so forth,

44
00:04:03,020 --> 00:04:04,950
for the other entries, and when I sum them,

45
00:04:04,970 --> 00:04:07,650
I'm going to get my result.

46
00:04:07,680 --> 00:04:11,230
So, we can write that out as a,

47
00:04:11,260 --> 00:04:18,350
let's see, I'm not sure

48
00:04:18,370 --> 00:04:21,570
this is going to all fit on one board,

49
00:04:21,600 --> 00:04:22,750
but we'll see we can do.

50
00:04:22,780 --> 00:04:26,580
OK, so we can write that out as a multithreaded program.

51
00:04:26,610 --> 00:04:32,700
So this, we're going to assume that

52
00:04:32,720 --> 00:04:40,190
n is an exact power of two for simplicity.

53
00:04:41,880 --> 00:04:46,960
Since we're going to have two matrices that we have to add

54
00:04:47,030 --> 00:04:52,930
we're going to basically put one of them in our output, C;

55
00:04:52,950 --> 00:04:54,270
that'll be the first one,

56
00:04:54,280 --> 00:05:02,670
and we're going to use a temporary matrix, T,

57
00:05:02,700 --> 00:05:04,990
which is also n by n.

58
00:05:10,650 --> 00:05:13,430
OK, and the code looks something like this,

59
00:05:13,450 --> 00:05:27,740
OK, n equals one, and C of one gets A of 1-1

60
00:05:27,760 --> 00:05:33,820
times B of 1-1.

61
00:05:33,850 --> 00:05:45,890
Otherwise, what we do then is we partition the matrices.

62
00:05:45,910 --> 00:05:51,670
OK, so we partition them into the block.

63
00:05:51,680 --> 00:05:56,820
So, how long does it take me to partition at matrix into blocks

64
00:05:56,840 --> 00:05:59,640
if I'm clever at my programming?

65
00:06:03,400 --> 00:06:08,830
Yeah? No time, or it actually does

66
00:06:08,860 --> 00:06:11,810
take a little bit of time. Yeah, order one,

67
00:06:11,830 --> 00:06:14,400
basically, OK, because all it is

68
00:06:14,410 --> 00:06:15,870
is just index calculations.

69
00:06:15,890 --> 00:06:17,680
You have to change what the index is.

70
00:06:17,710 --> 00:06:20,910
You have to pass in when you're passing these

71
00:06:20,940 --> 00:06:23,170
in addition to A, B, and C for example,

72
00:06:23,200 --> 00:06:25,190
pass and arrange which would

73
00:06:25,200 --> 00:06:26,770
have essentially a constant overhead.

74
00:06:26,780 --> 00:06:28,700
But it's basically order one time.

75
00:06:28,720 --> 00:06:35,590
Basically order one time,

76
00:06:35,610 --> 00:06:38,310
OK, to partition the matrices

77
00:06:38,330 --> 00:06:39,940
because all we are doing is index calculations.

78
00:06:39,960 --> 00:06:43,160
And all we have to do is just as we go through,

79
00:06:43,170 --> 00:06:44,890
is just make sure we keep track of the indices,

80
00:06:44,910 --> 00:06:48,770
OK? Any questions about that?

81
00:06:48,800 --> 00:06:54,730
People follow? OK, that's sort of standard programming.

82
00:06:54,750 --> 00:07:07,700
So then, what I do is I spawn multiplication of,

83
00:07:07,720 --> 00:07:20,700
woops, the sub-matrices, and spawn——

84
00:07:34,740 --> 00:07:38,830
——and continue, C_2-1, it's A_2-1,

85
00:07:38,860 --> 00:07:51,850
B_1-1, n over two, and let's see, 2-2, yeah, it's 2-1.

86
00:07:51,870 --> 00:07:57,880
OK, and continuing onto the next page.

87
00:07:57,900 --> 00:08:02,990
Let me just make sure I somehow get the indentation right.

88
00:08:03,010 --> 00:08:06,830
This is my level of indentation,

89
00:08:06,850 --> 00:08:08,700
and I'm continuing right along.

90
00:08:17,200 --> 00:08:32,780
And now what I do is put the results in T, and then

91
00:08:55,640 --> 00:09:00,410
OK, so I've spawn off all these multiplications.

92
00:09:00,430 --> 00:09:01,870
So that means when I spawn,

93
00:09:01,890 --> 00:09:04,300
I get to, after I spawn something

94
00:09:04,330 --> 00:09:06,160
I can go onto the next statement,

95
00:09:06,180 --> 00:09:09,490
and execute that even as this is executing.

96
00:09:09,510 --> 00:09:13,160
OK, so that's our notion of multithreaded programming.

97
00:09:13,190 --> 00:09:15,570
I spawn off these eight things.

98
00:09:15,600 --> 00:09:22,640
What do I do next? What's the next step in this code?

99
00:09:22,660 --> 00:09:25,920
Sync.

100
00:09:25,940 --> 00:09:28,490
Yeah. OK, I've got to wait for them to be done

101
00:09:28,520 --> 00:09:29,900
before I can use their results.

102
00:09:29,930 --> 00:09:37,150
OK, so I put a sync in, say wait for all those things

103
00:09:37,170 --> 00:09:40,020
I spawned off to be done, and then what?

104
00:09:40,070 --> 00:09:48,070
Yeah. That you have to add T and C.

105
00:09:48,080 --> 00:09:57,240
So let's do that with a subroutine call.

106
00:09:57,240 --> 00:09:59,460
OK, and then we are done. We do a return at the end.

107
00:09:59,480 --> 00:10:06,180
OK, so let's write the code for add, because add,

108
00:10:06,210 --> 00:10:10,500
we also would like to do in parallel if we can.

109
00:10:10,530 --> 00:10:20,350
And what we are doing here is doing C gets C plus T,

110
00:10:20,380 --> 00:10:27,160
OK? So, we're going to add T into C.

111
00:10:27,190 --> 00:10:31,200
So, we have some code here to do our base case,

112
00:10:31,210 --> 00:10:38,870
and partitioning because we're going to

113
00:10:38,890 --> 00:10:40,970
do it divide and conquer as before.

114
00:10:40,990 --> 00:10:43,050
And this one's actually a lot easier.

115
00:10:43,070 --> 00:10:49,430
We just spawn, add a C_1-1,

116
00:10:49,450 --> 00:10:56,300
T_1-1, n over 2, C_1-2, T_1-2,

117
00:10:56,320 --> 00:11:03,590
n over 2, C_2-1, T_2-1, n over 2,

118
00:11:03,610 --> 00:11:11,470
C_2-2, 2-2-2, n over 2, and then sync,

119
00:11:13,540 --> 00:11:21,710
and return the result. OK, so all we're doing here is

120
00:11:21,730 --> 00:11:24,920
just dividing it into four pieces, spawning them off.

121
00:11:24,940 --> 00:11:28,500
That's it. OK, wait until they're all done,

122
00:11:28,520 --> 00:11:29,840
then we return with the result.

123
00:11:29,860 --> 00:11:38,270
OK, so any questions about how this code works?

124
00:11:38,300 --> 00:11:40,160
So, remember that here,

125
00:11:40,180 --> 00:11:41,820
we're going to have a scheduler underneath

126
00:11:41,840 --> 00:11:43,510
which is scheduling this onto our processors.

127
00:11:43,540 --> 00:11:46,220
And we're going to have to worry about

128
00:11:46,240 --> 00:11:47,890
how well that scheduler is doing.

129
00:11:47,910 --> 00:11:50,280
And, from last time,

130
00:11:50,300 --> 00:11:52,920
we learned that there were two important measures,

131
00:11:52,940 --> 00:11:57,830
OK, that can be used essentially

132
00:11:57,850 --> 00:12:00,930
to predict the performance on any number of processors.

133
00:12:00,950 --> 00:12:03,140
And what are those two measures?

134
00:12:06,710 --> 00:12:09,540
Yeah, T_1 and T infinity so that we had some names.

135
00:12:09,560 --> 00:12:13,780
T_1 is the work,

136
00:12:13,800 --> 00:12:19,560
good, and T infinity is critical path length, good.

137
00:12:19,600 --> 00:12:22,650
So, you have to work in the critical path length.

138
00:12:22,680 --> 00:12:24,630
If we know the work in the critical path length,

139
00:12:24,650 --> 00:12:27,190
we can do things like say

140
00:12:27,220 --> 00:12:34,290
what the parallelism is of our program,

141
00:12:34,310 --> 00:12:36,490
and from that, understand how many processors

142
00:12:36,520 --> 00:12:38,310
it makes sense to run this program on.

143
00:12:38,330 --> 00:12:42,730
OK, so let's do that analysis.

144
00:12:46,720 --> 00:12:52,510
OK, so let's let M_P of n

145
00:12:52,530 --> 00:13:03,250
be the p processor execution time for our mult code,

146
00:13:03,270 --> 00:13:09,710
and A_P of n be the same thing

147
00:13:09,740 --> 00:13:13,310
for our matrix addition code.

148
00:13:13,330 --> 00:13:17,880
So, the first thing we're going to analyze is work.

149
00:13:17,900 --> 00:13:20,670
And, what do we hope our answer to our work is?

150
00:13:24,170 --> 00:13:29,760
When we analyze work, what do we hope it's going to be?

151
00:13:36,970 --> 00:13:38,710
Well, we hope it's going to be small.

152
00:13:38,740 --> 00:13:44,570
I'll grant you that. What could we benchmark it against?

153
00:13:48,660 --> 00:13:51,050
Yeah, if we wrote just something

154
00:13:51,070 --> 00:13:52,590
that didn't use and have any parallelism.

155
00:13:52,610 --> 00:13:56,900
We'd like our parallel code when run on one processor

156
00:13:56,970 --> 00:14:01,640
to be just as fast as our serial code,

157
00:14:01,710 --> 00:14:03,020
the normal code that we would write to do this problem.

158
00:14:04,560 --> 00:14:06,680
That's generally the way that

159
00:14:06,700 --> 00:14:09,640
we would like these things to operate, OK?

160
00:14:09,670 --> 00:14:17,010
So, what is that for matrix multiplication in the naive way?

161
00:14:17,080 --> 00:14:19,660
Yeah, it's n^3. Of course, we use Strassen's algorithm,

162
00:14:19,680 --> 00:14:24,830
or one of the other, faster algorithms that beat n^3.

163
00:14:24,870 --> 00:14:26,550
But, for this problem,

164
00:14:26,570 --> 00:14:28,870
we are just going to focus on n^3.

165
00:14:28,890 --> 00:14:31,830
I'm going to let you do the Strassen as an exercise.

166
00:14:31,860 --> 00:14:33,250
So, let's analyze the work.

167
00:14:33,270 --> 00:14:37,220
OK, since we have a subroutine for add

168
00:14:37,240 --> 00:14:41,500
that we are using in the multiply code,

169
00:14:41,520 --> 00:14:45,430
OK, we start by analyzing the add.

170
00:14:45,450 --> 00:14:49,950
So, we have A_1 of n, OK, is,

171
00:14:49,970 --> 00:14:54,770
well, can somebody give me a recurrence here?

172
00:14:54,790 --> 00:14:58,570
What's the recurrence for understanding

173
00:14:58,590 --> 00:15:00,430
the running time of this code?

174
00:15:08,820 --> 00:15:12,430
OK, this is basically week two.

175
00:15:12,460 --> 00:15:14,580
This is lecture one actually.

176
00:15:14,600 --> 00:15:18,440
This is like lecture two or, at worst, lecture three.

177
00:15:20,700 --> 00:15:23,670
Well, A of 1 of n.

178
00:15:32,720 --> 00:15:34,210
Plus order one, right.

179
00:15:34,230 --> 00:15:41,680
OK, that's right. So, we have four problems

180
00:15:41,700 --> 00:15:43,550
of size n over 2 that we are solving.

181
00:15:43,570 --> 00:15:48,120
OK, so to see this, you don't even have to know that

182
00:15:48,140 --> 00:15:49,320
we are doing this in parallel,

183
00:15:49,340 --> 00:15:52,110
because the work is basically what would happen

184
00:15:52,130 --> 00:15:56,520
if it executed on a serial machine.

185
00:15:56,540 --> 00:15:59,120
So, we have four problems of size n over 2

186
00:15:59,160 --> 00:16:01,310
plus order one is the total work.

187
00:16:01,330 --> 00:16:03,140
Any questions about how I got that recurrence?

188
00:16:03,160 --> 00:16:06,970
Is that pretty straightforward?

189
00:16:06,990 --> 00:16:09,190
If not, let me know.

190
00:16:09,220 --> 00:16:12,160
OK, and so, what's the solution to this recurrence?

191
00:16:12,180 --> 00:16:16,910
Yeah, order n^2.

192
00:16:16,930 --> 00:16:21,390
How do we know that? Yeah, master method,

193
00:16:21,410 --> 00:16:26,650
so n to the log base two of four, right, is n^2.

194
00:16:26,670 --> 00:16:30,190
Compare that with order one.

195
00:16:30,210 --> 00:16:32,660
This dramatically dominates.

196
00:16:32,690 --> 00:16:34,570
So this is the answer,

197
00:16:34,590 --> 00:16:37,890
the n to the log base two of four, n^2.

198
00:16:37,920 --> 00:16:39,850
OK, everybody remember that?

199
00:16:39,870 --> 00:16:41,120
OK, so I want people to bone up

200
00:16:41,140 --> 00:16:43,890
because this is going to be recurrences,

201
00:16:43,910 --> 00:16:45,090
and divide and conquer and stuff

202
00:16:45,110 --> 00:16:46,500
is going to be on the final,

203
00:16:46,520 --> 00:16:50,190
OK, even though we haven't seen it in many moons.

204
00:16:50,220 --> 00:16:52,500
OK, so that's good.

205
00:16:52,530 --> 00:16:53,740
That's the same as the serial.

206
00:16:53,760 --> 00:16:55,510
If I had to add two n by n matrices,

207
00:16:55,530 --> 00:16:58,780
how long does it take me to do it? n^2 time.

208
00:16:58,810 --> 00:17:00,640
OK, so the input is size n^2.

209
00:17:00,660 --> 00:17:03,690
So, you're not going to beat the size of the input

210
00:17:03,710 --> 00:17:07,920
if you have to look at every piece of the input.

211
00:17:07,940 --> 00:17:18,130
OK, let's now do the work of the matrix multiplication.

212
00:17:18,150 --> 00:17:21,040
So once again, we want to get a recurrence here.

213
00:17:28,840 --> 00:17:31,560
So, what's our recurrence here?

214
00:17:35,070 --> 00:17:43,280
Yeah? Not quite.

215
00:17:43,310 --> 00:17:48,080
Eight, right, good.

216
00:17:48,110 --> 00:17:53,080
OK, eight, M1, n over 2, plus,

217
00:17:57,670 --> 00:18:01,960
yeah, there's theta n^2 for the addition,

218
00:18:02,000 --> 00:18:04,580
and then there's extra theta one

219
00:18:04,600 --> 00:18:08,710
that we can absorb into theta n^2.

220
00:18:08,730 --> 00:18:15,170
Isn't asymptotics great? OK, it's just great.

221
00:18:15,190 --> 00:18:19,340
And so, what's the solution to that one?

222
00:18:26,310 --> 00:18:29,940
Theta n^3, why is that?

223
00:18:29,960 --> 00:18:34,760
Man, we are exercising old muscles. Aren't we?

224
00:18:34,770 --> 00:18:36,650
And they're just creaking. I can hear them.

225
00:18:36,680 --> 00:18:38,610
Why is that?

226
00:18:38,630 --> 00:18:41,350
Yeah, master method because we're looking at,

227
00:18:41,370 --> 00:18:42,430
what are we comparing?

228
00:18:42,470 --> 00:18:46,690
Yeah, n to the log base two of eight, or n^3 versus n^2,

229
00:18:46,710 --> 00:18:49,290
this one dominates order n^3.

230
00:18:49,310 --> 00:18:52,640
OK, so this is same as serial.

231
00:18:52,660 --> 00:18:54,130
This was the same as serial.

232
00:18:54,150 --> 00:18:55,400
This was the same as serial.

233
00:18:55,420 --> 00:18:57,380
That's good. OK, we know

234
00:18:57,400 --> 00:18:59,960
we have a program that on one processor,

235
00:18:59,980 --> 00:19:05,380
will execute the same as our serial code

236
00:19:05,400 --> 00:19:08,800
on which it's based.

237
00:19:08,820 --> 00:19:10,990
Namely, we could have done this.

238
00:19:11,010 --> 00:19:13,840
If I had just got rid of all the spawns and syncs,

239
00:19:13,860 --> 00:19:15,980
that would have just been

240
00:19:16,010 --> 00:19:18,690
a perfectly good piece of pseudocode

241
00:19:18,710 --> 00:19:22,500
describing the runtime of the algorithm,

242
00:19:22,530 --> 00:19:24,960
describing the serial algorithm.

243
00:19:24,980 --> 00:19:29,760
And its run time ends up being exactly the same,

244
00:19:29,790 --> 00:19:31,680
not too surprising. OK?

245
00:19:31,710 --> 00:19:37,890
OK, so now we do the new stuff, critical path length.

246
00:19:45,570 --> 00:19:49,120
OK, so here we have A infinity of n.

247
00:19:52,420 --> 00:19:56,050
Ooh, OK, so we're going to add up

248
00:19:56,110 --> 00:19:58,640
the critical path of this code here.

249
00:19:58,670 --> 00:20:02,800
Hmm, how do I figure out

250
00:20:02,820 --> 00:20:06,450
the critical path on a piece of code like that?

251
00:20:23,630 --> 00:20:26,630
So, it's going to expand into one of those DAG's.

252
00:20:26,650 --> 00:20:29,310
What's the DAG going to look like?

253
00:20:29,330 --> 00:20:31,610
How do I reason?

254
00:20:31,640 --> 00:20:33,500
So, it's actually easier not to think about the DAG,

255
00:20:33,520 --> 00:20:37,350
but to simply think about what's going on in the code.

256
00:20:37,370 --> 00:20:39,160
Yeah?

257
00:20:43,280 --> 00:20:44,800
Yeah, so it's basically,

258
00:20:44,820 --> 00:20:50,110
since all four spawns are spawning off the same thing,

259
00:20:50,130 --> 00:20:53,460
and they're operating in parallel,

260
00:20:53,480 --> 00:20:56,480
I could just look at one.

261
00:20:56,520 --> 00:20:59,460
Or in general, if I spawned off several things,

262
00:20:59,480 --> 00:21:00,940
I look at which everyone is going to

263
00:21:00,960 --> 00:21:03,530
have the maximum critical path

264
00:21:03,550 --> 00:21:08,010
for the things that I've spawned off.

265
00:21:08,030 --> 00:21:09,730
So, when we do work,

266
00:21:09,750 --> 00:21:15,150
we're usually doing plus when I have multiple subroutines.

267
00:21:15,160 --> 00:21:18,940
When we do critical path, I'm doing max.

268
00:21:18,960 --> 00:21:20,790
It's going to be the max

269
00:21:20,810 --> 00:21:23,820
over the critical paths of the subroutines that I call.

270
00:21:23,840 --> 00:21:26,260
OK, and here they are all equal.

271
00:21:26,280 --> 00:21:28,240
So what's the recurrence that I get?

272
00:21:40,140 --> 00:21:42,670
What's the recurrence I'm going to get out of this one?

273
00:21:45,300 --> 00:21:52,990
Yeah, A infinity, n over 2, plus constant,

274
00:21:54,830 --> 00:21:56,530
OK, because this is

275
00:21:56,560 --> 00:21:58,760
what the worst is of any of those four

276
00:21:58,780 --> 00:22:00,540
because they're all the same.

277
00:22:00,560 --> 00:22:02,170
They're all a problem looking at

278
00:22:02,200 --> 00:22:08,570
the critical path of something that's half the size,

279
00:22:08,590 --> 00:22:11,610
for a problem that's half the size.

280
00:22:11,640 --> 00:22:17,670
OK, people with me? OK, so what's the solution to this?

281
00:22:21,270 --> 00:22:22,510
Yeah, that's theta log n.

282
00:22:22,530 --> 00:22:28,420
That's just, once again, master theorem, case two,

283
00:22:28,460 --> 00:22:31,470
because the solution to this

284
00:22:31,490 --> 00:22:35,170
is n to the log base two of one,

285
00:22:35,190 --> 00:22:43,010
which is n to the zero. So we have, on this side,

286
00:22:43,030 --> 00:22:45,280
we have one, and here, we're comparing it with one.

287
00:22:45,310 --> 00:22:46,620
They're the same,

288
00:22:46,640 --> 00:22:49,910
so therefore we tack on that extra log n.

289
00:22:49,930 --> 00:22:53,860
OK, so tack on one log n.

290
00:22:53,880 --> 00:22:56,930
OK, so case two of the master method.

291
00:22:56,950 --> 00:22:59,450
Pretty good.

292
00:22:59,470 --> 00:23:02,050
OK, so that's pretty good,

293
00:23:02,080 --> 00:23:04,160
because the critical path is pretty short,

294
00:23:04,180 --> 00:23:05,960
log n compared to the work, n^2.

295
00:23:05,980 --> 00:23:10,380
So, let's do, then,

296
00:23:10,400 --> 00:23:15,040
this one which is a little bit more interesting,

297
00:23:15,060 --> 00:23:19,200
but not much harder. How about this one?

298
00:23:19,220 --> 00:23:23,020
What's the recurrence going to be?

299
00:23:23,040 --> 00:23:29,830
Critical path of the multiplication?

300
00:23:35,140 --> 00:23:37,590
So once again, it's going to be

301
00:23:37,610 --> 00:23:40,200
the maximum of everything we spawned off in parallel,

302
00:23:40,210 --> 00:23:44,650
which is, by symmetry, the same as one of them.

303
00:23:44,670 --> 00:23:51,430
So what do I get here? M infinity, n over 2,

304
00:23:51,450 --> 00:23:57,540
plus theta log n. Where'd the theta log n come from?

305
00:23:57,560 --> 00:24:00,280
Yeah, from the addition.

306
00:24:00,300 --> 00:24:04,490
That's the critical path of the addition.

307
00:24:04,510 --> 00:24:11,670
Now, why isn't that the maximum of that with all the spawns?

308
00:24:12,160 --> 00:24:13,930
You said that when you spawn things off,

309
00:24:13,950 --> 00:24:14,990
you're going to do them,

310
00:24:15,010 --> 00:24:20,260
yeah, you sync first.

311
00:24:20,300 --> 00:24:24,240
And, sync says you wait for all those to be done.

312
00:24:24,260 --> 00:24:25,600
So, you're only taking the maximum,

313
00:24:25,620 --> 00:24:28,220
and across syncs you're adding.

314
00:24:28,240 --> 00:24:30,750
So, you add across syncs,

315
00:24:30,770 --> 00:24:34,000
and across things that you spawned off in parallel.

316
00:24:34,020 --> 00:24:35,750
That's where you are doing the max.

317
00:24:35,770 --> 00:24:38,450
OK, but if you have a sync,

318
00:24:38,470 --> 00:24:40,540
it says that that's the end.

319
00:24:40,560 --> 00:24:41,970
You've got to wait for everything there to end.

320
00:24:41,990 --> 00:24:43,560
This isn't going on in parallel with it.

321
00:24:43,580 --> 00:24:45,220
This is going on after it.

322
00:24:45,240 --> 00:24:46,970
So, whatever the critical path is here,

323
00:24:46,990 --> 00:24:50,670
OK, if I have an infinite number of processors,

324
00:24:50,690 --> 00:24:52,740
I'd still have to wait up at this point,

325
00:24:52,770 --> 00:24:55,060
and that would therefore make it so that

326
00:24:55,130 --> 00:25:00,420
the remaining execution here was...

327
00:25:00,530 --> 00:25:01,620
I would have to add whatever

328
00:25:01,640 --> 00:25:03,370
the critical path was to this one.

329
00:25:03,390 --> 00:25:04,800
Is that clear to everybody?

330
00:25:04,820 --> 00:25:08,670
OK, so we get this recurrence.

331
00:25:08,680 --> 00:25:11,480
And, that has solution what?

332
00:25:11,500 --> 00:25:23,860
Yeah, theta log squared n. OK, once again,

333
00:25:23,870 --> 00:25:28,490
by master method, case two,

334
00:25:28,560 --> 00:25:31,050
where this ends up being a constant versus log n,

335
00:25:31,080 --> 00:25:35,740
those don't differ by a polynomial amount,

336
00:25:35,760 --> 00:25:38,420
or equal to a log factor.

337
00:25:38,440 --> 00:25:40,820
What we do in that circumstance

338
00:25:40,840 --> 00:25:42,480
is tack on an extra log factor.

339
00:25:42,520 --> 00:25:46,530
OK, so as I say, good idea to review the master method.

340
00:25:46,550 --> 00:25:49,580
OK, that's great.

341
00:25:49,600 --> 00:26:01,690
So now, let's take a look at the parallelism that we get.

342
00:26:01,710 --> 00:26:11,920
We'll just do it right here for the multiplication.

343
00:26:11,940 --> 00:26:19,220
OK, so parallelism is what for the multiplication?

344
00:26:19,240 --> 00:26:20,900
What's the formula for parallelism?

345
00:26:20,910 --> 00:26:31,520
So, we have p bar is the notation we use for this problem.

346
00:26:35,940 --> 00:26:38,610
What's the parallelism going to be?

347
00:26:38,630 --> 00:26:39,750
What's the ratio I take?

348
00:26:39,790 --> 00:26:49,800
Yeah, it's M_1 of n divided by M infinity of n.

349
00:26:49,820 --> 00:26:54,840
OK, and that's equal to, that's n^3.

350
00:26:54,860 --> 00:27:03,470
That's n^2, or log n^2, sorry, log squared n.

351
00:27:03,490 --> 00:27:09,190
OK, so this is the parallelism.

352
00:27:09,210 --> 00:27:12,610
That says you could run up to this many processors

353
00:27:12,630 --> 00:27:14,600
and expect to be getting linear speed up.

354
00:27:14,620 --> 00:27:18,250
If I ran with more processors than the parallelism,

355
00:27:18,270 --> 00:27:21,100
I don't expect to be getting linear speed up anymore,

356
00:27:21,120 --> 00:27:25,320
OK, because I'll hit the bound what I expect to run in,

357
00:27:25,340 --> 00:27:27,790
is just time proportional to critical path length,

358
00:27:27,800 --> 00:27:29,770
and throwing more processors at the problem

359
00:27:29,790 --> 00:27:31,710
is not going to help me very much,

360
00:27:31,730 --> 00:27:35,290
OK? So let's just look at this

361
00:27:35,310 --> 00:27:37,330
just to get a sense of what's going on here.

362
00:27:37,360 --> 00:27:40,830
Let's imagine that the constants are irrelevant,

363
00:27:40,860 --> 00:27:43,500
and we have, say, thousand by thousand matrices,

364
00:27:43,520 --> 00:27:49,160
OK, so in that case,

365
00:27:49,190 --> 00:28:06,010
our parallelism is 1,000^3 divided by log of 1,000^2.

366
00:28:06,030 --> 00:28:13,140
What's log of 1,000? Ten, approximately,

367
00:28:13,160 --> 00:28:16,010
right? Log base two of 1,000 is about ten,

368
00:28:16,030 --> 00:28:21,420
so that's 10^2. So, you have about 10^7 parallelism.

369
00:28:21,440 --> 00:28:22,960
How big is 10^7?

370
00:28:22,980 --> 00:28:25,780
Ten million processors.

371
00:28:25,800 --> 00:28:32,000
OK, so who knows of a machine with ten million processors?

372
00:28:32,020 --> 00:28:36,390
What's the most number of processors anybody knows about?

373
00:28:40,390 --> 00:28:41,900
Yeah, not quite,

374
00:28:41,920 --> 00:28:46,650
the IBM Blue Jean has a humungous number of processors,

375
00:28:46,670 --> 00:28:51,640
exceeding 10,000. Yeah.

376
00:28:51,660 --> 00:28:55,090
Those were one bit processors.

377
00:28:55,110 --> 00:29:02,170
OK, so this is actually a pretty big number,

378
00:29:02,190 --> 00:29:15,550
and so, our parallelism is much bigger than a typical,

379
00:29:15,570 --> 00:29:19,200
actual number of processors.

380
00:29:19,220 --> 00:29:22,580
So, we would expect to be able to

381
00:29:22,600 --> 00:29:24,410
run this and get very good performance,

382
00:29:24,430 --> 00:29:29,890
OK, because we're never going to be

383
00:29:29,910 --> 00:29:32,970
limited in this algorithm by performance.

384
00:29:33,000 --> 00:29:34,960
However, there are some tricks we can do.

385
00:29:34,980 --> 00:29:37,180
One of the things in this code is that

386
00:29:37,190 --> 00:29:40,040
we actually have some overhead

387
00:29:40,060 --> 00:29:42,070
that's not apparent

388
00:29:42,090 --> 00:29:44,300
because I haven't run this code with you,

389
00:29:44,320 --> 00:29:45,410
although I could,

390
00:29:45,430 --> 00:29:50,560
which is that we have this temporary matrix, T,

391
00:29:50,570 --> 00:29:56,430
and if you look at the execution stack,

392
00:29:56,450 --> 00:30:00,160
we're always allocating T and getting rid of it, etc.

393
00:30:00,190 --> 00:30:01,220
And, one of the things

394
00:30:01,240 --> 00:30:04,320
when you actually look at the performance of real code,

395
00:30:04,340 --> 00:30:06,510
which is now that you have your algorithmic background,

396
00:30:06,540 --> 00:30:09,120
you're ready to go and do that with some insight.

397
00:30:09,140 --> 00:30:11,040
Of course, you're interested in

398
00:30:11,060 --> 00:30:15,870
getting more than just asymptotic behavior.

399
00:30:15,890 --> 00:30:17,000
You're interested in

400
00:30:17,020 --> 00:30:19,930
getting real performance behavior on real things.

401
00:30:19,950 --> 00:30:22,170
So, you do care about constants in that nature.

402
00:30:22,190 --> 00:30:23,770
OK, and one of the things

403
00:30:23,790 --> 00:30:26,060
is having a large, temporary variable.

404
00:30:26,080 --> 00:30:28,500
That turns out to be a lot of overhead.

405
00:30:28,530 --> 00:30:30,920
And, in fact, it's often the case

406
00:30:30,940 --> 00:30:32,770
when you're looking at real code that

407
00:30:32,790 --> 00:30:34,110
if you can optimize for space,

408
00:30:34,130 --> 00:30:36,520
you also optimized for time.

409
00:30:36,550 --> 00:30:38,310
If you can run your code with smaller space,

410
00:30:38,330 --> 00:30:42,690
you can actually run it with smaller time,

411
00:30:42,700 --> 00:30:45,490
tends to be a constant factor advantage.

412
00:30:45,510 --> 00:30:47,620
But, those constants can add up,

413
00:30:47,640 --> 00:30:50,300
and can make a difference in

414
00:30:50,320 --> 00:30:52,090
whether somebody else's code is faster

415
00:30:52,110 --> 00:30:53,410
or your code is faster,

416
00:30:53,430 --> 00:30:55,530
once you have your basic algorithm.

417
00:30:55,540 --> 00:30:58,590
So, the idea is to, in this case,

418
00:30:58,610 --> 00:31:02,060
we're going to get rid of it by trading parallelism

419
00:31:02,090 --> 00:31:05,180
because we've got

420
00:31:05,200 --> 00:31:09,110
oodles of parallelism here for space efficiency.

421
00:31:14,110 --> 00:31:17,120
OK, and the idea is we're going to get rid of T.

422
00:31:21,870 --> 00:31:26,050
OK, so let's throw this up.

423
00:31:32,160 --> 00:31:35,070
So, who can suggest how I might get rid of T here,

424
00:31:42,980 --> 00:31:44,680
get rid of this temporary matrix?

425
00:31:57,330 --> 00:31:58,580
Yeah?

426
00:32:11,660 --> 00:32:14,640
So, if you just did adding it into C?

427
00:32:14,680 --> 00:32:16,390
So, the issue that you get there

428
00:32:16,420 --> 00:32:17,610
if they're both adding into C

429
00:32:17,630 --> 00:32:21,630
is you get interference between the two subcomputations.

430
00:32:21,640 --> 00:32:23,960
Now, there are ways of doing that that work out,

431
00:32:23,980 --> 00:32:25,460
but you now have to worry about

432
00:32:25,480 --> 00:32:26,650
things we're not going to talk about

433
00:32:26,670 --> 00:32:28,020
such as mutual exclusion

434
00:32:28,030 --> 00:32:29,930
to make sure that as you're updating it,

435
00:32:29,950 --> 00:32:31,030
somebody else isn't updating it,

436
00:32:31,050 --> 00:32:32,440
and you don't have race conditions.

437
00:32:32,470 --> 00:32:34,260
But you can actually do it

438
00:32:34,280 --> 00:32:35,830
in this context with no race conditions.

439
00:32:40,730 --> 00:32:44,660
Yeah, exactly. Exactly, OK, exactly.

440
00:32:44,680 --> 00:32:49,190
So, the idea is spawn off four of them.

441
00:32:49,210 --> 00:32:52,930
OK, they all update their copy of C,

442
00:32:52,950 --> 00:32:57,290
and then spawn off the other four that add their values in.

443
00:32:57,310 --> 00:33:01,870
So, that is a piece of code we'll call mult add.

444
00:33:10,730 --> 00:33:16,670
And, it's actually going to do C gets C plus A times B.

445
00:33:16,700 --> 00:33:21,170
OK, so it's actually going to add it in.

446
00:33:21,190 --> 00:33:23,300
So, initially you'd have to zero out C,

447
00:33:23,320 --> 00:33:25,950
but we can do that with code very similar to

448
00:33:25,970 --> 00:33:31,320
the addition code with order n^2 work,

449
00:33:31,340 --> 00:33:33,920
and order log n critical path.

450
00:33:33,940 --> 00:33:35,560
So that's not going to be

451
00:33:35,580 --> 00:33:37,840
a big part of what we have to deal with.

452
00:33:37,860 --> 00:33:43,820
OK, so here's the code. We basically, once again,

453
00:33:43,840 --> 00:33:46,060
do the base and partition

454
00:33:48,870 --> 00:33:50,760
which I'm not going to write out the code for.

455
00:33:50,780 --> 00:34:07,210
We spawn a mult add of C1-1, A1-1, B1-1, n over 2,

456
00:34:07,230 --> 00:34:12,620
and we do a few more of those down to the fourth one.

457
00:34:23,720 --> 00:34:30,500
And then we put in a sync. And then we do the other four --

458
00:34:59,420 --> 00:35:02,270
——and then sync when we're done with that.

459
00:35:09,330 --> 00:35:13,540
OK, does everybody understand that code?

460
00:35:13,550 --> 00:35:17,450
See that it basically does the same calculation.

461
00:35:17,460 --> 00:35:19,710
We actually don't need to call add anymore,

462
00:35:19,740 --> 00:35:21,150
because we are doing that

463
00:35:21,170 --> 00:35:24,660
as part of the multiply because we're adding it in.

464
00:35:24,680 --> 00:35:25,840
But we do have to initialize.

465
00:35:25,860 --> 00:35:30,110
OK, we do have to initialize the matrix in this case.

466
00:35:30,140 --> 00:35:34,420
OK, so there is another phase.

467
00:35:34,450 --> 00:35:38,790
So, people understand the semantics of this code？

468
00:35:38,810 --> 00:35:40,260
So let's analyze it.

469
00:35:45,580 --> 00:35:51,560
OK, so what's the work of multiply, add of n?

470
00:35:58,910 --> 00:36:03,730
It's basically the same thing, right?

471
00:36:03,750 --> 00:36:09,040
It's order n^3 because the serial code

472
00:36:09,060 --> 00:36:11,260
is almost the same as the serial code up there,

473
00:36:11,280 --> 00:36:13,370
OK, not quite,

474
00:36:13,390 --> 00:36:16,590
OK, but you get essentially the same recurrence

475
00:36:16,600 --> 00:36:17,900
except you don't even have the add.

476
00:36:17,920 --> 00:36:20,450
You just get the same recurrence

477
00:36:20,480 --> 00:36:24,700
but with order one here, oops, order one up here.

478
00:36:24,720 --> 00:36:30,130
So, it's still got the order n^3 solution.

479
00:36:30,150 --> 00:36:36,740
OK, so that, I think, is not too hard.

480
00:36:36,760 --> 00:36:42,130
OK, so the critical path length, so there,

481
00:36:42,150 --> 00:36:47,200
let's write out, so multiply add of n,

482
00:36:47,230 --> 00:36:50,160
OK, what's my recurrence for this code?

483
00:37:00,690 --> 00:37:12,200
Yeah, 2M infinity, n over 2 almost that,

484
00:37:12,220 --> 00:37:16,210
so order one. Plus order one, yeah.

485
00:37:16,240 --> 00:37:20,040
OK, so the point is that

486
00:37:20,060 --> 00:37:21,840
we're going to have, for the critical path,

487
00:37:21,860 --> 00:37:24,620
we're going to spawn these four off,

488
00:37:24,640 --> 00:37:26,740
and so I take the maximum of whatever those is,

489
00:37:26,760 --> 00:37:29,440
which since they're symmetric is any one of them,

490
00:37:29,460 --> 00:37:33,470
OK, and then I have to wait.

491
00:37:33,490 --> 00:37:35,600
And then I do it again.

492
00:37:35,630 --> 00:37:37,530
So, that sync, once again,

493
00:37:37,550 --> 00:37:39,630
translates into, in the analysis,

494
00:37:39,640 --> 00:37:42,260
it translates into a plus of the critical path,

495
00:37:42,280 --> 00:37:44,960
which are the things I spawn off in parallel,

496
00:37:44,980 --> 00:37:49,270
I do the max. OK, so people see that?

497
00:37:49,290 --> 00:37:51,000
So, I get this recurrence,

498
00:37:51,020 --> 00:37:55,730
2MA of n over 2 plus order one,

499
00:37:55,750 --> 00:37:57,510
and what's the solution to that?

500
00:38:00,700 --> 00:38:01,890
OK, that's order n,

501
00:38:01,910 --> 00:38:08,850
OK, because n to the log base two of two is n,

502
00:38:08,870 --> 00:38:12,220
and that's bigger than one so we get order n.

503
00:38:16,260 --> 00:38:28,480
OK, so the parallelism, we have p bar

504
00:38:28,500 --> 00:38:38,080
is equal to MA one of n over MA infinity of n is equal to,

505
00:38:38,100 --> 00:38:43,920
in this case, n^3 over n, or order n^2.

506
00:38:43,950 --> 00:38:49,820
OK, so for 1,000 by 1,000 matrices, for example,

507
00:38:49,830 --> 00:38:54,140
by the way, 1,000 by 1,000 is considered a small matrix these days,

508
00:38:54,170 --> 00:39:00,630
because that's only one million entries.

509
00:39:00,660 --> 00:39:03,470
You can put that on your laptop no sweat.

510
00:39:03,490 --> 00:39:09,060
OK, so, but for 1,000 by 1,000 matrices,

511
00:39:09,080 --> 00:39:15,650
our parallelism is about 10^6.

512
00:39:15,670 --> 00:39:19,730
OK, so once again,

513
00:39:19,750 --> 00:39:25,060
ample parallelism for anything we would run it on today.

514
00:39:25,080 --> 00:39:28,440
And as it turns out, it's faster in practice——

515
00:39:36,740 --> 00:39:44,080
——because we have less space.

516
00:39:44,080 --> 00:39:46,510
OK, so here's a game where,

517
00:39:46,530 --> 00:39:52,320
so, often the game you'll see in theory papers

518
00:39:52,330 --> 00:39:53,680
if you look at research papers,

519
00:39:53,700 --> 00:39:56,010
people are often striving to get the most parallelism,

520
00:39:56,040 --> 00:39:59,200
and that's a good game to play,

521
00:39:59,220 --> 00:40:01,950
OK, but it's not necessarily the only game.

522
00:40:01,960 --> 00:40:03,660
Particularly, if you have a lot of parallelism,

523
00:40:03,690 --> 00:40:05,220
one of the things that's very easy to do

524
00:40:05,250 --> 00:40:06,470
is to retreat on the parallelism

525
00:40:06,490 --> 00:40:09,420
and gain other aspects that you may want in your code.

526
00:40:09,450 --> 00:40:11,820
OK, and so this is a good example of that.

527
00:40:11,840 --> 00:40:15,360
In fact, and this is an exercise,

528
00:40:15,380 --> 00:40:18,910
you can actually achieve work n^3,

529
00:40:18,940 --> 00:40:23,630
order n^3 work, and a critical path of log n,

530
00:40:23,650 --> 00:40:27,410
so even better than either of these two algorithms

531
00:40:27,430 --> 00:40:28,580
in terms of parallelism.

532
00:40:28,600 --> 00:40:33,000
OK, so that gives you n^3 over log n parallelism.

533
00:40:33,030 --> 00:40:34,040
So, that's an exercise.

534
00:40:34,060 --> 00:40:37,040
And then, the other exercise that I mention that

535
00:40:37,070 --> 00:40:38,840
that's good to do is parallel Strassen,

536
00:40:38,870 --> 00:40:42,070
OK, doing the same thing with Strassen,

537
00:40:42,090 --> 00:40:43,990
and analyze, what's the working critical path

538
00:40:44,010 --> 00:40:48,120
and parallelism of the Strassen code?

539
00:40:48,140 --> 00:40:53,050
OK, any questions about matrix multiplication?

540
00:40:53,070 --> 00:40:56,440
Yeah?

541
00:41:00,920 --> 00:41:03,090
Yeah, so that would take,

542
00:41:03,110 --> 00:41:06,070
that would add a log n to the critical path,

543
00:41:06,090 --> 00:41:08,370
which is nothing compared to the n.

544
00:41:08,400 --> 00:41:11,010
Excuse me?

545
00:41:11,030 --> 00:41:15,240
Well, you got to make sure C is zero to begin with.

546
00:41:15,260 --> 00:41:19,530
OK, so you have to set all the entries to zero,

547
00:41:19,550 --> 00:41:23,900
and so that will take you n^2 work,

548
00:41:23,930 --> 00:41:25,450
which is nothing compared to

549
00:41:25,470 --> 00:41:26,870
the n^3 work you're doing here,

550
00:41:26,880 --> 00:41:31,600
and it will cost you log n additional to the critical path,

551
00:41:31,510 --> 00:41:32,810
which is nothing compared to

552
00:41:32,840 --> 00:41:34,090
the order n that you're spending.

553
00:41:36,260 --> 00:41:40,340
Any other questions about matrix multiplication?

554
00:41:40,360 --> 00:41:47,660
OK, as I say, this all goes back to week two,

555
00:41:47,680 --> 00:41:49,030
or something, in the class.

556
00:41:49,050 --> 00:41:59,090
Did you have a comment? Yes, you can.

557
00:41:59,110 --> 00:42:01,060
OK, yes you can.

558
00:42:01,080 --> 00:42:04,580
It's actually kind of interesting to look at that.

559
00:42:04,610 --> 00:42:06,380
Actually, we'll talk later.

560
00:42:06,410 --> 00:42:09,110
We'll write a research paper after the class is over,

561
00:42:09,130 --> 00:42:11,520
OK, because there's actually

562
00:42:11,550 --> 00:42:12,930
some interesting open questions there.

563
00:42:12,950 --> 00:42:25,040
OK, let's move on to something

564
00:42:25,060 --> 00:42:28,030
that you thought you'd gotten rid of weeks ago,

565
00:42:28,050 --> 00:42:34,450
and that would be the topic of sorting.

566
00:42:34,470 --> 00:42:43,580
Back to sorting. OK, so we want to parallel sort now, OK?

567
00:42:43,610 --> 00:42:47,530
Hugely important problem.

568
00:42:47,550 --> 00:42:53,340
So, let's take a look at, so if I think about algorithms

569
00:42:53,350 --> 00:42:55,270
for sorting that sound easy to parallelize,

570
00:42:55,290 --> 00:42:57,170
which ones sound kind of easy to parallelize?

571
00:42:57,190 --> 00:43:01,130
Quick sort, yeah,

572
00:43:01,150 --> 00:43:03,640
that's a good one. Yeah, quick sort is

573
00:43:03,660 --> 00:43:05,700
a pretty good one to parallelize and analyze.

574
00:43:05,720 --> 00:43:07,080
But remember, quick sort has a little bit

575
00:43:07,100 --> 00:43:09,300
more complicated analysis than some other sorts.

576
00:43:09,320 --> 00:43:11,340
What's another one that looks like

577
00:43:11,360 --> 00:43:12,660
it should be pretty easy to parallelize?

578
00:43:12,680 --> 00:43:14,730
Merge sort.

579
00:43:14,760 --> 00:43:19,860
When did we teach merge sort? Day one.

580
00:43:19,890 --> 00:43:22,630
OK, so do merge sort

581
00:43:22,650 --> 00:43:24,360
because it's just a little bit easier to analyze.

582
00:43:24,380 --> 00:43:26,030
OK, we could do the same thing for quick sort.

583
00:43:26,060 --> 00:43:32,470
Here's merge sort,

584
00:43:32,490 --> 00:43:39,980
OK, and it's going to sort A of p to r.

585
00:43:40,010 --> 00:43:44,870
So, if p is less than r,

586
00:43:44,890 --> 00:43:51,630
then we get the middle element,

587
00:43:51,650 --> 00:44:01,340
and then we'll spawn off since we have to, as you recall,

588
00:44:01,350 --> 00:44:03,550
when you merge sort you first recursively

589
00:44:03,570 --> 00:44:05,190
sort the two sub-arrays.

590
00:44:05,210 --> 00:44:07,120
There's no reason not to do those parallel.

591
00:44:07,140 --> 00:44:08,860
Let's just do them in parallel.

592
00:44:08,890 --> 00:44:14,710
Let's spawn off, merge sort of (A,p,q),

593
00:44:14,740 --> 00:44:26,340
and spawn off, then, merge sort of (A,q+1,r),

594
00:44:26,360 --> 00:44:36,920
And then, we wait for them to be done.

595
00:44:36,950 --> 00:44:39,380
Don't forget your syncs.

596
00:44:39,400 --> 00:44:42,980
Sync or swim.

597
00:44:43,000 --> 00:44:47,580
OK, and then what to do what we are done with this?

598
00:44:47,600 --> 00:44:52,240
OK, we merge.

599
00:44:52,260 --> 00:45:00,530
OK, so we merge of A, p, q, r,

600
00:45:00,550 --> 00:45:19,790
which is merge A of p up to q with A of q plus one up to r.

601
00:45:19,810 --> 00:45:24,470
And, once we've merged, we're done.

602
00:45:24,490 --> 00:45:30,750
OK, so this is the same code as we saw before in day one

603
00:45:30,770 --> 00:45:32,910
except we've got a couple of spawns in the sync.

604
00:45:32,930 --> 00:45:54,300
So let's analyze this. So, the work is called T_1 of n,

605
00:45:54,320 --> 00:45:57,450
what's the recurrence for this?

606
00:45:57,470 --> 00:46:04,770
This really is going back to day one, right?

607
00:46:04,800 --> 00:46:07,660
We actually did this on day one.

608
00:46:07,690 --> 00:46:12,730
OK, so what's the recurrence?

609
00:46:12,760 --> 00:46:21,940
2T_1 of n over 2 plus order n

610
00:46:21,960 --> 00:46:25,950
merges order n time operation, OK?

611
00:46:25,970 --> 00:46:30,910
And so, that gives us a solution of n log n,

612
00:46:30,930 --> 00:46:33,600
OK, even if you didn't know the solution,

613
00:46:33,630 --> 00:46:34,910
you should know the answer,

614
00:46:34,930 --> 00:46:38,040
OK, which is the same as the serial code,

615
00:46:38,060 --> 00:46:40,300
not surprisingly. That's what we want.

616
00:46:40,310 --> 00:46:48,520
OK, critical path length, T infinity of n is equal to,

617
00:46:48,550 --> 00:47:05,860
OK, T infinity of n over 2 plus order n again.

618
00:47:05,880 --> 00:47:13,450
And that's equal to order n, OK?

619
00:47:13,470 --> 00:47:14,880
So, the parallelism is

620
00:47:14,920 --> 00:47:27,680
then p bar equals T_1 of n over T infinity of n

621
00:47:27,700 --> 00:47:34,860
is equal to theta of log n.

622
00:47:34,880 --> 00:47:41,430
Is that a lot of parallelism?

623
00:47:41,450 --> 00:47:46,260
No, we have a technical name for that. We call it puny.

624
00:47:46,280 --> 00:47:53,030
OK, that's puny parallelism. Log n?

625
00:47:53,070 --> 00:47:58,320
Now, so this is actually probably a decent algorithm

626
00:47:58,350 --> 00:48:02,380
for some of the small scale processors,

627
00:48:02,410 --> 00:48:04,140
especially the multicore processors

628
00:48:04,170 --> 00:48:06,560
that are coming on the market,

629
00:48:06,600 --> 00:48:11,120
and some of the smaller SMP, symmetric multiprocessors,

630
00:48:11,140 --> 00:48:12,470
that are available.

631
00:48:12,480 --> 00:48:14,450
You know, they have four or eight processors or something.

632
00:48:14,470 --> 00:48:17,040
It might be OK. There's not a lot of parallelism.

633
00:48:17,060 --> 00:48:24,330
For a million elements, log n is about 20.

634
00:48:24,350 --> 00:48:28,050
OK, and so and then there's constant overheads,etc.

635
00:48:28,070 --> 00:48:30,790
This is not very much parallelism at all.

636
00:48:30,810 --> 00:48:31,870
Question?

637
00:48:37,780 --> 00:48:47,160
Yeah, so how can we do better? I mean, it's like,

638
00:48:47,170 --> 00:48:51,370
man, at merge, right, it takes order n.

639
00:48:51,390 --> 00:48:54,520
if I want to do better, what should I do?

640
00:48:54,540 --> 00:49:01,200
Yeah? Sort in-place,

641
00:49:01,220 --> 00:49:03,830
but for example if you do quick sort and partition,

642
00:49:03,840 --> 00:49:07,130
you still have a linear time partition.

643
00:49:07,150 --> 00:49:10,750
So you're going to be very much in the same situation.

644
00:49:10,770 --> 00:49:19,480
But what can I do here? Parallel merge.

645
00:49:19,510 --> 00:49:22,990
OK, let's make merge go in parallel.

646
00:49:23,010 --> 00:49:26,060
That's where all the critical path is.

647
00:49:26,080 --> 00:49:30,920
Let's figure out a way of building a merge program

648
00:49:30,940 --> 00:49:33,820
that has a very short critical path.

649
00:49:33,870 --> 00:49:45,670
You have to parallelize the merge. This is great.

650
00:49:45,690 --> 00:49:52,570
It's so nice to see at the end of a course like this

651
00:49:52,580 --> 00:49:57,000
that people have the intuition for,

652
00:49:57,020 --> 00:49:58,570
oh, you can look at it and sort of see,

653
00:49:58,600 --> 00:50:00,390
where should you put in your work?

654
00:50:00,410 --> 00:50:02,760
OK, the one thing about algorithms is

655
00:50:02,790 --> 00:50:04,750
it doesn't stop you from

656
00:50:04,770 --> 00:50:08,420
having to engineer a program when you code it.

657
00:50:08,440 --> 00:50:10,140
There's a lot more to coding a program well

658
00:50:10,160 --> 00:50:12,410
than just having the algorithm

659
00:50:12,430 --> 00:50:14,140
as we talked about, also, in day one.

660
00:50:14,160 --> 00:50:16,570
There's things like making it modular,

661
00:50:16,590 --> 00:50:18,330
and making it maintainable,

662
00:50:18,370 --> 00:50:20,610
and a whole bunch of things like that.

663
00:50:20,630 --> 00:50:21,830
But one of the things

664
00:50:21,870 --> 00:50:23,320
that algorithms does is it tells you,

665
00:50:23,340 --> 00:50:24,480
where should you focus your work.

666
00:50:24,500 --> 00:50:27,280
OK, there's no point in,

667
00:50:27,300 --> 00:50:28,540
for example, sort of saying,

668
00:50:28,560 --> 00:50:30,850
OK, let me spawn off

669
00:50:30,870 --> 00:50:33,280
four of these things of size n over 4

670
00:50:33,300 --> 00:50:37,510
in hopes of getting, I mean, it's like,

671
00:50:37,530 --> 00:50:39,140
that's not where you put the work.

672
00:50:39,160 --> 00:50:41,380
You put the work in merge

673
00:50:41,410 --> 00:50:44,680
because that's the one that's the bottleneck, OK?

674
00:50:44,700 --> 00:50:47,120
And, that's the nice thing about algorithms is

675
00:50:47,140 --> 00:50:48,920
it very quickly lets you hone in

676
00:50:48,940 --> 00:50:50,270
on where you should put your effort,

677
00:50:50,280 --> 00:50:56,250
when you're doing algorithmic design in engineering practice

678
00:50:56,320 --> 00:50:58,070
So you must parallelize the merge.

679
00:51:07,480 --> 00:51:10,270
The merge we're taking,

680
00:51:10,290 --> 00:51:11,910
so here's the basic idea we're going to use.

681
00:51:11,940 --> 00:51:17,090
So, in general, when we merge,

682
00:51:17,120 --> 00:51:18,730
when we do our recursive merge,

683
00:51:18,760 --> 00:51:20,000
we're going to have two arrays.

684
00:51:20,030 --> 00:51:22,420
Let's call them A and B.

685
00:51:22,440 --> 00:51:24,680
I called them A there.

686
00:51:24,720 --> 00:51:25,870
I probably shouldn't have used A.

687
00:51:25,890 --> 00:51:28,200
I probably should have called them something else,

688
00:51:28,220 --> 00:51:29,420
but that's what my notes have,

689
00:51:29,450 --> 00:51:30,490
so we're going to stick to it.

690
00:51:30,530 --> 00:51:33,380
But we get a little bit more space there

691
00:51:33,410 --> 00:51:36,260
and see what's going on.

692
00:51:39,760 --> 00:51:41,880
We have two arrays. I'll call them A and B,

693
00:51:41,900 --> 00:51:48,910
OK? And, what we're going to do,

694
00:51:48,930 --> 00:51:50,130
these are going to be already sorted.

695
00:51:50,160 --> 00:51:53,930
And our job is going to be to merge them together.

696
00:51:53,950 --> 00:51:57,500
So, what I'll do is I'll take the middle element of A.

697
00:51:57,520 --> 00:52:02,650
So this, let's say, goes from one to l,

698
00:52:02,680 --> 00:52:07,200
and this goes from one to m.

699
00:52:07,230 --> 00:52:11,640
OK, I'll take the middle element,

700
00:52:11,660 --> 00:52:14,070
the element at l over 2, say,

701
00:52:14,090 --> 00:52:23,390
and what I'll do is use binary search to figure out,

702
00:52:23,400 --> 00:52:26,200
where does it go in the array B?

703
00:52:26,220 --> 00:52:28,750
Where does this element go?

704
00:52:28,770 --> 00:52:31,670
It goes to some point here

705
00:52:31,680 --> 00:52:36,490
where we have j here and j plus one here.

706
00:52:36,510 --> 00:52:41,380
So, we know, since this is sorted,

707
00:52:41,400 --> 00:52:42,740
that all these things are

708
00:52:42,760 --> 00:52:45,330
less than or equal to A of l over 2,

709
00:52:45,350 --> 00:52:48,750
and all these things are

710
00:52:48,760 --> 00:52:50,630
greater than or equal to A of l over 2.

711
00:52:52,080 --> 00:52:56,070
And similarly, since that element falls here,

712
00:52:56,090 --> 00:52:59,490
all these are less than or equal to A of l over 2.

713
00:52:59,520 --> 00:53:02,100
And all these are going to be

714
00:53:02,120 --> 00:53:04,160
less greater than or equal to two.

715
00:53:11,660 --> 00:53:14,510
OK, and so now what I can do is

716
00:53:14,530 --> 00:53:16,240
once I figured out where this goes,

717
00:53:16,260 --> 00:53:20,850
I can recursively merge this array with this one,

718
00:53:20,870 --> 00:53:24,130
and this one with this one,

719
00:53:24,150 --> 00:53:30,480
and then if I can just concatenate them altogether,

720
00:53:30,500 --> 00:53:37,400
I've got my merged array. OK, so let's write that code.

721
00:53:37,420 --> 00:53:41,960
Everybody get the gist of what's going on there,

722
00:53:41,980 --> 00:53:43,900
how we're going to parallelize the merge?

723
00:53:43,920 --> 00:53:46,070
Of course, you can see, it's going to get a little messy

724
00:53:46,090 --> 00:53:49,700
because j could be anywhere.

725
00:53:53,560 --> 00:53:56,000
heres my code, parallel merge of,

726
00:54:06,110 --> 00:54:12,320
and we're going to put it in C of one to n,

727
00:54:12,340 --> 00:54:14,630
so I'm going to have n elements.

728
00:54:14,640 --> 00:54:25,030
So, this is doing merge A and B into C,

729
00:54:25,050 --> 00:54:29,000
and n is equal to l plus m.

730
00:54:31,810 --> 00:54:34,070
OK, so we're going to take two arrays

731
00:54:34,120 --> 00:54:37,900
and merge it into the third array, OK?

732
00:54:37,920 --> 00:54:45,560
So, without loss of generality,

733
00:54:45,580 --> 00:54:49,790
I'm going to say l is bigger than m as I show here

734
00:54:49,810 --> 00:54:51,620
because if it's not, what do I do?

735
00:54:51,630 --> 00:54:54,380
Just do it the other way around, right?

736
00:54:54,400 --> 00:54:58,130
So, I figure out which one was bigger.

737
00:54:58,150 --> 00:55:00,310
So that only cost me order one to test that or whatever.

738
00:55:00,330 --> 00:55:03,200
And then, I basically do a base case,

739
00:55:03,210 --> 00:55:08,360
you know, if the two arrays are empty or whatever,

740
00:55:08,380 --> 00:55:10,480
what you do in practice, of course, is, you know

741
00:55:10,520 --> 00:55:13,670
if they're small enough, you just do a serial merge,

742
00:55:13,680 --> 00:55:16,880
OK, if they're small enough,

743
00:55:16,900 --> 00:55:18,990
and I don't really expect to get much parallelism.

744
00:55:19,020 --> 00:55:20,300
There isn't much work there.

745
00:55:20,320 --> 00:55:21,950
You might as well just do serial merge,

746
00:55:21,960 --> 00:55:24,270
and be a little bit more efficient, OK?

747
00:55:24,290 --> 00:55:25,810
So, do the base case.

748
00:55:25,830 --> 00:55:32,800
So then, what I do is I find the j

749
00:55:32,820 --> 00:55:39,240
such that B of j is less than or equal to A of l over 2,

750
00:55:39,260 --> 00:55:43,690
less than or equal to B of j plus one,

751
00:55:43,710 --> 00:55:48,820
using binary search.

752
00:55:53,850 --> 00:55:55,190
What did recover binary search?

753
00:55:55,210 --> 00:55:58,370
Oh yeah, that was week one, right?

754
00:55:58,390 --> 00:56:00,920
That was first recitation or something.

755
00:56:00,940 --> 00:56:04,030
Yeah, it's amazing.

756
00:56:04,050 --> 00:56:06,840
OK, and now, what we do is

757
00:56:06,860 --> 00:56:25,000
we spawn off p merge of A of one, l over 2, B of one to j,

758
00:56:25,030 --> 00:56:33,040
and stick it into C of one, two, l over 2 plus j.

759
00:56:38,530 --> 00:56:52,970
OK, and similarly now, we can spawn off a merge of

760
00:56:53,000 --> 00:57:10,480
A of l over 2 plus one up to l. B of j plus one up to M,

761
00:57:10,500 --> 00:57:20,160
and a C of l over two plus j plus one up to n.

762
00:57:20,170 --> 00:57:23,320
And then, I sync.

763
00:57:23,350 --> 00:57:32,290
So, code is pretty straightforward,

764
00:57:32,310 --> 00:57:35,160
doing exactly what I said we were going to do over here,

765
00:57:35,180 --> 00:57:43,130
analysis, a little messier, a little messier.

766
00:57:43,150 --> 00:57:51,180
So, let's just try to understand it

767
00:57:51,200 --> 00:57:52,490
before we do the analysis.

768
00:57:52,510 --> 00:57:57,060
Why is it that I want to pick

769
00:57:57,080 --> 00:58:03,030
the middle of the big array rather than the small array?

770
00:58:03,030 --> 00:58:09,310
What sort of my rationale there?

771
00:58:09,310 --> 00:58:11,570
That's actually a key part,

772
00:58:11,590 --> 00:58:19,530
going to be a key part of the analysis. Yeah?

773
00:58:32,480 --> 00:58:33,770
Yeah, imagine that B, for example,

774
00:58:33,790 --> 00:58:40,700
had only one element in it, or just a few elements,

775
00:58:40,770 --> 00:58:43,160
then finding it in A might mean

776
00:58:43,260 --> 00:58:46,930
finding it right near the beginning of A.

777
00:58:46,950 --> 00:58:55,040
And now, I'd be left with subproblems that were very big,

778
00:58:55,900 --> 00:58:58,000
whereas here, as you're pointing out,

779
00:58:58,020 --> 00:59:03,690
if I start here, if my total number of elements is n,

780
00:59:03,690 --> 00:59:11,050
what's the smallest that one of these recursions could be?

781
00:59:11,050 --> 00:59:13,910
N over 4 is the smallest it could be,

782
00:59:15,880 --> 00:59:22,270
because I would have at least a quarter of the total

783
00:59:22,340 --> 00:59:25,570
number of elements to the left here or to the right here

784
00:59:25,640 --> 00:59:28,260
If I do it the other way around, my recursion,

785
00:59:28,290 --> 00:59:32,110
I might get a recursion that was nearly as big as n,

786
00:59:32,130 --> 00:59:34,600
and that's sort of, once again,

787
00:59:34,620 --> 00:59:35,740
sort of like the difference

788
00:59:35,760 --> 00:59:38,460
when we were analyzing quick sort with

789
00:59:38,480 --> 00:59:43,580
whether we got a good partitioning element or not.

790
00:59:43,600 --> 00:59:46,030
The partitioning element is somewhere in the middle,

791
00:59:46,050 --> 00:59:49,150
we're really good, but it's always at one end,

792
00:59:49,170 --> 00:59:51,440
it's no better than insertion sort.

793
00:59:51,440 --> 00:59:54,140
You want to cut off at least a constant fraction

794
00:59:54,140 --> 00:59:56,400
in your divided and conquered

795
00:59:56,430 --> 00:59:57,850
in order to get the logarithmic behavior.

796
00:59:57,870 --> 01:00:01,440
OK, so we'll see that in the analysis.

797
01:00:01,460 --> 01:00:02,960
But the key thing here is that

798
01:00:02,980 --> 01:00:06,620
when we are going to do the recursion,

799
01:00:06,650 --> 01:00:09,470
we're going to have at least n over 4 elements in

800
01:00:09,490 --> 01:00:11,200
whatever the smaller thing is.

801
01:00:11,220 --> 01:00:15,800
OK, but let's start.

802
01:00:15,830 --> 01:00:17,650
It turns out the work is the hard part of this.

803
01:00:17,670 --> 01:00:19,540
Let's start with critical path length.

804
01:00:19,560 --> 01:00:24,230
OK, look at that, critical path length.

805
01:00:24,250 --> 01:00:36,590
OK, so parallel merge, so infinity of n is going to be,

806
01:00:36,610 --> 01:00:44,810
at most, so if the smaller piece has at least a quarter,

807
01:00:44,830 --> 01:00:46,340
what's the larger piece going to

808
01:00:46,360 --> 01:00:50,370
be of these two things here?

809
01:00:56,850 --> 01:00:59,780
So, we have two problems spawning off.

810
01:00:59,800 --> 01:01:02,900
Now, we really have to do max

811
01:01:02,930 --> 01:01:04,380
because they're not symmetric.

812
01:01:04,400 --> 01:01:05,760
Which one's going to be worse?

813
01:01:05,780 --> 01:01:16,180
One could have, at most, three quarters of n.

814
01:01:16,200 --> 01:01:27,560
Woops, 3n, of 3n over 4 plus,

815
01:01:27,590 --> 01:01:33,730
OK, so the worst of those two is going to be

816
01:01:33,750 --> 01:01:36,950
three quarters of the elements plus, what?

817
01:01:36,970 --> 01:01:47,280
Plus log n. What's the log n?

818
01:01:47,300 --> 01:01:54,980
The binary search. OK, and that gives me a solution of,

819
01:01:54,990 --> 01:02:09,140
this ends up being n to the, what?

820
01:02:13,930 --> 01:02:15,500
n to the zero, right.

821
01:02:15,530 --> 01:02:20,660
OK, it's n to the log base four thirds of one.

822
01:02:20,680 --> 01:02:25,080
OK, it was the log of anything of one is zero.

823
01:02:25,100 --> 01:02:26,150
So, it's n to the zero.

824
01:02:26,180 --> 01:02:27,890
So that's just one compared with log n,

825
01:02:27,910 --> 01:02:31,460
tack on, it's log squared n.

826
01:02:31,480 --> 01:02:37,370
So, we have a critical path of log squared n.

827
01:02:37,400 --> 01:02:38,420
That's good news.

828
01:02:38,440 --> 01:02:40,370
Now, let's hope that

829
01:02:40,400 --> 01:02:42,650
we didn't blow up the work by a substantial amount.

830
01:02:46,190 --> 01:02:56,060
OK, so the work is PM_1 of n is equal to, OK,

831
01:02:56,080 --> 01:02:58,890
so we don't know what the split is.

832
01:02:58,910 --> 01:03:05,420
So let's call it alpha. OK, so alpha n in one side,

833
01:03:12,000 --> 01:03:13,570
and then the work on the other side

834
01:03:13,590 --> 01:03:19,870
will be PM of one of one minus alpha n plus,

835
01:03:19,900 --> 01:03:22,420
and then still order of log n

836
01:03:22,440 --> 01:03:29,070
to the binary search where, as we've said,

837
01:03:29,100 --> 01:03:32,780
alpha is going to fall

838
01:03:32,810 --> 01:03:34,730
between one quarter and three quarters.

839
01:03:44,440 --> 01:03:46,740
OK, how do we solve a recurrence like this?

840
01:03:51,720 --> 01:03:53,800
What's the technical name for this kind of recurrence?

841
01:03:58,060 --> 01:04:02,330
Hairy. It's a hairy recurrence.

842
01:04:02,350 --> 01:04:03,630
How do we solve hairy recurrences?

843
01:04:03,660 --> 01:04:07,050
Substitution. OK, good.

844
01:04:07,070 --> 01:04:20,700
Substitution. OK, so we're going to say

845
01:04:20,730 --> 01:04:23,570
PM one of k is less than or equal to,

846
01:04:23,590 --> 01:04:28,810
OK, I want to make a good guess here,

847
01:04:28,830 --> 01:04:31,310
OK, because I've fooled around with it.

848
01:04:31,350 --> 01:04:33,110
I want it to be linear,

849
01:04:33,130 --> 01:04:36,810
so it's going to have a linear term, a times k

850
01:04:36,830 --> 01:04:39,900
minus and then I'm going to do b log k.

851
01:04:39,930 --> 01:04:41,820
So, this is this trick of subtracting a low order term.

852
01:04:41,830 --> 01:04:46,350
Remember that in substitution in order to make it stronger?

853
01:04:46,370 --> 01:04:47,850
If I just did ak it's not going to work

854
01:04:47,860 --> 01:04:49,680
because here I would get n,

855
01:04:49,700 --> 01:04:51,560
and then when I did this substitution

856
01:04:51,580 --> 01:04:55,080
I'm going to get a alpha n,

857
01:04:55,110 --> 01:04:58,740
and then a one minus alpha n, and those two together

858
01:04:58,760 --> 01:05:01,090
are already going to add up to everything here.

859
01:05:01,110 --> 01:05:03,640
So, there's no way I'm going to get it bounded

860
01:05:03,660 --> 01:05:05,020
when I add this term in.

861
01:05:05,040 --> 01:05:06,780
So, I need to subtract something

862
01:05:06,790 --> 01:05:09,940
from both of these so as to absorb this term,

863
01:05:09,980 --> 01:05:14,120
OK? So, I'm skipping over those steps,

864
01:05:14,150 --> 01:05:19,130
OK, because we did those steps in lecture two or something.

865
01:05:19,160 --> 01:05:23,030
OK, so that's the thing I'm going to guess

866
01:05:23,050 --> 01:05:28,320
where a and b are greater than zero.

867
01:05:28,350 --> 01:05:31,990
OK, so let's do the substitution.

868
01:05:43,430 --> 01:05:50,410
OK, so we have PM one of n is less than or equal to,

869
01:05:50,440 --> 01:05:56,180
OK, we substitute this inductive hypothesis in

870
01:05:56,200 --> 01:05:58,290
for these two guys.

871
01:05:58,310 --> 01:06:07,580
So, we get a alpha n minus b log of alpha n

872
01:06:07,650 --> 01:06:13,590
plus a of one minus alpha n

873
01:06:13,660 --> 01:06:21,880
minus b log of one minus alpha,

874
01:06:21,950 --> 01:06:22,690
maybe another parentheses there,

875
01:06:22,760 --> 01:06:25,360
one minus alpha n,

876
01:06:25,760 --> 01:06:27,840
and even leave myself enough space here

877
01:06:27,910 --> 01:06:30,560
Plus, let me just move this over

878
01:06:30,630 --> 01:06:32,710
so I don't end up using too much space.

879
01:06:32,740 --> 01:06:37,490
So, b log of one minus alpha n

880
01:06:37,520 --> 01:06:46,070
plus theta of log n. How's that?

881
01:06:46,090 --> 01:06:55,760
Are we OK on that? OK, so that's just substitution.

882
01:06:55,780 --> 01:06:58,370
Let's do a little algebra.

883
01:06:58,400 --> 01:07:04,750
That's equal to a of times alpha na times one minus alpha n.

884
01:07:04,780 --> 01:07:08,930
That's just an, OK, minus,

885
01:07:08,960 --> 01:07:11,200
well, the b isn't quite so simple.

886
01:07:11,230 --> 01:07:13,160
OK, so I have a b term.

887
01:07:13,180 --> 01:07:15,520
Now I've got a whole bunch of stuff there.

888
01:07:15,560 --> 01:07:19,060
I've got log of alpha n.

889
01:07:19,080 --> 01:07:25,170
I have, then, this log of one minus alpha n,

890
01:07:25,190 --> 01:07:35,500
OK, one minus alpha n, and then plus theta log n.

891
01:07:35,520 --> 01:07:42,680
Did I do that right? Does that look OK?

892
01:07:42,700 --> 01:07:50,630
OK, so look at that.

893
01:07:50,650 --> 01:07:55,980
OK, so now let's just multiply some of this stuff out.

894
01:07:56,000 --> 01:08:00,460
So, I have an minus b times,

895
01:08:00,490 --> 01:08:05,570
well, log of alpha n is just log alpha plus log n.

896
01:08:05,590 --> 01:08:12,640
And then I have plus log of one minus alpha plus log n,

897
01:08:12,670 --> 01:08:20,520
OK, plus theta log n. That's just more algebra,

898
01:08:20,540 --> 01:08:24,830
OK, using our rules for logs.

899
01:08:24,850 --> 01:08:27,860
Now let me express this

900
01:08:27,890 --> 01:08:34,150
as my solution minus my desired solution minus a residual,

901
01:08:34,160 --> 01:08:43,860
an minus b log n, OK, minus, OK,

902
01:08:43,880 --> 01:08:48,750
and so that was one of these b log n's, right, is here.

903
01:08:48,770 --> 01:08:51,190
And the other one's going to end up in here.

904
01:08:51,210 --> 01:09:03,330
I have B times log n plus log of alpha

905
01:09:03,350 --> 01:09:09,890
times one minus alpha minus, oops, I've got too many.

906
01:09:09,910 --> 01:09:11,460
Do I have the right number of closes.

907
01:09:11,480 --> 01:09:14,880
Close that, close that, that's good,

908
01:09:14,900 --> 01:09:29,660
minus theta log n. Two there.

909
01:09:29,680 --> 01:09:35,950
Boy, my writing is degrading. OK, did I do that right?

910
01:09:35,990 --> 01:09:37,150
Do I have the parentheses right?

911
01:09:37,180 --> 01:09:39,970
That matches, that matches,

912
01:09:39,990 --> 01:09:41,380
that matches, good.

913
01:09:41,410 --> 01:09:44,170
And then B goes to that, OK, good.

914
01:09:44,190 --> 01:09:48,670
OK, and I claim that is less than or equal to

915
01:09:48,700 --> 01:09:59,140
an minus B log n if we choose B large enough.

916
01:09:59,160 --> 01:10:09,980
OK, this mess dominates this

917
01:10:10,000 --> 01:10:13,610
because this is basically a log n here,

918
01:10:13,640 --> 01:10:16,680
and this is essentially a constant.

919
01:10:16,700 --> 01:10:20,620
OK, so if I increase B,

920
01:10:20,650 --> 01:10:29,010
OK, times log n, I can overcome that log n,

921
01:10:29,030 --> 01:10:31,030
whatever the constant is,

922
01:10:31,050 --> 01:10:36,390
hidden by the asymptotic notation,

923
01:10:36,410 --> 01:10:51,980
OK, such that B times log n plus log of alpha

924
01:10:52,000 --> 01:10:59,610
times one minus alpha dominates the theta log n.

925
01:10:59,630 --> 01:11:04,810
OK, and I can also choose

926
01:11:04,830 --> 01:11:07,950
my base condition to be big enough

927
01:11:07,970 --> 01:11:09,280
to handle the initial conditions,

928
01:11:09,300 --> 01:11:10,930
whatever they might be.

929
01:11:10,960 --> 01:11:28,840
OK, so we'll choose A big enough --

930
01:11:46,590 --> 01:11:48,050
——to satisfy the base of the induction.

931
01:11:48,070 --> 01:12:00,900
OK, so thus PM_1 of n is equal to theta n, OK?

932
01:12:00,920 --> 01:12:05,850
So I actually showed O, and it turns out,

933
01:12:05,870 --> 01:12:10,680
the lower bound that it is omega n is more straightforward

934
01:12:10,710 --> 01:12:11,750
because the recurrence is easier

935
01:12:11,770 --> 01:12:13,540
because I can do the same substitution.

936
01:12:13,560 --> 01:12:18,040
I just don't have to subtract off low order terms.

937
01:12:18,060 --> 01:12:20,760
OK, so it's actually theta, not just O.

938
01:12:20,790 --> 01:12:28,870
OK, so that gives us a log,

939
01:12:28,890 --> 01:12:31,170
what did we say the critical path was?

940
01:12:31,200 --> 01:12:34,420
The critical path is log squared n for the parallel merge.

941
01:12:34,440 --> 01:12:40,740
So, let's do the analysis of merge sort using this.

942
01:12:46,000 --> 01:12:50,910
So, the work is, as we know already,

943
01:12:50,930 --> 01:12:55,380
T_1 of n is theta of n log n

944
01:12:55,390 --> 01:12:59,310
because our work that we just analyzed was order n,

945
01:12:59,330 --> 01:13:02,190
same as for the serial algorithm, OK?

946
01:13:02,210 --> 01:13:04,510
The critical path length, now,

947
01:13:04,530 --> 01:13:10,560
is T infinity of n is equal to,

948
01:13:10,590 --> 01:13:14,230
OK, so in normal merge sort,

949
01:13:14,260 --> 01:13:19,050
we have a problem of half the size, T of n over 2 plus,

950
01:13:19,060 --> 01:13:24,320
now, my critical path for merging

951
01:13:24,350 --> 01:13:26,780
is not order n as it was before.

952
01:13:26,800 --> 01:13:33,700
Instead, it's just over there.

953
01:13:33,730 --> 01:13:40,180
Log squared n, there we go.

954
01:13:40,210 --> 01:13:55,050
OK, and so that gives us theta of log cubed n.

955
01:13:55,070 --> 01:14:08,800
So, our parallelism is then theta of n over log cubed n.

956
01:14:08,830 --> 01:14:18,100
And, in fact, the best that's been done is,

957
01:14:18,120 --> 01:14:24,180
sorry, log squared n, you're right.

958
01:14:24,200 --> 01:14:31,660
Log squared n because it's n log n over log cubed n.

959
01:14:31,690 --> 01:14:33,900
It's n over log squared n, OK?

960
01:14:33,930 --> 01:14:39,690
And the best, so now I wonder if I have a typo here.

961
01:14:39,710 --> 01:14:42,200
I have that the best is,

962
01:14:42,210 --> 01:14:48,240
p bar is theta of n over log n. Is that right?

963
01:14:48,270 --> 01:14:57,430
I think so. Yeah, that's the best to date.

964
01:14:57,450 --> 01:15:07,550
That's the best to date. By Occoli, I believe,

965
01:15:07,570 --> 01:15:12,050
is who did this, for this

966
01:15:13,720 --> 01:15:17,680
So you can actually get a fairly good, but it turns out

967
01:15:17,760 --> 01:15:20,580
sorting is a really tough problem to parallelize

968
01:15:20,640 --> 01:15:23,040
to get really good constants where you want to make it

969
01:15:23,110 --> 01:15:24,630
so that it's running exactly the same.

970
01:15:24,660 --> 01:15:25,850
Matrix multiplication,

971
01:15:25,870 --> 01:15:28,330
you can make it run in parallel and get

972
01:15:28,350 --> 01:15:31,470
straight, hard rail, linear speed up with a number of processors

973
01:15:31,500 --> 01:15:33,230
There is plenty of parallelism,

974
01:15:33,250 --> 01:15:35,140
and running on more processors,

975
01:15:35,160 --> 01:15:38,100
every processor carries a full weight. With sorting,

976
01:15:38,120 --> 01:15:41,550
typically you lose, I don't know,

977
01:15:41,590 --> 01:15:48,030
20% in my experience, in terms of other stuff going on

978
01:15:48,090 --> 01:15:51,000
because you have to work really hard

979
01:15:51,040 --> 01:15:54,600
to get the constants of this merge algorithm down

980
01:15:54,610 --> 01:15:57,990
to the constants of that normal merge, right?

981
01:15:58,020 --> 01:15:59,590
I mean that's a pretty good algorithm, right,

982
01:15:59,620 --> 01:16:01,410
the one that just goes, BUZZING SOUND,

983
01:16:01,410 --> 01:16:05,770
and just takes two lists and merges them like that.

984
01:16:05,790 --> 01:16:10,590
So, it's an interesting issue.

985
01:16:10,610 --> 01:16:13,460
And a lot of people work very hard on sorting,

986
01:16:13,480 --> 01:16:14,910
because it's a hugely important problem,

987
01:16:14,930 --> 01:16:17,820
and how it is that you can actually get the constants down

988
01:16:17,840 --> 01:16:19,580
while still guaranteeing that

989
01:16:19,610 --> 01:16:22,960
it will scale up with a number of processors.

990
01:16:22,980 --> 01:16:29,250
OK, that's our little sojourn into parallel land,

991
01:16:29,280 --> 01:16:34,060
and next week we're going to talk about caching,

992
01:16:34,080 --> 01:16:40,140
which is another very important area of algorithms,

993
01:16:40,160 --> 01:16:43,070
and of programming in general.

